[
    {
        "id": 1,
        "title": {
            "en": "ATLAS Qualification Task – Detector Alignment",
            "es": "Tarea de calificación de ATLAS: Alineación del detector",
            "ja": "ATLAS資格タスク - 検出器のアライメント",
            "fr": "Tâche de qualification ATLAS – Alignement du détecteur",
            "ru": "Квалификационное задание ATLAS – Выравнивание детектора"
        },
        "date": "2023-05-01",
        "description": {
            "en": "Contribution to the ATLAS detector alignment framework within ATHENA, focusing on alignment corrections for the Inner Detector using track–hit residual minimization under strict code review and validation procedures.",
            "es": "Contribución al marco de alineación del detector ATLAS dentro de ATHENA, centrándose en las correcciones de alineación para el Detector Interno utilizando la minimización de residuos de pista-impacto bajo estrictos procedimientos de revisión y validación de código.",
            "ja": "ATHENA内のATLAS検出器アライメントフレームワークへの貢献、トラック-ヒット残差最小化を使用して内部検出器のアライメント補正に焦点を当て、厳格なコードレビューと検証手順を実施しました。",
            "fr": "Contribution au cadre d'alignement du détecteur ATLAS au sein d'ATHENA, en se concentrant sur les corrections d'alignement pour le détecteur interne en utilisant la minimisation des résidus piste-hit sous des procédures strictes de révision et de validation du code.",
            "ru": "Вклад в рамки выравнивания детектора ATLAS в ATHENA, с акцентом на коррекции выравнивания для внутреннего детектора с использованием минимизации остатков треков-попаданий при строгих процедурах проверки и валидации кода."
        },
        "tags": [
            1,
            2
        ],
        "languages": [
            {
                "name": "C++",
                "proportion": 100
            }
        ],
        "topic": "Detector Instrumentation",
        "image": {
            "en": "/assets/atlas_front.jpg"
        },
        "skills": [
            {
                "id": 1,
                "relevance": 80
            },
            {
                "id": 2,
                "relevance": 100
            },
            {
                "id": 3,
                "relevance": 70
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>ATLAS Qualification Task – Detector Alignment</h2>\n\n  <p>\n    As part of my qualification task within the <strong>ATLAS Collaboration</strong>, \n    I worked on the performance study of the detector alignment algorithm for the \n    <strong>High-Luminosity LHC (HL-LHC)</strong> upgrade, focusing on the new \n    <strong>ATLAS Inner Tracker (ITk)</strong> geometry.\n  </p>\n\n  <p>\n    The HL-LHC will operate at unprecedented luminosities, requiring a complete \n    replacement of the current inner detector due to radiation damage, bandwidth \n    limitations, and tracking performance constraints. Precise alignment of the \n    ITk is essential, as tracking accuracy is ultimately limited by how well the \n    positions and orientations of individual detector modules are known over time.\n  </p>\n\n  <p>\n    My work focused on the <strong>migration and validation of the misalignment framework</strong> \n    in <em>Athena</em>, the ATLAS software environment, using the latest ITk geometry. \n    This framework is a critical component for testing and benchmarking the alignment \n    algorithm, which minimizes global track residuals by optimizing six degrees of \n    freedom (three translations and three rotations) for each detector element.\n  </p>\n\n  <p>\n    I implemented and validated several classes of misalignments, including \n    <strong>global distortions</strong> used to verify detector groupings and geometry \n    consistency, as well as more <strong>realistic, complex misalignments</strong> that \n    emulate mechanical deformations and temperature-dependent effects observed in \n    real detectors. The validation was performed by correlating applied analytical \n    distortions with observed module displacements in simulation.\n  </p>\n\n  <p>\n    This work contributes to ensuring that the ATLAS alignment strategy remains robust \n    and scalable for the HL-LHC era, where precise tracking must be maintained under \n    extreme pile-up and long-term operational conditions. The results of this study \n    were presented at the <strong>Japan Physical Society Spring Meeting 2023</strong>.\n  </p>\n\n    <div style='margin: 1rem 0; max-width: 900px;'>\n        <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n            <iframe\n                src='assets/23aT2-07.pdf#view=FitH'\n                title='Embedded slides: 23aT2-07'\n                style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n                allowfullscreen>\n            </iframe>\n        </div>\n        <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n            <a href='assets/23aT2-07.pdf' target='_blank' rel='noopener noreferrer'>\n                Open slides in a new tab\n            </a>\n        </p>\n    </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2023spe/data/html/programsj.html'>Japan physics society timetable</a>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Tarea de calificación de ATLAS: Alineación del detector</h2>\n    <p>\n    Como parte de mi tarea de calificación dentro de la <strong>Colaboración ATLAS</strong>,\n    trabajé en el estudio de rendimiento del algoritmo de alineación del detector para la\n    <strong>actualización del HL-LHC</strong>, centrándome en la nueva geometría del\n    <strong>ATLAS Inner Tracker (ITk)</strong>.\n    </p>\n    <p>\n    El HL-LHC operará a luminosidades sin precedentes, lo que requiere un reemplazo completo\n    del detector interno debido a daños por radiación, limitaciones de ancho de banda y\n    restricciones de rendimiento de seguimiento. La alineación precisa del ITk es esencial,\n    ya que la precisión del seguimiento está limitada en última instancia por qué tan bien\n    se conocen las posiciones y orientaciones de los módulos individuales del detector a lo largo del tiempo.\n    </p>\n    <p>\n    Mi trabajo se centró en la <strong>migración y validación del marco de desalineación</strong>\n    en <em>Athena</em>, el entorno de software de ATLAS, utilizando la última geometría de ITk.\n    Este marco es un componente crítico para probar y evaluar el algoritmo de alineación,\n    que minimiza los residuos globales de seguimiento optimizando seis grados de libertad\n    (tres traslaciones y tres rotaciones) para cada elemento del detector.\n    </p>\n    <p>\n    Implementé y validé varias clases de desalineaciones, incluidas las\n    <strong>distorsiones globales</strong> utilizadas para verificar los agrupamientos del\n    detectores y la consistencia de la geometría, así como desalineaciones más\n    <strong>realistas y complejas</strong> que emulan deformaciones mecánicas y efectos\n    dependientes de la temperatura observados en detectores reales. La validación se\n    realizó correlacionando las distorsiones analíticas aplicadas con los desplazamientos\n    observados de los módulos en la simulación.\n    </p>\n    <p>\n    Este trabajo contribuye a garantizar que la estrategia de alineación de ATLAS siga siendo\n    robusta y escalable para la era del HL-LHC, donde se debe mantener un seguimiento\n    preciso bajo condiciones extremas de apilamiento y operación a largo plazo. Los\n    resultados de este estudio se presentaron en la <strong>Reunión de primavera de la\n    Sociedad Física de Japón 2023</strong>.\n    </p>\n    <div style='margin: 1rem 0; max-width: 900px;'>\n        <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n            <iframe\n                src='assets/23aT2-07.pdf#view=FitH'\n                title='Diapositivas integradas: 23aT2-07'\n                style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n                allowfullscreen>\n            </iframe>\n        </div>\n        <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n            <a href='assets/23aT2-07.pdf' target='_blank' rel='noopener noreferrer'>\n                Abrir diapositivas en una nueva pestaña\n            </a>\n        </p>\n    </div>\n    <h3>Enlaces</h3>\n    <a href='https://onsite.gakkai-web.net/jps/jps_search/2023spe/data/html/programsj.html'>Programa de la sociedad de física de Japón (En ingles)</a>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>ATLAS資格タスク - 検出器のアライメント</h2>\n    <p>\n    ATLASコラボレーションの資格タスクの一環として、HL-LHCアップグレードの検出器アライメントアルゴリズムのパフォーマンス研究に取り組み、\n    新しいATLAS Inner Tracker（ITk）ジオメトリに焦点を当てました。\n    </p>\n    <p>\n    HL-LHCは前例のないルミノシティで動作し、放射線損傷、帯域幅の制限、追跡性能の制約により、現在の内部検出器の完全な交換が必要です。\n    ITkの正確なアライメントは不可欠であり、追跡の精度は最終的に、時間の経過とともに個々の検出器モジュールの位置と方向がどれだけ正確に知られているかによって制限されます。\n    </p>\n    <p>\n    私の仕事は、最新のITkジオメトリを使用して、ATLASソフトウェア環境である<Athena>でのミスアライメントフレームワークの移行と検証に焦点を当てました。\n    このフレームワークは、検出器要素ごとに6つの自由度（3つの平行移動と3つの回転）を最適化することにより、グローバルトラック残差を最小化するアライメントアルゴリズムをテストおよびベンチマークするための重要なコンポーネントです。\n    </p>\n    <p>\n    私は、検出器のグループ化とジオメトリの一貫性を検証するために使用されるグローバルな歪みを含む、いくつかのクラスのミスアライメントを実装および検証しました。\n    また、実際の検出器で観察される機械的変形や温度依存効果をエミュレートする、より現実的で複雑なミスアライメントも実装しました。\n    検証は、シミュレーションで観察されたモジュールの変位と適用された解析的歪みを相関させることによって行われました。\n    </p>\n    <p>\n    この作業は、ATLASのアライメント戦略がHL-LHC時代に堅牢でスケーラブルであり続けることを保証するのに貢献します。\n    極端なパイルアップと長期的な運用条件下で正確な追跡を維持する必要があります。\n    この研究の結果は、2023年の日本物理学会春季大会で発表されました。\n    </p>\n    <div style='margin: 1rem 0; max-width: 900px;'>\n        <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n            <iframe\n                src='assets/23aT2-07.pdf#view=FitH'\n                title='埋め込みスライド：23aT2-07'\n                style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n                allowfullscreen>\n            </iframe>\n        </div>\n        <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n            <a href='assets/23aT2-07.pdf' target='_blank' rel='noopener noreferrer'>\n                新しいタブでスライドを開く\n            </a>\n        </p>\n    </div>\n    <h3>リンク</h3>\n    <a href='https://jps2023s.gakkai-web.net/data/html/programsj.html'>日本物理学会プログラム</a>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>Tâche de qualification ATLAS – Alignement du détecteur</h2>\n    <p>\n    Dans le cadre de ma tâche de qualification au sein de la <strong>collaboration ATLAS</strong>, j'ai travaillé sur l'étude des performances de l'algorithme d'alignement du détecteur pour la mise à niveau du <strong>HL-LHC</strong>, en me concentrant sur la nouvelle géométrie du <strong>ATLAS Inner Tracker (ITk)</strong>.\n    </p>\n    <p>\n    Le HL-LHC fonctionnera à des luminosités sans précédent, nécessitant un remplacement complet du détecteur interne en raison des dommages causés par les radiations, des limitations de bande passante et des contraintes de performance de suivi. Un alignement précis de l'ITk est essentiel, car la précision du suivi est finalement limitée par la connaissance des positions et des orientations des modules individuels du détecteur au fil du temps.\n    </p>\n    <p>\n    Mon travail s'est concentré sur la <strong>migration et la validation du cadre de désalignement</strong> dans <em>Athena</em>, l'environnement logiciel d'ATLAS, en utilisant la dernière géométrie ITk. Ce cadre est un composant critique pour tester et évaluer l'algorithme d'alignement, qui minimise les résidus globaux de suivi en optimisant six degrés de liberté (trois translations et trois rotations) pour chaque élément du détecteur.\n    </p>\n    <p>\n    J'ai mis en œuvre et validé plusieurs classes de désalignements, y compris les <strong>distorsions globales</strong> utilisées pour vérifier les groupements de détecteurs et la cohérence géométrique, ainsi que des désalignements plus <strong>réalistes et complexes</strong> qui imitent les déformations mécaniques et les effets dépendant de la température observés dans les détecteurs réels. La validation a été effectuée en corrélant les distorsions analytiques appliquées avec les déplacements observés des modules dans la simulation.\n    </p>\n    <p>\n    Ce travail contribue à garantir que la stratégie d'alignement d'ATLAS reste robuste et évolutive pour l'ère du HL-LHC, où un suivi précis doit être maintenu dans des conditions extrêmes de superposition et d'exploitation à long terme. Les résultats de cette étude ont été présentés lors de la <strong>réunion de printemps 2023 de la Société japonaise de physique</strong>.\n    </p>\n    <div style='margin: 1rem 0; max-width: 900px;'>\n        <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n            <iframe\n                src='assets/23aT2-07.pdf#view=FitH'\n                title='Diapositives intégrées : 23aT2-07'\n                style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n                allowfullscreen>\n            </iframe>\n        </div>\n        <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n            <a href='assets/23aT2-07.pdf' target='_blank' rel='noopener noreferrer'>\n                Ouvrir les diapositives dans un nouvel onglet\n            </a>\n        </p>\n    </div>\n    <h3>Liens</h3>\n    </h3>\n    <a href='https://onsite.gakkai-web.net/jps/jps_search/2023spe/data/html/programsj.html'>Programme de la Société japonaise de physique (en anglais)</a>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Квалификационное задание ATLAS – Выравнивание детектора</h2>\n    <p>\n    В рамках моей квалификационной задачи в составе <strong>Коллаборации ATLAS</strong>,\n    я работал над исследованием производительности алгоритма выравнивания детектора для\n    обновления <strong>HL-LHC</strong>, сосредоточив внимание на новой геометрии\n    <strong>ATLAS Inner Tracker (ITk)</strong>.\n    </p>\n    <p>\n    HL-LHC будет работать на беспрецедентных уровнях светимости, что требует полной замены\n    внутреннего детектора из-за повреждений от радиации, ограничений пропускной способности\n    и ограничений производительности отслеживания. Точное выравнивание ITk имеет решающее значение,\n    поскольку точность отслеживания в конечном итоге ограничивается тем, насколько хорошо известны\n    положения и ориентации отдельных модулей детектора с течением времени.\n    </p>\n    <p>\n    Моя работа была сосредоточена на <strong>миграции и проверке рамок смещения</strong>\n    в <em>Athena</em>, программной среде ATLAS, используя последнюю геометрию ITk.\n    Эта рамка является критическим компонентом для тестирования и оценки алгоритма выравнивания,\n    который минимизирует глобальные остатки треков, оптимизируя шесть степеней свободы\n    (три перемещения и три вращения) для каждого элемента детектора.\n    </p>\n    <p>\n    Я реализовал и проверил несколько классов смещений, включая\n    <strong>глобальные искажения</strong>, используемые для проверки группировок детекторов\n    и согласованности геометрии, а также более <strong>реалистичные и сложные смещения</strong>,\n    которые имитируют механические деформации и температурно-зависимые эффекты,\n    наблюдаемые в реальных детекторах. Проверка была выполнена путем корреляции\n    примененных аналитических искажений с наблюдаемыми смещениями модулей в симуляции.\n    </p>\n    <p>\n    Эта работа способствует обеспечению того, чтобы стратегия выравнивания ATLAS оставалась\n    надежной и масштабируемой для эпохи HL-LHC, где необходимо поддерживать точное отслеживание\n    в экстремальных условиях наложения и длительной эксплуатации. Результаты этого исследования были\n    представлены на <strong>весенней встрече Японского физического общества 2023 года</strong>.\n    </p>\n    <div style='margin: 1rem 0; max-width: 900px;'>\n        <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n            <iframe\n                src='assets/23aT2-07.pdf#view=FitH'\n                title='Встроенные слайды: 23aT2-07'\n                style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n                allowfullscreen>\n            </iframe>\n        </div>\n        <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n            <a href='assets/23aT2-07.pdf' target='_blank' rel='noopener noreferrer'>\n                Открыть слайды в новой вкладке\n            </a>\n        </p>\n    </div>\n    <h3>Ссылки</h3>\n    <a href='https://onsite.gakkai-web.net/jps/jps_search/2023spe/data/html/programsj.html'>Расписание Японского физического общества</a>\n</article>"
        }
    },
    {
        "id": 2,
        "title": {
            "en": "Diphoton Background Modeling (Z→ee)",
            "es": "Modelado del fondo diphotónico (Z→ee)",
            "ja": "二光子バックグラウンドモデリング (Z→ee)",
            "fr": "Modélisation du fond diphoton (Z→ee)",
            "ru": "Моделирование дипфотонного фона (Z→ee)"
        },
        "date": "2024-09-01",
        "description": {
            "en": "Ph.D. research project focused on modeling the Z→ee background in diphoton analyses using optimal transport techniques to model fake photons invariant mass distributions.",
            "es": "Proyecto de investigación de doctorado centrado en el modelado del fondo Z→ee en análisis diphotónicos utilizando técnicas de transporte óptimo para modelar las distribuciones de masa invariante de fotones falsos.",
            "ja": "偽の光子の不変質量分布をモデル化するために最適輸送技術を使用して、二光子分析におけるZ→eeバックグラウンドのモデリングに焦点を当てた博士課程の研究プロジェクト。",
            "fr": "Projet de recherche de doctorat axé sur la modélisation du fond Z→ee dans les analyses diphotoniques en utilisant des techniques de transport optimal pour modéliser les distributions de masse invariante des faux photons.",
            "ru": "Исследовательский проект Ph.D., посвященный моделированию фона Z→ee в дипфотонных анализах с использованием методов оптимального транспорта для моделирования распределений инвариантной массы ложных фотонов."
        },
        "tags": [
            10,
            11,
            6,
            1,
            2
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 13
            },
            {
                "name": "C++",
                "proportion": 85
            },
            {
                "name": "YAML",
                "proportion": 2
            }
        ],
        "topic": "High-Energy Physics",
        "image": {
            "en": "/assets/atlas.jpg"
        },
        "skills": [
            {
                "id": 1,
                "relevance": 30
            },
            {
                "id": 2,
                "relevance": 40
            },
            {
                "id": 3,
                "relevance": 100
            },
            {
                "id": 4,
                "relevance": 70
            },
            {
                "id": 5,
                "relevance": 70
            },
            {
                "id": 6,
                "relevance": 80
            }
        ],
        "content": {
            "en": "<article class='project-article'> \n <h2>Diphoton Background Modeling</h2>\n\n  <p>\n    This project is part of my Ph.D. research within the <strong>ATLAS Collaboration</strong> \n    and focuses on the modeling of backgrounds in <strong>diphoton final states</strong>, \n    a key channel for precision measurements and searches for physics beyond the \n    Standard Model, including Higgs-related analyses.\n  </p>\n\n  <p>\n    In diphoton analyses, the dominant backgrounds arise not only from genuine photon \n    production but also from events in which <strong>electrons are misidentified as photons</strong>. \n    These misidentifications originate from reconstruction ambiguities in the inner detector \n    and electromagnetic calorimeter, such as missing or partially reconstructed tracks, \n    photon conversions, and bremsstrahlung-induced energy loss.\n  </p>\n\n  <p>\n    My work addresses this challenge by developing a <strong>data-driven background modeling strategy</strong> \n    that simultaneously estimates both the <em>rate</em> and the <em>invariant-mass shape</em> \n    of misidentified events. Rather than attempting to correct individual objects, the method \n    models the observed diphoton invariant mass as a probabilistic transformation of the true \n    underlying distributions.\n  </p>\n\n  <p>\n    A central component of the approach is the use of <strong>probability density functions (PDFs)</strong> \n    and their corresponding <strong>cumulative distribution functions (CDFs)</strong> to map correctly \n    reconstructed events to the mass distributions expected from one or two particle \n    misidentifications. This framework allows the construction of consistent mass templates \n    without relying on direct truth-level information.\n  </p>\n\n  <p>\n    The model further incorporates <strong>event-level misidentification probabilities</strong>, \n    accounting for correlations between leading and subleading particles and extending naturally \n    to multiple analysis categories, including multivariate (BDT-based) selections. Normalization \n    constraints are treated carefully to remain robust against residual correlations and \n    reconstruction effects.\n  </p>\n\n  <p>\n    This work provides a scalable and statistically well-defined method for diphoton background \n    estimation, improving sensitivity in precision measurements and new-physics searches while \n    remaining compatible with the reconstruction realities of the ATLAS detector. Detailed \n    results and validations are currently under internal review and are therefore not yet public.\n  </p>\n</article>",
            "es": "<article class='project-article'> \n <h2>Modelado del fondo diphotónico</h2>\n\n  <p>\n    Este proyecto es parte de mi investigación de doctorado dentro de la <strong>Colaboración ATLAS</strong> \n    y se centra en el modelado de fondos en <strong>estados finales diphotónicos</strong>, \n    un canal clave para mediciones de precisión y búsquedas de física más allá del \n    Modelo Estándar, incluyendo análisis relacionados con el Higgs.\n  </p>\n\n  <p>\n    En los análisis diphotónicos, los fondos dominantes no solo provienen de la producción genuina de fotones, \n    sino también de eventos en los que <strong>los electrones son mal identificados como fotones</strong>. \n    Estas malas identificaciones se originan a partir de ambigüedades de reconstrucción en el detector interno \n    y el calorímetro electromagnético, como pistas faltantes o parcialmente reconstruidas, \n    conversiones de fotones y pérdida de energía inducida por bremsstrahlung.\n  </p>\n\n  <p>\n    Mi trabajo aborda este desafío desarrollando una <strong>estrategia de modelado de fondo basada en datos</strong> \n    que estima simultáneamente tanto la <em>tasa</em> como la <em>forma de masa invariante</em> \n    de eventos mal identificados. En lugar de intentar corregir objetos individuales, el método \n    modela la masa invariante diphotónica observada como una transformación probabilística de las distribuciones subyacentes verdaderas.\n  </p>\n\n  <p>\n    Un componente central del enfoque es el uso de <strong>funciones de densidad de probabilidad (PDF)</strong> \n    y sus correspondientes <strong>funciones de distribución acumulativa (CDF)</strong> para mapear eventos correctamente \n    reconstruidos a las distribuciones de masa esperadas por una o dos malas identificaciones de partículas. Este marco permite la construcción de plantillas de masa consistentes \n    sin depender de información directa a nivel de verdad.\n  </p>\n\n  <p>\n    El modelo incorpora además <strong>probabilidades de mala identificación a nivel de evento</strong>, \n    teniendo en cuenta las correlaciones entre las partículas líderes y sublíderes y extendiéndose naturalmente \n    a múltiples categorías de análisis, incluidas selecciones multivariadas (basadas en BDT). Las restricciones de normalización \n    se tratan cuidadosamente para mantenerse robustas frente a correlaciones residuales y \n    efectos de reconstrucción.\n  </p>\n\n  <p>\n    Este trabajo proporciona un método escalable y estadísticamente bien definido para la estimación del fondo diphotónico, mejorando la sensibilidad en mediciones de precisión y búsquedas de nueva física mientras \n    se mantiene compatible con las realidades de reconstrucción del detector ATLAS. Los resultados detallados y las validaciones están actualmente bajo revisión interna y, por lo tanto, aún no son públicos.\n  </p>\n</article>",
            "ja": "<article class='project-article'> \n <h2>二光子背景モデリング</h2>\n\n  <p>\n    このプロジェクトは、<strong>ATLASコラボレーション</strong>内での私の博士研究の一部であり、\n    <strong>二光子最終状態</strong>における背景のモデリングに焦点を当てています。\n    これは、精密測定と標準モデルを超えた物理学の探索のための重要なチャネルであり、ヒッグス関連の分析も含まれます。\n  </p>\n\n  <p>\n    二光子分析では、支配的な背景は本物の光子生成だけでなく、\n    <strong>電子が光子として誤認識される</strong>イベントからも発生します。\n    これらの誤認識は、内部検出器と電磁カロリメーターでの再構成のあいまいさから生じます。\n    例えば、欠落または部分的に再構成されたトラック、光子変換、ブレムストラールングによるエネルギー損失などです。\n  </p>\n\n  <p>\n    私の仕事は、<strong>データ駆動型の背景モデリング戦略</strong>を開発することでこの課題に取り組んでいます。\n    これは、誤認識されたイベントの<em>率</em>と<em>不変質量分布</em>を同時に推定します。\n    個々のオブジェクトを修正しようとする代わりに、この方法は観測された二光子不変質量を真の基礎分布の確率的変換としてモデル化します。\n  </p>\n\n  <p>\n    このアプローチの中心的な要素は、<strong>確率密度関数（PDF）</strong>とその対応する<strong>累積分布関数（CDF）</strong>を使用して、\n    正しく再構成されたイベントを1つまたは2つの粒子の誤認識から予想される質量分布にマッピングすることです。\n    このフレームワークにより、真レベルの情報に依存せずに一貫した質量テンプレートの構築が可能になります。\n  </p>\n\n  <p>\n    このモデルはさらに、<strong>イベントレベルの誤認識確率</strong>を組み込み、\n    主要粒子と副主要粒子間の相関を考慮し、BDTベースの選択を含む多変量分析カテゴリに自然に拡張します。\n    正規化の制約は、残留相関と再構成効果に対して堅牢であるように注意深く扱われます。\n  </p>\n\n  <p>\n    この作業は、二光子背景推定のためのスケーラブルで統計的に定義された方法を提供し、\n    精密測定と新物理探索の感度を向上させる一方で、ATLAS検出器の再構成の現実と互換性を保ちます。\n    詳細な結果と検証は現在内部レビュー中であり、まだ公開されていません。\n  </p>\n</article>",
            "fr": "<article class='project-article'> \n <h2>Modélisation du fond diphoton</h2>\n\n  <p>\n    Ce projet fait partie de ma recherche de doctorat au sein de la <strong>collaboration ATLAS</strong> \n    et se concentre sur la modélisation des fonds dans les <strong>états finaux diphoton</strong>, \n    un canal clé pour les mesures de précision et les recherches de physique au-delà du \n    Modèle Standard, y compris les analyses liées au Higgs.\n  </p>\n\n  <p>\n    Dans les analyses diphoton, les fonds dominants proviennent non seulement de la production \n    authentique de photons, mais aussi d'événements dans lesquels <strong>des électrons sont mal identifiés comme des photons</strong>. \n    Ces mauvaises identifications proviennent d'ambiguïtés de reconstruction dans le détecteur interne \n    et le calorimètre électromagnétique, telles que des traces manquantes ou partiellement reconstruites, \n    des conversions de photons et des pertes d'énergie induites par le freinage.\n  </p>\n\n  <p>\n    Mon travail aborde ce défi en développant une <strong>stratégie de modélisation du fond basée sur les données</strong> \n    qui estime simultanément à la fois le <em>taux</em> et la <em>forme de masse invariante</em> \n    des événements mal identifiés. Plutôt que d'essayer de corriger des objets individuels, la méthode \n    modélise la masse invariante diphoton observée comme une transformation probabiliste des distributions sous-jacentes vraies.\n  </p>\n\n  <p>\n    Un élément central de l'approche est l'utilisation de <strong>fonctions de densité de probabilité (PDF)</strong> \n    et de leurs <strong>fonctions de distribution cumulative (CDF)</strong> correspondantes pour mapper les événements correctement \n    reconstruits aux distributions de masse attendues à partir d'une ou deux mauvaises identifications de particules. Ce cadre permet la construction de modèles de masse cohérents \n    sans s'appuyer sur des informations directes au niveau de la vérité.\n  </p>\n\n  <p>\n    Le modèle intègre en outre des <strong>probabilités de mauvaise identification au niveau de l'événement</strong>, \n    tenant compte des corrélations entre les particules principales et secondaires et s'étendant naturellement \n    à plusieurs catégories d'analyse, y compris les sélections multivariées (basées sur BDT). Les contraintes de normalisation \n    sont traitées avec soin pour rester robustes face aux corrélations résiduelles et aux \n    effets de reconstruction.\n  </p>\n\n  <p>\n    Ce travail fournit une méthode évolutive et statistiquement bien définie pour l'estimation du fond diphoton, améliorant la sensibilité des mesures de précision et des recherches de nouvelle physique tout en \n    restant compatible avec les réalités de reconstruction du détecteur ATLAS. Les résultats détaillés et les validations sont actuellement en cours d'examen interne et ne sont donc pas encore publics.\n  </p>\n</article>",
            "ru": "<article class='project-article'> \n <h2>Моделирование дипфотонного фона</h2>\n\n  <p>\n    Этот проект является частью моего исследования на степень доктора философии в рамках \n    <strong>Коллаборации ATLAS</strong> и сосредоточен на моделировании фонов в \n    <strong>дипфотонных конечных состояниях</strong>, которые являются ключевым каналом для точных измерений \n    и поисков физики за пределами Стандартной модели, включая анализы, связанные с Хиггсом.\n  </p>\n\n  <p>\n    В дипфотонных анализах доминирующие фоны возникают не только из-за истинного производства фотонов, \n    но и из событий, в которых <strong>электроны ошибочно идентифицируются как фотоны</strong>. \n    Эти ошибки идентификации возникают из-за неоднозначностей реконструкции во внутреннем детекторе \n    и электромагнитном калориметре, таких как отсутствующие или частично реконструированные треки, \n    конверсии фотонов и потери энергии, вызванные тормозным излучением.\n  </p>\n\n  <p>\n    Моя работа решает эту проблему путем разработки <strong>стратегии моделирования фона на основе данных</strong>, \n    которая одновременно оценивает как <em>скорость</em>, так и <em>распределение инвариантной массы</em> \n    неправильно идентифицированных событий. Вместо того чтобы пытаться исправить отдельные объекты, метод \n    моделирует наблюдаемую дипфотонную инвариантную массу как вероятностное преобразование истинных \n    подлежащих распределений.\n  </p>\n\n  <p>\n    Центральным компонентом подхода является использование <strong>функций плотности вероятности (PDF)</strong> \n    и соответствующих им <strong>накопительных функций распределения (CDF)</strong> для отображения правильно \n    реконструированных событий на ожидаемые распределения масс от одной или двух ошибок идентификации частиц. \n    Эта структура позволяет создавать согласованные шаблоны масс без опоры на прямую информацию на уровне истины.\n  </p>\n\n  <p>\n    Модель дополнительно включает <strong>вероятности неправильной идентификации на уровне события</strong>, \n    учитывая корреляции между ведущими и субведущими частицами и естественно расширяясь \n    на несколько категорий анализа, включая многовариантные (на основе BDT) выборки. Ограничения нормализации \n    тщательно обрабатываются, чтобы оставаться устойчивыми к остаточным корреляциям и \n    эффектам реконструкции.\n  </p>\n\n  <p>\n    Эта работа предоставляет масштабируемый и статистически хорошо определенный метод оценки дипфотонного фона, \n    повышая чувствительность в точных измерениях и поисках новой физики, оставаясь \n    совместимой с реалиями реконструкции детектора ATLAS. Подробные результаты и проверки в настоящее время находятся на внутреннем рассмотрении и поэтому еще не являются общедоступными.\n  </p>\n</article>"
        }
    },
    {
        "id": 3,
        "title": {
            "en": "Diphoton Discrimination with Graph Neural Networks",
            "es": "Discriminación diphotónica con redes neuronales gráficas",
            "ja": "グラフニューラルネットワークによる二光子識別",
            "fr": "Discrimination diphoton avec des réseaux de neurones graphiques",
            "ru": "Дипфотонная дискриминация с помощью графовых нейронных сетей"
        },
        "date": "2024-06-01",
        "description": {
            "en": "Exploration of graph neural network methods using reconstruction-level detector information to improve discrimination between diphoton signal and electron background, under constraints from simulation–data mismodeling.",
            "es": "Exploración de métodos de redes neuronales gráficas utilizando información del detector a nivel de reconstrucción para mejorar la discriminación entre la señal diphotónica y el fondo electrónico, bajo restricciones de desajuste entre simulación y datos.",
            "ja": "シミュレーションとデータのミスマッチからの制約の下で、再構成レベルの検出器情報を使用して、二光子信号と電子背景の識別を改善するためのグラフニューラルネットワーク手法の探索。",
            "fr": "Exploration des méthodes de réseaux de neurones graphiques utilisant des informations de détecteur au niveau de la reconstruction pour améliorer la discrimination entre le signal diphoton et le fond électronique, sous contraintes de mauvais modélisation simulation-données.",
            "ru": "Исследование методов графовых нейронных сетей с использованием информации детектора на уровне реконструкции для улучшения дискриминации между дипфотонным сигналом и электронным фоном, с учетом ограничений, связанных с несоответствием моделирования и данных."
        },
        "tags": [
            3,
            12,
            1,
            2
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 90
            },
            {
                "name": "C++",
                "proportion": 10
            }
        ],
        "topic": "Machine Learning",
        "image": {
            "en": "/assets/gcn.jpg"
        },
        "skills": [
            {
                "id": 3,
                "relevance": 80
            },
            {
                "id": 7,
                "relevance": 75
            },
            {
                "id": 8,
                "relevance": 80
            },
            {
                "id": 9,
                "relevance": 60
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>Graph Neural Network Experimentation for Diphoton Event Selection</h2>\n\n  <p>\n    This project explores the use of <strong>Graph Neural Networks (GNNs)</strong> to improve \n    diphoton event selection in ATLAS analyses, with a particular focus on low-mass \n    <em>H → γγ</em> searches. The work was conducted alongside my Ph.D. research on diphoton \n    background modeling and aims to overcome limitations of traditional multivariate methods.\n  </p>\n\n  <p>\n    In Run-2 analyses, diphoton event selection relied on a multi-stage \n    <strong>Boosted Decision Tree (BDT)</strong> approach, operating on summary variables and \n    fixed candidate ordering. While effective, this strategy is not well suited for handling \n    variable-length detector information such as tracks and vertices, nor for exploring all \n    possible photon-pair combinations in complex events.\n  </p>\n\n  <p>\n    To address these challenges, I designed and evaluated a <strong>GNN-based architecture</strong> \n    that represents each event as a fully connected graph, where nodes correspond to photon or \n    ambiguous electron/photon candidates and edges represent possible diphoton pairings. \n    The task is formulated as an <em>edge prediction problem</em>, allowing the model to directly \n    identify the most likely diphoton pair within each event.\n  </p>\n\n  <p>\n    A key component of the approach is a flexible <strong>encoder design</strong> that maps \n    heterogeneous reconstruction objects into a common latent representation. Scalar features \n    are combined with variable-length information from tracks and conversion vertices using \n    dedicated neural encoders, including GNN-based sub-encoders for structured inputs. This \n    allows the model to retain detailed reconstruction information without premature pooling \n    or hand-crafted summarization.\n  </p>\n\n  <p>\n    The resulting architecture naturally incorporates correlations between candidates, scales \n    to events with many objects, and removes the need for heuristic preselection of photon pairs. \n    The project demonstrates how modern graph-based methods can align more closely with the \n    underlying structure of HEP reconstruction data while remaining compatible with ATLAS \n    analysis workflows.\n  </p>\n\n  <p>\n    This work was presented multiple times within the ATLAS and HEP-ML communities, including \n    international workshops and collaboration-wide meetings, reflecting growing interest in \n    GNN-based approaches for event-level inference.\n  </p>\n\n  <!-- Embedded slides -->\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/MLColloquium2024_v3.pdf#view=FitH'\n        title='Embedded slides: Improving the diphoton event selection with GNNs'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/MLColloquium2024_v3.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <!-- Embedded poster -->\n  <div style='margin: 1.5rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 70%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/PosterAtlasWeek2024IsaiSotarriva.pdf#view=FitH'\n        title='Embedded poster: ATLAS Week 2024 – GNN Diphoton Selection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/PosterAtlasWeek2024IsaiSotarriva.pdf' target='_blank' rel='noopener noreferrer'>\n        Open poster in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://conference-indico.kek.jp/event/253/timetable/' target='_blank' rel='noopener noreferrer'>\n        ML at HEP Workshop (KEK) – Presentation timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.cern.ch/event/1355214/' target='_blank' rel='noopener noreferrer'>\n        ATLAS Week 2024 – Poster presentation (CERN)\n      </a>\n    </li>\n    <li>\n      <a href='https://onsite.gakkai-web.net/jps/jps_search/2024spe/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n        Japan Physical Society Spring Meeting 2024 – Timetable\n      </a>\n    </li>\n  </ul>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Experimentación con Redes Neuronales de Grafos para la Selección de Eventos Diphotónicos</h2>\n\n  <p>\n    Este proyecto explora el uso de <strong>Redes Neuronales de Grafos (GNNs)</strong> para mejorar \n    la selección de eventos diphotónicos en los análisis de ATLAS, con un enfoque particular en las búsquedas \n    de baja masa de <em>H → γγ</em>. El trabajo se realizó junto con mi investigación de doctorado sobre el modelado \n    del fondo diphotónico y tiene como objetivo superar las limitaciones de los métodos multivariantes tradicionales.\n  </p>\n\n  <p>\n    En los análisis de la Corrida-2, la selección de eventos diphotónicos se basó en un enfoque \n    de <strong>Árboles de Decisión Potenciados (BDT)</strong> en múltiples etapas, que operaba sobre variables resumidas y \n    un orden fijo de candidatos. Aunque efectivo, esta estrategia no es adecuada para manejar \n    información del detector de longitud variable, como pistas y vértices, ni para explorar todas las \n    posibles combinaciones de pares de fotones en eventos complejos.\n  </p>\n\n  <p>\n    Para abordar estos desafíos, diseñé y evalué una <strong>arquitectura basada en GNN</strong> que representa cada evento como un grafo completamente conectado, donde los nodos corresponden a candidatos \n    de fotones o electrones/fotones ambiguos y los bordes representan posibles emparejamientos diphotónicos. \n    La tarea se formula como un <em>problema de predicción de bordes</em>, lo que permite al modelo identificar directamente \n    el par diphotónico más probable dentro de cada evento.\n  </p>\n\n  <p>\n    Un componente clave del enfoque es un <strong>diseño codificador</strong> flexible que mapea \n    objetos heterogéneos de reconstrucción en una representación latente común. Las características escalares \n    se combinan con información de longitud variable proveniente de pistas y vértices de conversión utilizando \n    codificadores neuronales dedicados, incluidos sub-codificadores basados en GNN para entradas estructuradas. Esto \n    permite que el modelo retenga información detallada de reconstrucción sin agrupamiento prematuro \n    o resumen elaborado a mano.\n  </p>\n\n  <p>\n    La arquitectura resultante incorpora naturalmente las correlaciones entre candidatos, escala \n eventos con muchos objetos y elimina la necesidad de una preselección heurística de pares de fotones. \n    El proyecto demuestra cómo los métodos modernos basados en grafos pueden alinearse más estrechamente con la \n    estructura subyacente de los datos de reconstrucción de HEP, al tiempo que permanecen compatibles con los flujos de trabajo de análisis de ATLAS.\n  </p>\n\n  <p>\n    Este trabajo fue presentado varias veces dentro de las comunidades de ATLAS y HEP-ML, incluyendo \n    talleres internacionales y reuniones a nivel de colaboración, reflejando el creciente interés en \n    enfoques basados en GNN para la inferencia a nivel de evento.\n  </p>\n\n  <!-- Embedded slides -->\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/MLColloquium2024_v3.pdf#view=FitH'\n        title='Embedded slides: Improving the diphoton event selection with GNNs'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/MLColloquium2024_v3.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <!-- Embedded poster -->\n  <div style='margin: 1.5rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 70%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/PosterAtlasWeek2024IsaiSotarriva.pdf#view=FitH'\n        title='Embedded poster: ATLAS Week 2024 – GNN Diphoton Selection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/PosterAtlasWeek2024IsaiSotarriva.pdf' target='_blank' rel='noopener noreferrer'>\n        Open poster in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://conference-indico.kek.jp/event/253/timetable/' target='_blank' rel='noopener noreferrer'>\n        ML at HEP Workshop (KEK) – Presentation timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.cern.ch/event/1355214/' target='_blank' rel='noopener noreferrer'>\n        ATLAS Week 2024 – Poster presentation (CERN)\n      </a>\n    </li>\n    <li>\n      <a href='https://onsite.gakkai-web.net/jps/jps_search/2024spe/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n        Japan Physical Society Spring Meeting 2024 – Timetable\n      </a>\n    </li>\n  </ul>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>二光子イベント選択のためのグラフニューラルネットワーク実験</h2>\n\n  <p>\n    このプロジェクトは、<strong>グラフニューラルネットワーク（GNN）</strong>を使用してATLAS分析における二光子イベント選択を改善することを探求しており、特に低質量の<em>H → γγ</em>探索に焦点を当てています。 \n    この作業は、二光子背景モデリングに関する私の博士研究と並行して行われ、従来の多変量手法の制限を克服することを目的としています。\n  </p>\n\n  <p>\n    ラン2の分析では、二光子イベント選択は多段階の<strong>ブーステッド決定木（BDT）</strong>アプローチに依存しており、要約変数と固定された候補順序で動作していました。 \n    効果的ではありますが、この戦略はトラックや頂点などの可変長検出器情報を扱うのには適しておらず、複雑なイベントでのすべての可能な光子ペアの組み合わせを探索することもできません。\n  </p>\n\n  <p>\n    これらの課題に対処するために、私は各イベントを完全に接続されたグラフとして表現する<strong>GNNベースのアーキテクチャ</strong>を設計および評価しました。ここで、ノードは光子またはあいまいな電子/光子候補に対応し、エッジは可能な二光子ペアリングを表します。 \n    タスクは<em>エッジ予測問題</em>として定式化されており、モデルが各イベント内で最も可能性の高い二光子ペアを直接特定できるようにしています。\n  </p>\n\n  <p>\n    アプローチの重要な要素は、異種の再構成オブジェクトを共通の潜在表現にマッピングする柔軟な<strong>エンコーダーデザイン</strong>です。 \n    スカラー特徴は、トラックや変換頂点からの可変長情報と専用のニューラルエンコーダーを使用して組み合わせられ、構造化された入力にはGNNベースのサブエンコーダーが含まれています。 \n    これにより、モデルは早期のプーリングや手作りの要約なしで詳細な再構成情報を保持できます。\n  </p>\n\n  <p>\n    結果として得られるアーキテクチャは、候補間の相関を自然に組み込み、多くのオブジェクトを持つイベントにスケーリングし、光子ペアのヒューリスティックな事前選択の必要性を排除します。 \n    このプロジェクトは、最新のグラフベースの手法がHEP再構成データの基礎構造とより密接に一致しながら、ATLAS分析ワークフローと互換性を保つ方法を示しています。\n  </p>\n\n  <p>\n    この作業は、国際ワークショップやコラボレーション全体の会議など、ATLASおよびHEP-MLコミュニティ内で複数回発表され、イベントレベルの推論のためのGNNベースのアプローチに対する関心の高まりを反映しています。\n  </p>\n\n  <!-- Embedded slides -->\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/MLColloquium2024_v3.pdf#view=FitH'\n        title='Embedded slides: Improving the diphoton event selection with GNNs'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/MLColloquium2024_v3.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <!-- Embedded poster -->\n  <div style='margin: 1.5rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 70%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/PosterAtlasWeek2024IsaiSotarriva.pdf#view=FitH'\n        title='Embedded poster: ATLAS Week 2024 – GNN Diphoton Selection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/PosterAtlasWeek2024IsaiSotarriva.pdf' target='_blank' rel='noopener noreferrer'>\n        Open poster in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://conference-indico.kek.jp/event/253/timetable/' target='_blank' rel='noopener noreferrer'>\n        ML at HEP Workshop (KEK) – Presentation timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.cern.ch/event/1355214/' target='_blank' rel='noopener noreferrer'>\n        ATLAS Week 2024 – Poster presentation (CERN)\n      </a>\n    </li>\n    <li>\n      <a href='https://onsite.gakkai-web.net/jps/jps_search/2024sp/data2/html/programsj.html#j21aT2' target='_blank' rel='noopener noreferrer'>\n        Japan Physical Society Spring Meeting 2024 – Timetable\n      </a>\n    </li>\n  </ul>\n</article>",
            "fr": "<article class='project-article'> \n <h2>Expérimentation avec les réseaux de neurones graphiques pour la sélection d'événements diphotons</h2>\n\n  <p>\n    Ce projet explore l'utilisation des <strong>réseaux de neurones graphiques (GNN)</strong> pour améliorer la sélection d'événements diphotons dans les analyses ATLAS, avec un accent particulier sur les recherches de faible masse de <em>H → γγ</em>. \n    Le travail a été réalisé parallèlement à ma recherche de doctorat sur la modélisation du fond diphoton et vise à surmonter les limitations des méthodes multivariées traditionnelles.\n  </p>\n\n  <p>\n    Dans les analyses de la Run-2, la sélection des événements diphotons reposait sur une approche en plusieurs étapes basée sur les <strong>arbres de décision boostés (BDT)</strong>, fonctionnant sur des variables résumées et un ordre fixe des candidats. \n    Bien que efficace, cette stratégie n'est pas bien adaptée pour gérer les informations du détecteur de longueur variable telles que les pistes et les vertex, ni pour explorer toutes les combinaisons possibles de paires de photons dans des événements complexes.\n  </p>\n\n  <p>\n    Pour relever ces défis, j'ai conçu et évalué une <strong>architecture basée sur les GNN</strong> qui représente chaque événement comme un graphe entièrement connecté, où les nœuds correspondent aux candidats photons ou électrons/photons ambigus et les arêtes représentent les appariements diphotons possibles. \n    La tâche est formulée comme un <em>problème de prédiction d'arêtes</em>, permettant au modèle d'identifier directement la paire diphoton la plus probable dans chaque événement.\n  </p>\n\n  <p>\n    Un élément clé de l'approche est une <strong>conception d'encodeur</strong> flexible qui mappe les objets hétérogènes de reconstruction en une représentation latente commune. \n    Les caractéristiques scalaires sont combinées avec des informations de longueur variable provenant des pistes et des vertex de conversion à l'aide d'encodeurs neuronaux dédiés, y compris des sous-encodeurs basés sur les GNN pour les entrées structurées. \n    Cela permet au modèle de conserver des informations de reconstruction détaillées sans de regroupement prématuré ou de résumé manuel.\n  </p>\n\n  <p>\n    L'architecture résultante intègre naturellement les corrélations entre les candidats, s'adapte aux événements avec de nombreux objets et élimine le besoin d'une présélection heuristique des paires de photons. \n    Le projet démontre comment les méthodes modernes basées sur les graphes peuvent s'aligner plus étroitement sur la structure sous-jacente des données de reconstruction HEP tout en restant compatibles avec les flux de travail d'analyse ATLAS.\n  </p>\n\n  <p>\n    Ce travail a été présenté à plusieurs reprises au sein des communautés ATLAS et HEP-ML, notamment lors d'ateliers internationaux et de réunions à l'échelle de la collaboration, reflétant l'intérêt croissant pour les approches basées sur les GNN pour l'inférence au niveau des événements.\n  </p>\n\n  <!-- Embedded slides -->\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/MLColloquium2024_v3.pdf#view=FitH'\n        title='Embedded slides: Improving the diphoton event selection with GNNs'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/MLColloquium2024_v3.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <!-- Embedded poster -->\n  <div style='margin: 1.5rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 70%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/PosterAtlasWeek2024IsaiSotarriva.pdf#view=FitH'\n        title='Embedded poster: ATLAS Week 2024 – GNN Diphoton Selection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/PosterAtlasWeek2024IsaiSotarriva.pdf' target='_blank' rel='noopener noreferrer'>\n        Open poster in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://conference-indico.kek.jp/event/253/timetable/' target='_blank' rel='noopener noreferrer'>\n        ML at HEP Workshop (KEK) – Presentation timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.cern.ch/event/1355214/' target='_blank' rel='noopener noreferrer'>\n        ATLAS Week 2024 – Poster presentation (CERN)\n      </a>\n    </li>\n    <li>\n      <a href='https://onsite.gakkai-web.net/jps/jps_search/2024spe/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n        Japan Physical Society Spring Meeting 2024 – Timetable\n      </a>\n    </li>\n  </ul>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Эксперименты с графовыми нейронными сетями для отбора дипhoton-событий</h2>\n\n  <p>\n    Этот проект исследует использование <strong>графовых нейронных сетей (GNN)</strong> для улучшения отбора дипhoton-событий в анализах ATLAS, с особым акцентом на поиски низкомассового <em>H → γγ</em>. \n    Работа была проведена параллельно с моими исследованиями по моделированию дипhoton-фона в рамках моей докторской диссертации и направлена на преодоление ограничений традиционных многомерных методов.\n  </p>\n\n  <p>\n    В анализах Run-2 отбор дипhoton-событий основывался на многоступенчатом подходе с использованием <strong>усиленных деревьев решений (BDT)</strong>, работающем на обобщенных переменных и фиксированном порядке кандидатов. \n    Хотя этот метод был эффективен, он не подходит для обработки информации детектора переменной длины, такой как треки и вершины, а также для исследования всех возможных комбинаций пар фотонов в сложных событиях.\n  </p>\n\n  <p>\n    Чтобы решить эти задачи, я разработал и оценил <strong>архитектуру на основе GNN</strong>, которая представляет каждое событие как полностью связный граф, где узлы соответствуют кандидатам в фотоны или неоднозначным электронам/фотоны, а ребра представляют возможные дипhoton-пары. \n    Задача формулируется как <em>задача предсказания ребер</em>, что позволяет модели напрямую идентифицировать наиболее вероятную дипhoton-пару в каждом событии.\n  </p>\n\n  <p>\n    Ключевым компонентом подхода является гибкий <strong>дизайн кодировщика</strong>, который отображает гетерогенные объекты реконструкции в общее латентное представление. \n    Скалярные признаки комбинируются с информацией переменной длины из треков и вершин конверсии с помощью специализированных нейронных кодировщиков, включая субкодировщики на основе GNN для структурированных входных данных. \n    Это позволяет модели сохранять подробную информацию о реконструкции без преждевременного объединения или ручного суммирования.\n  </p>\n\n  <p>\n    Полученная архитектура естественным образом учитывает корреляции между кандидатами, масштабируется для событий с большим количеством объектов и устраняет необходимость в эвристической предварительной выборке пар фотонов. \n    Проект демонстрирует, как современные методы на основе графов могут лучше соответствовать основной структуре данных реконструкции HEP, оставаясь при этом совместимыми с рабочими процессами анализа ATLAS.\n  </p>\n\n  <p>\n    Эта работа была представлена несколько раз в сообществах ATLAS и HEP-ML, включая международные семинары и встречи на уровне сотрудничества, что отражает растущий интерес к подходам на основе GNN для вывода на уровне событий.\n  </p>\n\n  <!-- Embedded slides -->\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/MLColloquium2024_v3.pdf#view=FitH'\n        title='Embedded slides: Improving the diphoton event selection with GNNs'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/MLColloquium2024_v3.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <!-- Embedded poster -->\n  <div style='margin: 1.5rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 70%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/PosterAtlasWeek2024IsaiSotarriva.pdf#view=FitH'\n        title='Embedded poster: ATLAS Week 2024 – GNN Diphoton Selection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/PosterAtlasWeek2024IsaiSotarriva.pdf' target='_blank' rel='noopener noreferrer'>\n        Open poster in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://conference-indico.kek.jp/event/253/timetable/' target='_blank' rel='noopener noreferrer'>\n        ML at HEP Workshop (KEK) – Presentation timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.cern.ch/event/1355214/' target='_blank' rel='noopener noreferrer'>\n        ATLAS Week 2024 – Poster presentation (CERN)\n      </a>\n    </li>\n    <li>\n      <a href='https://onsite.gakkai-web.net/jps/jps_search/2024spe/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n        Japan Physical Society Spring Meeting 2024 – Timetable\n      </a>\n    </li>\n  </ul>\n</article>"
        }
    },
    {
        "id": 4,
        "title": {
            "en": "High-Performance Image Stitching"
        },
        "date": "2021-08-01",
        "description": {
            "en": "Developed a gradient-based image stitching algorithm optimized for reliability and ultra low memory usage on very high-resolution images (100+ megapixels).",
            "es": "Desarrollé un algoritmo de cosido de imágenes basado en gradientes optimizado para la fiabilidad y el uso ultra bajo de memoria en imágenes de muy alta resolución (más de 100 megapíxeles).",
            "fr": "Développement d'un algorithme d'assemblage d'images basé sur les gradients, optimisé pour la fiabilité et une utilisation ultra faible de la mémoire sur des images très haute résolution (plus de 100 mégapixels).",
            "ja": "非常に高解像度の画像（100メガピクセル以上）での信頼性と超低メモリ使用量に最適化された、勾配ベースの画像スティッチングアルゴリズムを開発しました。",
            "ru": "Разработан алгоритм сшивания изображений на основе градиентов, оптимизированный для надежности и ультранизкого использования памяти на очень высокоразрешающих изображениях (более 100 мегапикселей)."
        },
        "tags": [
            4,
            13,
            2,
            14,
            9
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 80
            },
            {
                "name": "C++",
                "proportion": 20
            }
        ],
        "topic": "Computer Vision",
        "image": {
            "en": "/assets/IMG_20220422_181038129_HDR.jpg"
        },
        "skills": [
            {
                "id": 10,
                "relevance": 80
            },
            {
                "id": 11,
                "relevance": 75
            },
            {
                "id": 1,
                "relevance": 30
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>Optimized Image Stitching Algorithm for ITk Pixel Module Inspection</h2>\n\n  <p>\n    This project focuses on the development and optimization of a high-precision \n    <strong>image stitching algorithm</strong> designed for the visual inspection of \n    ATLAS ITk pixel modules during large-scale production. The work was carried out \n    as part of the effort to automate wire bond quality assessment for the HL-LHC upgrade.\n  </p>\n\n  <p>\n    A single visual inspection of a pixel module consists of multiple high-resolution \n    microscope images acquired in a grid pattern. These images must be combined into \n    a single, geometrically consistent representation while preserving sub-pixel accuracy, \n    as small distortions directly affect downstream defect detection algorithms.\n  </p>\n\n  <p>\n    The stitching problem was formulated as an optimization task over a \n    <strong>homography plus translation</strong>, where transformation parameters are \n    determined by minimizing cost functions defined on overlapping image regions. \n    Several metrics were evaluated, including image-difference and feature-based \n    similarity measures, to ensure robust alignment under varying lighting conditions.\n  </p>\n\n  <p>\n    The optimized stitching pipeline produces a standardized, large-scale image with \n    a known mapping between pixel coordinates and physical module geometry. This \n    significantly simplifies both automated analysis and manual cross-checks, while \n    reducing the operational complexity of the image acquisition process.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Optimized stitching and wire bond inspection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Algoritmo optimizado de cosido de imágenes para la inspección de módulos de píxeles ITk</h2>\n\n  <p>\n    Este proyecto se centra en el desarrollo y la optimización de un \n    <strong>algoritmo de cosido de imágenes</strong> de alta precisión diseñado para \n    la inspección visual de los módulos de píxeles ITk de ATLAS durante la producción \n    a gran escala. El trabajo se llevó a cabo como parte del esfuerzo para automatizar \n    la evaluación de la calidad de los enlaces por cable para la actualización HL-LHC.\n  </p>\n\n  <p>\n    Una inspección visual única de un módulo de píxeles consta de múltiples imágenes \n    de microscopio de alta resolución adquiridas en un patrón de cuadrícula. Estas \n    imágenes deben combinarse en una representación única y geométricamente consistente \n    mientras se preserva la precisión subpíxel, ya que pequeñas distorsiones afectan \n    directamente a los algoritmos de detección de defectos posteriores.\n  </p>\n\n  <p>\n    El problema del cosido se formuló como una tarea de optimización sobre una \n    <strong>homografía más traslación</strong>, donde los parámetros de transformación \n    se determinan minimizando funciones de costo definidas en regiones superpuestas \n    de las imágenes. Se evaluaron varias métricas, incluyendo medidas de similitud \n    basadas en diferencias de imagen y características, para garantizar una alineación \n    robusta bajo condiciones de iluminación variables.\n  </p>\n\n  <p>\n    La canalización optimizada de cosido produce una imagen estandarizada a gran escala \n    con un mapeo conocido entre las coordenadas de píxeles y la geometría física del módulo. \n    Esto simplifica significativamente tanto el análisis automatizado como las verificaciones \n    manuales, al tiempo que reduce la complejidad operativa del proceso de adquisición \n    de imágenes.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Optimized stitching and wire bond inspection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>Algorithme de couture d'images optimisé pour l'inspection des modules à pixels ITk</h2>\n\n  <p>\n    Ce projet se concentre sur le développement et l'optimisation d'un \n    <strong>algorithme de couture d'images</strong> de haute précision conçu pour \n    l'inspection visuelle des modules à pixels ITk d'ATLAS lors de la production \n    à grande échelle. Le travail a été réalisé dans le cadre des efforts visant \n    à automatiser l'évaluation de la qualité des connexions filaires pour la mise \n    à niveau HL-LHC.\n  </p>\n\n  <p>\n    Une inspection visuelle unique d'un module à pixels consiste en plusieurs images \n    de microscope haute résolution acquises selon un motif en grille. Ces images \n    doivent être combinées en une représentation unique et géométriquement cohérente \n    tout en préservant une précision sous-pixel, car de petites distorsions affectent \n    directement les algorithmes de détection de défauts en aval.\n  </p>\n\n  <p>\n    Le problème de couture a été formulé comme une tâche d'optimisation sur une \n    <strong>homographie plus translation</strong>, où les paramètres de transformation \n    sont déterminés en minimisant des fonctions de coût définies sur les régions \n    d'images qui se chevauchent. Plusieurs métriques ont été évaluées, y compris \n    des mesures de similarité basées sur la différence d'image et les caractéristiques, \n    pour garantir un alignement robuste dans des conditions d'éclairage variables.\n  </p>\n\n  <p>\n    Le pipeline de couture optimisé produit une image standardisée à grande échelle \n    avec une correspondance connue entre les coordonnées des pixels et la géométrie \n    physique du module. Cela simplifie considérablement à la fois l'analyse automatisée \n    et les vérifications manuelles, tout en réduisant la complexité opérationnelle \n    du processus d'acquisition d'images.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Optimized stitching and wire bond inspection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>ITkピクセルモジュール検査のための最適化された画像スティッチングアルゴリズム</h2>\n\n  <p>\n    このプロジェクトは、HL-LHCアップグレードのためのワイヤーボンド品質評価の自動化の取り組みの一環として、\n    大規模生産中のATLAS ITkピクセルモジュールの視覚的検査のために設計された高精度な\n    <strong>画像スティッチングアルゴリズム</strong>の開発と最適化に焦点を当てています。\n  </p>\n\n  <p>\n    ピクセルモジュールの単一の視覚検査は、グリッドパターンで取得された複数の高解像度顕微鏡画像で構成されます。 \n    これらの画像は、サブピクセル精度を維持しながら、単一で幾何学的に一貫した表現に結合する必要があります。 \n    小さな歪みが下流の欠陥検出アルゴリズムに直接影響を与えるためです。\n  </p>\n\n  <p>\n    スティッチング問題は、重複する画像領域で定義されたコスト関数を最小化することによって変換パラメータが決定される\n    <strong>ホモグラフィーと平行移動</strong>に関する最適化タスクとして定式化されました。 \n    さまざまな照明条件下で堅牢な整列を確保するために、画像差分および特徴ベースの類似性測定など、いくつかの指標が評価されました。\n  </p>\n\n  <p>\n    最適化されたスティッチングパイプラインは、ピクセル座標と物理的なモジュールジオメトリとの間の既知のマッピングを備えた標準化された大規模画像を生成します。 \n    これにより、自動化された分析と手動のクロスチェックの両方が大幅に簡素化され、画像取得プロセスの運用の複雑さが軽減されます。\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Optimized stitching and wire bond inspection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022au/data2/html/programsj.html#j7pA421' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Оптимизированный алгоритм сшивания изображений для инспекции модулей пикселей ITk</h2>\n\n  <p>\n    Этот проект сосредоточен на разработке и оптимизации высокоточного \n    <strong>алгоритма сшивания изображений</strong>, предназначенного для визуальной инспекции \n    модулей пикселей ITk ATLAS в ходе крупномасштабного производства. Работа была выполнена \n    в рамках усилий по автоматизации оценки качества проводных соединений для обновления HL-LHC.\n  </p>\n\n  <p>\n    Одна визуальная инспекция модуля пикселей состоит из нескольких высокоразрешающих \n    микроскопических изображений, полученных в сетчатом узоре. Эти изображения должны быть \n    объединены в единое геометрически согласованное представление с сохранением субпиксельной \n    точности, поскольку небольшие искажения напрямую влияют на последующие алгоритмы обнаружения дефектов.\n  </p>\n\n  <p>\n    Проблема сшивания была сформулирована как задача оптимизации по \n    <strong>гомографии плюс трансляция</strong>, где параметры преобразования определяются путем минимизации \n    функций стоимости, определенных на перекрывающихся областях изображений. Были оценены несколько метрик, \n    включая меры сходства на основе разницы изображений и признаков, чтобы обеспечить надежное выравнивание при \n    различных условиях освещения.\n  </p>\n\n  <p>\n    Оптимизированный конвейер сшивания создает стандартизированное крупномасштабное изображение с известным отображением \n    между координатами пикселей и физической геометрией модуля. Это значительно упрощает как автоматический анализ, \n    так и ручные проверки, одновременно снижая операционную сложность процесса получения изображений.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Optimized stitching and wire bond inspection'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>"
        }
    },
    {
        "id": 5,
        "title": {
            "en": "Quality Control of Pixel Detector Modules",
            "es": "Control de Calidad de Módulos de Detectores de Píxeles",
            "fr": "Contrôle de Qualité des Modules de Détecteurs à Pixels",
            "ja": "ピクセル検出器モジュールの品質管理",
            "ru": "Контроль качества модулей пиксельных детекторов"
        },
        "date": "2021-12-01",
        "description": {
            "en": "Development of tools for the visual inspection and quality control of semiconductor pixel detector modules using a linetracing algorithm inspired by the Steger line detection method.",
            "es": "Desarrollo de herramientas para la inspección visual y el control de calidad de módulos de detectores de píxeles semiconductores utilizando un algoritmo de trazado de líneas inspirado en el método de detección de líneas de Steger.",
            "fr": "Développement d'outils pour l'inspection visuelle et le contrôle qualité des modules de détecteurs à pixels semi-conducteurs en utilisant un algorithme de traçage de lignes inspiré de la méthode de détection de lignes de Steger.",
            "ja": "Stegerのライン検出法に触発されたライントレーシングアルゴリズムを使用して、半導体ピクセル検出器モジュールの視覚的検査と品質管理のためのツールを開発しました。",
            "ru": "Разработка инструментов для визуального осмотра и контроля качества модулей полупроводниковых пиксельных детекторов с использованием алгоритма трассировки линий, вдохновленного методом обнаружения линий Штегера."
        },
        "tags": [
            9,
            13,
            4,
            2
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 90
            },
            {
                "name": "C++",
                "proportion": 10
            }
        ],
        "topic": "Detector Instrumentation",
        "image": {
            "en": "/assets/IMG_20210709_153623076.jpg"
        },
        "skills": [
            {
                "id": 10,
                "relevance": 80
            },
            {
                "id": 12,
                "relevance": 70
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>Modified Steger’s Algorithm with Kalman Filter for Robust Line Tracking</h2>\n\n  <p>\n    This project presents an improved <strong>line-tracking algorithm</strong> for \n    automatic wire bond inspection, based on a modified version of \n    <strong>Steger’s ridge detection method</strong> augmented with a \n    <strong>Kalman filter</strong> for stabilization. The work targets failure modes \n    observed in dense and noisy visual inspection data from ATLAS ITk pixel modules.\n  </p>\n\n  <p>\n    While Steger’s algorithm is effective at identifying line centers, it becomes \n    unstable in regions where multiple wires cross or where image quality is degraded \n    by reflections and noise. In such cases, the original linking procedure can make \n    ambiguous or inconsistent decisions about track continuation.\n  </p>\n\n  <p>\n    To address this, a Kalman filter was introduced into the linking stage, allowing \n    the algorithm to combine current measurements with predictions based on previous \n    states. The tracked state includes position, local direction, and line strength, \n    enabling smoother and more physically consistent tracking through intersections \n    and low-contrast regions.\n  </p>\n\n  <p>\n    The improved tracker enables reliable identification of broken, loose, and touching \n    wires by enforcing geometric continuity and endpoint consistency. This approach \n    substantially increases robustness while remaining computationally efficient, \n    making it suitable for large-scale automated inspection workflows.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Modified Steger algorithm with Kalman filter'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Algoritmo modificado de Steger con filtro de Kalman para trazado de líneas robusto</h2>\n\n  <p>\n    Este proyecto presenta un <strong>algoritmo de trazado de líneas</strong> mejorado \n    para la inspección automática de enlaces por cable, basado en una versión modificada \n    del <strong>método de detección de crestas de Steger</strong> aumentado con un \n    <strong>filtro de Kalman</strong> para la estabilización. El trabajo se centra en los \n    modos de falla observados en datos de inspección visual densos y ruidosos de los módulos \n    de píxeles ITk de ATLAS.\n  </p>\n\n  <p>\n    Si bien el algoritmo de Steger es efectivo para identificar los centros de las líneas, \n    se vuelve inestable en regiones donde múltiples cables se cruzan o donde la calidad \n    de la imagen se degrada por reflejos y ruido. En tales casos, el procedimiento original \n    de enlace puede tomar decisiones ambiguas o inconsistentes sobre la continuación del seguimiento.\n  </p>\n\n  <p>\n    Para abordar esto, se introdujo un filtro de Kalman en la etapa de enlace, lo que permite \n    que el algoritmo combine las mediciones actuales con predicciones basadas en estados anteriores. \n    El estado rastreado incluye posición, dirección local y fuerza de línea, lo que permite un \n    seguimiento más suave y físicamente consistente a través de intersecciones y regiones de bajo contraste.\n  </p>\n\n  <p>\n    El rastreador mejorado permite la identificación confiable de cables rotos, sueltos y tocándose al \n    hacer cumplir la continuidad geométrica y la consistencia del punto final. Este enfoque aumenta \n    sustancialmente la robustez mientras sigue siendo computacionalmente eficiente, lo que lo hace adecuado \n    para flujos de trabajo automatizados de inspección a gran escala.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Modified Steger algorithm with Kalman filter'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>Algorithme modifié de Steger avec filtre de Kalman pour le suivi robuste des lignes</h2>\n\n  <p>\n    Ce projet présente un <strong>algorithme de suivi de lignes</strong> amélioré pour \n    l'inspection automatique des connexions filaires, basé sur une version modifiée de \n    la <strong>méthode de détection de crêtes de Steger</strong> augmentée d'un \n    <strong>filtre de Kalman</strong> pour la stabilisation. Le travail cible les modes \n    de défaillance observés dans les données d'inspection visuelle denses et bruyantes \n    des modules à pixels ITk d'ATLAS.\n  </p>\n\n  <p>\n    Bien que l'algorithme de Steger soit efficace pour identifier les centres des lignes, \n    il devient instable dans les régions où plusieurs fils se croisent ou où la qualité \n    de l'image est dégradée par des réflexions et du bruit. Dans de tels cas, la procédure \n    de liaison originale peut prendre des décisions ambiguës ou incohérentes sur la \n    continuation du suivi.\n  </p>\n\n  <p>\n    Pour y remédier, un filtre de Kalman a été introduit dans l'étape de liaison, permettant \n    à l'algorithme de combiner les mesures actuelles avec des prédictions basées sur les états \n    précédents. L'état suivi comprend la position, la direction locale et la force de la ligne, \n    permettant un suivi plus fluide et physiquement cohérent à travers les intersections et les \n    régions à faible contraste.\n  </p>\n\n  <p>\n    Le traceur amélioré permet une identification fiable des fils cassés, lâches et en contact en \n    appliquant la continuité géométrique et la cohérence des points finaux. Cette approche augmente \n    considérablement la robustesse tout en restant efficace sur le plan informatique, ce qui la rend \n    adaptée aux flux de travail d'inspection automatisée à grande échelle.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Modified Steger algorithm with Kalman filter'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>ロバストなライン追跡のためのカルマンフィルターを用いた修正Stegerアルゴリズム</h2>\n\n  <p>\n    このプロジェクトでは、ATLAS ITkピクセルモジュールからの密でノイズの多い視覚検査データで観察される故障モードを対象とした、\n    <strong>Stegerのリッジ検出法</strong>の修正版に基づき、<strong>カルマンフィルター</strong>で強化された自動ワイヤーボンド検査のための\n    <strong>ライン追跡アルゴリズム</strong>を紹介します。\n  </p>\n\n  <p>\n    Stegerのアルゴリズムはライン中心の特定に効果的ですが、複数のワイヤが交差する領域や反射やノイズによって画像品質が低下する領域では不安定になります。 \n    そのような場合、元のリンク手順はトラック継続に関してあいまいまたは一貫性のない決定を下す可能性があります。\n  </p>\n\n  <p>\n    これに対処するために、リンク段階にカルマンフィルターが導入され、アルゴリズムが以前の状態に基づく予測と現在の測定値を組み合わせることができるようにしました。 \n    追跡された状態には位置、局所方向、およびライン強度が含まれ、交差点や低コントラスト領域を通じてより滑らかで物理的に一貫した追跡が可能になります。\n  </p>\n\n  <p>\n    改良されたトラッカーは、幾何学的連続性とエンドポイントの一貫性を強制することにより、切断されたワイヤー、緩んだワイヤー、および接触しているワイヤーの信頼できる識別を可能にします。 \n    このアプローチは、計算効率を維持しながら堅牢性を大幅に向上させ、大規模な自動検査ワークフローに適しています。\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Modified Steger algorithm with Kalman filter'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022au/data2/html/programsj.html#j7pA421' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Модифицированный алгоритм Штегера с фильтром Калмана для надежного отслеживания линий</h2>\n\n  <p>\n    В этом проекте представлен улучшенный <strong>алгоритм отслеживания линий</strong> для \n    автоматической инспекции проводных соединений, основанный на модифицированной версии \n    <strong>метода обнаружения гребней Штегера</strong>, дополненной \n    <strong>фильтром Калмана</strong> для стабилизации. Работа направлена на устранение \n    режимов отказа, наблюдаемых в плотных и шумных данных визуальной инспекции модулей \n    пикселей ITk ATLAS.\n  </p>\n\n  <p>\n    Хотя алгоритм Штегера эффективен для идентификации центров линий, он становится \n    нестабильным в областях, где пересекаются несколько проводов или где качество изображения \n    ухудшается из-за отражений и шума. В таких случаях исходная процедура связывания может \n    принимать неоднозначные или непоследовательные решения о продолжении отслеживания.\n  </p>\n\n  <p>\n    Для решения этой проблемы на этапе связывания был введен фильтр Калмана, позволяющий \n    алгоритму комбинировать текущие измерения с прогнозами на основе предыдущих состояний. \n    Отслеживаемое состояние включает позицию, локальное направление и силу линии, что позволяет \n    более плавное и физически согласованное отслеживание через пересечения и области с низкой контрастностью.\n  </p>\n\n  <p>\n    Улучшенный трекер позволяет надежно идентифицировать сломанные, ослабленные и соприкасающиеся провода, \n    обеспечивая геометрическую непрерывность и согласованность конечных точек. Этот подход значительно повышает \n    надежность при сохранении вычислительной эффективности, что делает его подходящим для крупномасштабных автоматизированных рабочих процессов инспекции.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/7pA421-06.pdf#view=FitH'\n        title='Embedded slides: Modified Steger algorithm with Kalman filter'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/7pA421-06.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <a href='https://onsite.gakkai-web.net/jps/jps_search/2022aue/data/html/programsj.html' target='_blank' rel='noopener noreferrer'>\n    Japan Physical Society Autumn Meeting 2022 – Program\n  </a>\n</article>"
        }
    },
    {
        "id": 6,
        "title": {
            "en": "Z-Scan Experiment and Beam Profile Modeling",
            "es": "Experimento de Z-Scan y Modelado de Perfiles de Haz",
            "fr": "Expérience de Z-Scan et Modélisation des Profils de Faisceau",
            "ja": "Zスキャン実験とビームプロファイルモデリング",
            "ru": "Эксперимент Z-сканирования и моделирование профиля луча"
        },
        "date": "2016-06-01",
        "description": {
            "en": "Experimental optics project involving Z-scan measurements of nonlinear thin films, including data acquisition and mathematical modeling of Gaussian laser beam profiles.",
            "es": "Proyecto experimental de óptica que involucra mediciones de Z-scan de películas delgadas no lineales, incluyendo adquisición de datos y modelado matemático de perfiles de haz láser gaussiano.",
            "fr": "Projet d'optique expérimentale impliquant des mesures Z-scan de films minces non linéaires, y compris l'acquisition de données et la modélisation mathématique des profils de faisceau laser gaussien.",
            "ja": "非線形薄膜のZスキャン測定を含む実験的な光学プロジェクトで、データ取得とガウスレーザービームプロファイルの数学的モデリングを含みます。",
            "ru": "Экспериментальный оптический проект, включающий измерения Z-сканирования нелинейных тонких пленок, включая сбор данных и математическое моделирование профилей гауссовского лазерного луча."
        },
        "tags": [
            1,
            5
        ],
        "languages": [
            {
                "name": "Labview",
                "proportion": 100
            }
        ],
        "topic": "Optics",
        "image": {
            "en": "/assets/zscan.jpg"
        },
        "skills": [],
        "content": {
            "en": ""
        }
    },
    {
        "id": 7,
        "title": {
            "en": "Femtoscopy with Monte Carlo Simulations",
            "es": "Femtoscopía con Simulaciones de Monte Carlo",
            "fr": "Femtoscopie avec des Simulations de Monte Carlo",
            "ja": "モンテカルロシミュレーションによるフェムトスコピー",
            "ru": "Фемтоскопия с помощью Монте-Карло симуляций"
        },
        "date": "2018-07-01",
        "description": {
            "en": "Monte Carlo study of momentum correlations in high-energy collisions using Pythia, aimed at characterizing the size and shape of the fireball created in heavy-ion collisions",
            "es": "Estudio de Monte Carlo de correlaciones de momento en colisiones de alta energía utilizando Pythia, con el objetivo de caracterizar el tamaño y la forma de la bola de fuego creada en colisiones de iones pesados.",
            "fr": "Étude de Monte Carlo des corrélations de moment dans les collisions à haute énergie utilisant Pythia, visant à caractériser la taille et la forme de la boule de feu créée dans les collisions d'ions lourds.",
            "ja": "Pythiaを使用した高エネルギー衝突における運動量相関のモンテカルロ研究で、重イオン衝突で生成されるファイアボールのサイズと形状を特徴付けることを目的としています。",
            "ru": "Исследование Монте-Карло корреляций импульсов в высокоэнергетических столкновениях с использованием Pythia, направленное на характеристику размера и формы огненного шара, созданного в столкновениях тяжелых ионов."
        },
        "tags": [
            15,
            16,
            1
        ],
        "languages": [
            {
                "name": "C++",
                "proportion": 100
            }
        ],
        "topic": "High-Energy Physics",
        "image": {
            "en": "/assets/femtoscopy.jpg"
        },
        "skills": [
            {
                "id": 4,
                "relevance": 100
            },
            {
                "id": 3,
                "relevance": 70
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>Femtoscopy in Proton–Proton Collisions at √s = 7 TeV</h2>\n\n  <p>\n    This project was carried out as my <strong>servicio social</strong> at the \n    <em>Instituto de Ciencias Nucleares (UNAM)</em> and represents my first formal \n    research experience in high-energy physics, prior to my bachelor’s thesis. \n    The work focused on <strong>femtoscopy</strong>, a technique used to probe the \n    space–time structure of particle-emitting sources in high-energy collisions.\n  </p>\n\n  <p>\n    Femtoscopy exploits <strong>Hanbury Brown–Twiss (HBT) correlations</strong> between \n    identical particles to extract characteristic length and time scales of the \n    interaction region. In this study, the method was applied to simulated \n    proton–proton collisions at √s = 7 TeV generated with <strong>Pythia 8</strong>, \n    including Bose–Einstein correlations.\n  </p>\n\n  <p>\n    The analysis was based on constructing two-particle correlation functions using \n    both <em>same-event</em> particle pairs and <em>mixed-event</em> pairs to model the \n    uncorrelated background. By studying the relative momentum distributions and their \n    dependence on transverse momentum (k<sub>T</sub>), it is possible to infer the \n    effective size and geometry of the particle-emitting source.\n  </p>\n\n  <p>\n    Special attention was given to the physical interpretation of the correlation \n    variables and to the implementation of event mixing, ensuring that the background \n    preserved single-particle kinematics while removing genuine correlations. The \n    study also explored how model parameters controlling the Bose–Einstein effect \n    influence the extracted femtoscopic radii.\n  </p>\n\n  <p>\n    The results of this work were presented at the \n    <strong>4th Annual Meeting of the ALICE Network in Mexico</strong>, held in \n    Puebla de los Ángeles, within the <em>Detectors and Phenomenology</em> session. \n    This project laid the foundation for my later work in collider physics, data \n    analysis, and detector-related studies.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Femtoscopy7TeV.pdf#view=FitH'\n        title='Embedded slides: Femtoscopy at 7 TeV'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Femtoscopy7TeV.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/timetable/#20171103' target='_blank' rel='noopener noreferrer'>\n        4th Annual ALICE Network Meeting (Mexico) – Main timetable\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/session/3/timetable.pdf' target='_blank' rel='noopener noreferrer'>\n        Detectors and Phenomenology session – Sub timetable\n      </a>\n    </li>\n  </ul>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Femtoscopía en colisiones protón-protón a √s = 7 TeV</h2>\n\n  <p>\n    Este proyecto se llevó a cabo como mi <strong>servicio social</strong> en el \n    <em>Instituto de Ciencias Nucleares (UNAM)</em> y representa mi primera experiencia \n    formal de investigación en física de altas energías, antes de mi tesis de licenciatura. \n    El trabajo se centró en la <strong>femtoscopía</strong>, una técnica utilizada para sondear \n    la estructura espacio-temporal de las fuentes emisoras de partículas en colisiones de alta energía.\n  </p>\n\n  <p>\n    La femtoscopía explota las <strong>correlaciones Hanbury Brown–Twiss (HBT)</strong> entre \n    partículas idénticas para extraer escalas características de longitud y tiempo de la \n    región de interacción. En este estudio, el método se aplicó a colisiones protón-protón \n    simuladas a √s = 7 TeV generadas con <strong>Pythia 8</strong>, incluyendo correlaciones \n    Bose–Einstein.\n  </p>\n\n  <p>\n    El análisis se basó en la construcción de funciones de correlación de dos partículas \n    utilizando pares de partículas del <em>mismo evento</em> y pares de <em>eventos mezclados</em> \n    para modelar el fondo no correlacionado. Al estudiar las distribuciones de momento relativo \n    y su dependencia del momento transversal (k<sub>T</sub>), es posible inferir el tamaño efectivo \n    y la geometría de la fuente emisora de partículas.\n  </p>\n\n  <p>\n    Se prestó especial atención a la interpretación física de las variables de correlación y a \n    la implementación de la mezcla de eventos, asegurando que el fondo preservara la cinemática \n    de partículas individuales mientras eliminaba las correlaciones genuinas. El estudio también \n    exploró cómo los parámetros del modelo que controlan el efecto Bose–Einstein influyen en los \n    radios femtoscópicos extraídos.\n  </p>\n\n  <p>\n    Los resultados de este trabajo se presentaron en la \n    <strong>4ta Reunión Anual de la Red ALICE en México</strong>, \n    celebrada en Puebla de los Ángeles, dentro de la sesión de \n    <em>Detectores y Fenomenología</em>. Este proyecto sentó las bases para mi \n    trabajo posterior en física de colisionadores, análisis de datos y estudios relacionados con detectores.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Femtoscopy7TeV.pdf#view=FitH'\n        title='Embedded slides: Femtoscopy at 7 TeV'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Femtoscopy7TeV.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/timetable/#20171103' target='_blank' rel='noopener noreferrer'>\n        4ta Reunión Anual de la Red ALICE (México) – Programa principal\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/session/3/timetable.pdf' target='_blank' rel='noopener noreferrer'>\n        Sesión de Detectores y Fenomenología – Subprograma\n      </a>\n    </li>\n  </ul>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>Femtoscopie dans les collisions proton-proton à √s = 7 TeV</h2>\n\n  <p>\n    Ce projet a été réalisé dans le cadre de mon <strong>servicio social</strong> à \n    l'<em>Instituto de Ciencias Nucleares (UNAM)</em> et représente ma première expérience \n    formelle de recherche en physique des hautes énergies, avant ma thèse de licence. \n    Le travail s'est concentré sur la <strong>femtoscopie</strong>, une technique utilisée \n    pour sonder la structure espace-temps des sources émettrices de particules dans les \n    collisions à haute énergie.\n  </p>\n\n  <p>\n    La femtoscopie exploite les <strong>corrélations Hanbury Brown–Twiss (HBT)</strong> entre \n    particules identiques pour extraire des échelles caractéristiques de longueur et de temps \n    de la région d'interaction. Dans cette étude, la méthode a été appliquée à des collisions \n    proton-proton simulées à √s = 7 TeV générées avec <strong>Pythia 8</strong>, incluant des \n    corrélations Bose–Einstein.\n  </p>\n\n  <p>\n    L'analyse était basée sur la construction de fonctions de corrélation à deux particules \n    utilisant à la fois des paires de particules du <em>même événement</em> et des paires \n    d'<em>événements mélangés</em> pour modéliser le fond non corrélé. En étudiant les \n    distributions de moment relatif et leur dépendance au moment transverse (k<sub>T</sub>), \n    il est possible d'inférer la taille effective et la géométrie de la source émettrice de particules.\n  </p>\n\n  <p>\n    Une attention particulière a été accordée à l'interprétation physique des variables de \n    corrélation et à la mise en œuvre du mélange d'événements, en veillant à ce que le fond \n    préserve la cinématique des particules individuelles tout en éliminant les corrélations \n    authentiques. L'étude a également exploré comment les paramètres du modèle contrôlant l'effet \n    Bose–Einstein influencent les rayons femtoscopiques extraits.\n  </p>\n\n  <p>\n    Les résultats de ce travail ont été présentés lors de la \n    <strong>4e réunion annuelle du réseau ALICE au Mexique</strong>, \n    tenue à Puebla de los Ángeles, dans le cadre de la session \n    <em>Détecteurs et Phénoménologie</em>. Ce projet a jeté les bases de mon \n    travail ultérieur en physique des collisionneurs, analyse de données et études liées aux détecteurs.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Femtoscopy7TeV.pdf#view=FitH'\n        title='Embedded slides: Femtoscopy at 7 TeV'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Femtoscopy7TeV.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/timetable/#20171103' target='_blank' rel='noopener noreferrer'>\n        4e réunion annuelle du réseau ALICE (Mexique) – Programme principal\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/session/3/timetable.pdf' target='_blank' rel='noopener noreferrer'>\n        Session Détecteurs et Phénoménologie – Sous-programme\n      </a>\n    </li>\n  </ul>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>√s = 7 TeVの陽子-陽子衝突におけるフェムトスコピー</h2>\n\n  <p>\n    このプロジェクトは、<em>Instituto de Ciencias Nucleares (UNAM)</em>での<strong>servicio social</strong>として実施され、\n    学士論文の前に高エネルギー物理学での最初の正式な研究経験を表しています。 \n    この作業は、高エネルギー衝突における粒子放出源の時空構造を調査するために使用される技術である<strong>フェムトスコピー</strong>に焦点を当てました。\n  </p>\n\n  <p>\n    フェムトスコピーは、同一粒子間の<strong>Hanbury Brown–Twiss (HBT)相関</strong>を利用して、\n    相互作用領域の特徴的な長さと時間のスケールを抽出します。 \n    この研究では、Bose–Einstein相関を含む<strong>Pythia 8</strong>で生成された√s = 7 TeVのシミュレートされた陽子-陽子衝突にこの方法が適用されました。\n  </p>\n\n  <p>\n    分析は、<em>同一イベント</em>粒子ペアと<em>混合イベント</em>ペアの両方を使用して二粒子相関関数を構築し、\n    非相関背景をモデル化することに基づいていました。 \n    相対運動量分布とその横運動量(k<sub>T</sub>)への依存性を研究することにより、\n    粒子放出源の有効サイズとジオメトリを推測することが可能です。\n  </p>\n\n  <p>\n    相関変数の物理的解釈とイベントミキシングの実装に特別な注意が払われ、\n    背景が本物の相関を除去しながら単一粒子の運動学を保存することが保証されました。 \n    また、Bose–Einstein効果を制御するモデルパラメータが抽出されたフェムトスコピー半径にどのように影響するかも探求しました。\n  </p>\n\n  <p>\n    この作業の結果は、プエブラ・デ・ロス・アンヘレスで開催された<strong>メキシコのALICEネットワーク第4回年次会議</strong>で、\n    <em>検出器と現象論</em>セッション内で発表されました。 \n    このプロジェクトは、後のコライダー物理学、データ分析、および検出器関連の研究の基礎を築きました。\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Femtoscopy7TeV.pdf#view=FitH'\n        title='Embedded slides: Femtoscopy at 7 TeV'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Femtoscopy7TeV.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/timetable/#20171103' target='_blank' rel='noopener noreferrer'>\n        メキシコのALICEネットワーク第4回年次会議 – メインタイムテーブル\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/session/3/timetable.pdf' target='_blank' rel='noopener noreferrer'>\n        検出器と現象論セッション – サブタイムテーブル\n      </a>\n    </li>\n  </ul>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Фемтоскопия в протон-протонных столкновениях при √s = 7 ТэВ</h2>\n\n  <p>\n    Этот проект был выполнен в рамках моего <strong>servicio social</strong> в \n    <em>Instituto de Ciencias Nucleares (UNAM)</em> и представляет собой мой первый \n    официальный исследовательский опыт в области физики высоких энергий до моей \n    бакалаврской работы. Работа была сосредоточена на <strong>фемтоскопии</strong>, \n    технике, используемой для изучения пространственно-временной структуры источников \n    излучающих частицы в столкновениях высоких энергий.\n  </p>\n\n  <p>\n    Фемтоскопия использует <strong>корреляции Ханбери Брауна–Твисса (HBT)</strong> между \n    идентичными частицами для извлечения характерных масштабов длины и времени \n    области взаимодействия. В этом исследовании метод был применен к смоделированным \n    протон-протонным столкновениям при √s = 7 ТэВ, сгенерированным с помощью \n    <strong>Pythia 8</strong>, включая корреляции Бозе–Эйнштейна.\n  </p>\n\n  <p>\n    Анализ основывался на построении двухчастичных корреляционных функций с использованием \n    как пар частиц из <em>одного события</em>, так и пар из <em>смешанных событий</em> для \n    моделирования некоррелированного фона. Изучая распределения относительного импульса \n    и их зависимость от поперечного импульса (k<sub>T</sub>), можно сделать вывод о \n    эффективном размере и геометрии источника излучающих частицы.\n  </p>\n\n  <p>\n    Особое внимание уделялось физической интерпретации корреляционных переменных и \n    реализации смешивания событий, обеспечивая сохранение кинематики отдельных частиц \n    фоном при удалении истинных корреляций. Исследование также изучало, как параметры \n    модели, контролирующие эффект Бозе–Эйнштейна, влияют на извлеченные фемтоскопические радиусы.\n  </p>\n\n  <p>\n    Результаты этой работы были представлены на \n    <strong>4-й ежегодной встрече сети ALICE в Мексике</strong>, \n    которая проходила в Пуэбла-де-лос-Анджелес, в рамках сессии \n    <em>Детекторы и феноменология</em>. Этот проект заложил основу для моей \n    дальнейшей работы в области физики коллайдеров, анализа данных и исследований, связанных с детекторами.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Femtoscopy7TeV.pdf#view=FitH'\n        title='Embedded slides: Femtoscopy at 7 TeV'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Femtoscopy7TeV.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/timetable/#20171103' target='_blank' rel='noopener noreferrer'>\n        4-я ежегодная встреча сети ALICE (Мексика) – Основное расписание\n      </a>\n    </li>\n    <li>\n      <a href='https://indico.nucleares.unam.mx/event/1325/session/3/timetable.pdf' target='_blank' rel='noopener noreferrer'>\n        Сессия Детекторы и феноменология – Подрасписание\n      </a>\n    </li>\n  </ul>\n</article>"
        }
    },
    {
        "id": 8,
        "title": {
            "en": "Estimation of the number of multiparton interactions on pp collisions at ALICE using TMVA ROOT",
            "es": "Estimación del número de interacciones multiparton en colisiones pp en ALICE utilizando TMVA ROOT",
            "fr": "Estimation du nombre d'interactions multiparton dans les collisions pp à ALICE en utilisant TMVA ROOT",
            "ja": "TMVA ROOTを使用したALICEでのpp衝突におけるマルチパートン相互作用の数の推定",
            "ru": "Оценка количества мультипартонных взаимодействий в pp столкновениях на ALICE с использованием TMVA ROOT"
        },
        "date": "2019-10-01",
        "description": {
            "en": "Bachelor’s thesis project using ROOT TMVA to perform feature ranking, decorrelation, and comparison of multiple machine learning models for regression and classification tasks.",
            "es": "Proyecto de tesis de licenciatura utilizando ROOT TMVA para realizar clasificación de características, decorrelación y comparación de múltiples modelos de aprendizaje automático para tareas de regresión y clasificación.",
            "fr": "Projet de mémoire de licence utilisant ROOT TMVA pour effectuer le classement des caractéristiques, la décorrélation et la comparaison de plusieurs modèles d'apprentissage automatique pour les tâches de régression et de classification.",
            "ja": "回帰および分類タスクのための特徴ランキング、デコレーション、および複数の機械学習モデルの比較を実行するためにROOT TMVAを使用した学士論文プロジェクト。",
            "ru": "Проект бакалаврской работы с использованием ROOT TMVA для выполнения ранжирования признаков, декорреляции и сравнения нескольких моделей машинного обучения для задач регрессии и классификации."
        },
        "tags": [
            3,
            1,
            16,
            10,
            6
        ],
        "languages": [
            {
                "name": "C++",
                "proportion": 100
            }
        ],
        "topic": "High-Energy Physics",
        "image": {
            "en": "/assets/covarianceMatrix.jpg"
        },
        "skills": [
            {
                "id": 13,
                "relevance": 70
            },
            {
                "id": 7,
                "relevance": 75
            },
            {
                "id": 3,
                "relevance": 60
            },
            {
                "id": 4,
                "relevance": 50
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n<h2>Machine learning classification and regression of multiparton interactions in pp collisions — Bachelor’s project</h2>\n\n<p>\nThis bachelor’s project developed machine‑learning (ML) methods to estimate how many multiparton interactions (MPI) occurred in individual proton–proton (pp) collision events recorded by ALICE. The work was motivated by an observed excess of particle activity in the transverse region of pp events, a feature that prompted debate: some groups proposed tiny droplets of quark–gluon plasma, while our lab championed an explanation based on multiparton interactions combined with color reconnection during hadronization. The goal here was to move beyond qualitative arguments and build an event‑by‑event estimator of MPI using only detector‑level observables.\n</p>\n\n<h3>Context and motivation (non‑expert friendly)</h3>\n<p>\nIn each collision the detector records many particles. MPI are multiple scatterings between constituent partons (quarks and gluons) inside the protons that can increase particle activity in an event. In simulated events you can set the number of MPI, but in real data MPI occur before the particles are formed and are not directly observable — they must be inferred from quantities the detector measures.\n</p>\n<p>\nTwo observables strongly correlated with MPI are:\n<ul>\n<li><strong>Multiplicity</strong>: how many particles the detector sees in the event.</li>\n<li><strong>Spherocity</strong>: how uniformly particle momenta are distributed (0 = jet‑like, 1 = isotropic/spherical).</li>\n</ul>\nHistorically, analyses used a simple rectangular cut in multiplicity and spherocity to separate high‑MPI from low‑MPI events; this is easy but coarse and only gives a binary label (high/low), not the actual MPI count.\n</p>\n\n<h3>Project goals</h3>\n<ul>\n<li>Select and preprocess detector‑level features informative about MPI.</li>\n<li>Rank and decorrelate features (ROOT/TMVA) to remove redundant information.</li>\n<li>Train and compare classifiers to separate high‑MPI from low‑MPI events.</li>\n<li>Find an optimal working point and compare ML selection with the traditional spherocity×multiplicity cut.</li>\n<li>Perform regression to predict the actual number of MPI per event (novel for this analysis).</li>\n</ul>\n\n<h3>Data and training strategy</h3>\n<p>\nTraining and testing used dedicated Monte Carlo productions to mimic ALICE detector conditions. For the NMPI (number of MPI) work the classifiers were trained using the LHC18f1 sample anchored to LHC16k, and testing was performed on LHC15g3c3 — this separation helps evaluate model generalization to independent samples [machine_learningfin1.pdf].\n</p>\n\n<h3>Feature selection and preprocessing</h3>\n<p>\nAfter reconstruction, a set of candidate observables was prepared (examples: multiplicity, spherocity, average pT, sphericity, recoil, leading pT). ROOT/TMVA ranking was used to determine which variables had the most discrimination power. A covariance / decorrelation step removed variables that were only useful because they were correlated with stronger variables; the result was a compact set of orthogonal, informative features that improved model stability and reduced overfitting.\n</p>\n\n<h3>Models trained and rationale</h3>\n<p>\nMultiple methods were compared, including boosted decision trees (BDT), multilayer perceptrons (MLP), and linear discriminants. Linear methods can fail when the separation boundary is nonlinear; tree‑based and neural methods (BDT, MLP) performed better for this problem. Models were trained on MC truth labels (high/low MPI for classification and numeric MPI for regression) and evaluated on independent test samples [machine_learningfin1.pdf].\n</p>\n\n<h3>Evaluation and results</h3>\n<p>\nClassifier performance was summarized with signal efficiency vs background rejection curves. ML‑based selections improved separation power compared with the simple spherocity×multiplicity cut, providing better control of purity and efficiency. Most notably, regression models produced continuous estimates of the number of MPI per event — a capability not previously available in this analysis chain and useful for quantitative model‑data comparisons.\n</p>\n\n<h3>Novelty and impact</h3>\n<p>\nThe key novelty is event‑by‑event regression of MPI counts using detector observables. This enables direct, quantitative tests of competing explanations for the transverse‑region activity (e.g., MPI+color reconnection vs. QGP hypotheses) and can be used to correlate MPI estimates with other observables. The feature‑ranking and decorrelation workflow plus the TMVA training/evaluation process is also broadly applicable to other situations where a latent (unobserved) quantity must be inferred from measured data [machine_learningfin1.pdf].\n</p>\n\n<div style='margin: 1rem 0; max-width: 900px;'>\n<div style='width: 100%; padding-top: 56%; position:relative; border: 1px solid #ddd; border-radius: 6px; overflow:hidden;'>\n<iframe\nsrc='/assets/machine_learningfin1.pdf#view=FitH'\ntitle='Embedded slides: Machine learning applied to event classification'\nstyle='position:absolute; top:0; left:0; width:100%; height:100%; border:0;'\nallowfullscreen>\n</iframe>\n</div>\n<p style='font-size:0.9rem; margin:0.5rem 0 0;'>\n<a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Open slides in a new tab</a>\n</p>\n</div>\n\n<h3>Files and links</h3>\n<ul>\n<li><a href='https://tesiunamdocumentos.dgb.unam.mx/ptd2019/septiembre/0796038/Index.html' target='_blank' rel='noopener noreferrer'>Full bachelor’s thesis</a></li>\n<li><a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Presentation slides (embedded above)</a></li>\n</ul>\n\n</article>",
            "es": "</article class='project-article'>\n<h2>Clasificación y regresión de interacciones multiparton en colisiones pp mediante aprendizaje automático — Proyecto de licenciatura</h2>\n\n<p>\nEste proyecto de licenciatura desarrolló métodos de aprendizaje automático (ML) para estimar cuántas interacciones multiparton (MPI) ocurrieron en eventos individuales de colisiones protón-protón (pp) registrados por ALICE. El trabajo fue motivado por un exceso observado de actividad de partículas en la región transversal de los eventos pp, una característica que generó debate: algunos grupos propusieron pequeñas gotas de plasma de quarks y gluones, mientras que nuestro laboratorio defendió una explicación basada en interacciones multiparton combinadas con reconexión de color durante la hadronización. El objetivo aquí era ir más allá de los argumentos cualitativos y construir un estimador de MPI evento por evento utilizando solo observables a nivel del detector.\n</p>\n\n<h3>Contexto y motivación (amigable para no expertos)</h3>\n<p>\nEn cada colisión, el detector registra muchas partículas. Las MPI son múltiples dispersaciones entre los partones constituyentes (quarks y gluones) dentro de los protones que pueden aumentar la actividad de partículas en un evento. En eventos simulados, se puede establecer el número de MPI, pero en datos reales las MPI ocurren antes de que se formen las partículas y no son directamente observables; deben inferirse a partir de las cantidades que mide el detector.\n</p>\n<p>\nDos observables fuertemente correlacionados con las MPI son:\n<ul>\n<li><strong>Multiplicidad</strong>: cuántas partículas ve el detector en el evento.</li>\n<li><strong>Sfericidad</strong>: qué tan uniformemente están distribuidos los momentos de las partículas (0 = tipo chorro, 1 = isotrópico/esférico).</li>\n</ul>\nHistóricamente, los análisis usaban un corte rectangular simple en multiplicidad y sfericidad para separar eventos de alta MPI de baja MPI; esto es fácil pero tosco y solo da una etiqueta binaria (alto/bajo), no el recuento real de MPI.\n</p>\n\n<h3>Objetivos del proyecto</h3>\n<ul>\n<li>Seleccionar y preprocesar características a nivel del detector informativas sobre las MPI.</li>\n<li>Clasificar y decorrelacionar características (ROOT/TMVA) para eliminar información redundante.</li>\n<li>Entrenar y comparar clasificadores para separar eventos de alta MPI de baja MPI.</li>\n<li>Encontrar un punto de trabajo óptimo y comparar la selección ML con el corte tradicional de sfericidad×multiplicidad.</li>\n<li>Realizar regresión para predecir el número real de MPI por evento (novedad para este análisis).</li>\n</ul>\n\n<h3>Datos y estrategia de entrenamiento</h3>\n<p>\nEl entrenamiento y la prueba utilizaron producciones dedicadas de Monte Carlo para imitar las condiciones del detector ALICE. Para el trabajo NMPI (número de MPI), los clasificadores se entrenaron utilizando la muestra LHC18f1 anclada a LHC16k, y las pruebas se realizaron en LHC15g3c3; esta separación ayuda a evaluar la generalización del modelo a muestras independientes [machine_learningfin1.pdf].\n</p>\n\n<h3>Selección y preprocesamiento de características</h3>\n<p>\nDespués de la reconstrucción, se preparó un conjunto de observables candidatos (ejemplos: multiplicidad, sfericidad, pT promedio, esfericidad, retroceso, pT líder). Se utilizó la clasificación ROOT/TMVA para determinar qué variables tenían el mayor poder de discriminación. Un paso de covarianza/decorrelación eliminó variables que solo eran útiles porque estaban correlacionadas con variables más fuertes; el resultado fue un conjunto compacto de características ortogonales e informativas que mejoraron la estabilidad del modelo y redujeron el sobreajuste.\n</p>\n\n<h3>Modelos entrenados y justificación</h3>\n<p>\nSe compararon múltiples métodos, incluidos árboles de decisión potenciados (BDT), perceptrones multicapa (MLP) y discriminantes lineales. Los métodos lineales pueden fallar cuando el límite de separación es no lineal; los métodos basados en árboles y neuronales (BDT, MLP) funcionaron mejor para este problema. Los modelos se entrenaron con etiquetas de verdad de MC (alto/bajo MPI para clasificación y MPI numérico para regresión) y se evaluaron en muestras de prueba independientes [machine_learningfin1.pdf].\n</p>\n\n<h3>Evaluación y resultados</h3>\n<p>\nEl rendimiento del clasificador se resumió con curvas de eficiencia de señal frente a rechazo de fondo. Las selecciones basadas en ML mejoraron el poder de separación en comparación con el simple corte de sfericidad×multiplicidad, proporcionando un mejor control de la pureza y la eficiencia. Lo más notable es que los modelos de regresión produjeron estimaciones continuas del número de MPI por evento, una capacidad que no estaba disponible anteriormente en esta cadena de análisis y útil para comparaciones cuantitativas modelo-datos.\n</p>\n\n<h3>Novedad e impacto</h3>\n<p>\nLa novedad clave es la regresión de MPI evento por evento utilizando observables medidos por el detector. Esto permite pruebas directas y cuantitativas de explicaciones en competencia para la actividad en la región transversal (por ejemplo, MPI+reconexión de color vs. hipótesis QGP) y se puede usar para correlacionar estimaciones de MPI con otros observables. El flujo de trabajo de clasificación y decorrelación de características, junto con el proceso de entrenamiento/evaluación TMVA, también es ampliamente aplicable a otras situaciones donde una cantidad latente (no observada) debe inferirse a partir de datos medidos [machine_learningfin1.pdf].\n</p>\n\n<div style='margin: 1rem 0; max-width: 900px;'>\n<div style='width: 100%; padding-top: 56%; position:relative; border: 1px solid #ddd; border-radius: 6px; overflow:hidden;'>\n<iframe\nsrc='/assets/machine_learningfin1.pdf#view=FitH'\ntitle='Embedded slides: Machine learning applied to event classification'\nstyle='position:absolute; top:0; left:0; width:100%; height:100%; border:0;'\nallowfullscreen>\n</iframe>\n</div>\n<p style='font-size:0.9rem; margin:0.5rem 0 0;'>\n<a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Open slides in a new tab</a>\n</p>\n</div>\n\n<h3>Archivos y enlaces</h3>\n<ul>\n<li><a href='https://tesiunamdocumentos.dgb.unam.mx/ptd2019/septiembre/0796038/Index.html' target='_blank' rel='noopener noreferrer'>Tesis completa de licenciatura</a></li>\n<li><a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Diapositivas de la presentación (incrustadas arriba)</a></li>\n</ul>\n\n</article>",
            "ja": "</article class='project-article'>\n<h2>多重パートン相互作用の機械学習による分類と回帰 — 学士プロジェクト</h2>\n\n<p>\nこの学士プロジェクトでは、ALICEによって記録された個々の陽子-陽子（pp）衝突イベントで発生した多重パートン相互作用（MPI）の数を推定するために、機械学習（ML）手法を開発しました。この研究は、ppイベントの横断領域で観測された粒子活動の過剰に動機付けられました。この特徴は議論を引き起こし、一部のグループはクォーク-グルーオンプラズマの小さな滴を提案しましたが、私たちの研究室はハドロニゼーション中のカラー再結合と組み合わせた多重パートン相互作用に基づく説明を支持しました。ここでの目標は、定性的な議論を超えて、検出器レベルの観測値のみを使用してイベントごとのMPI推定器を構築することでした。\n</p>\n\n<h3>コンテキストと動機（非専門家向け）</h3>\n<p>\n各衝突で、検出器は多くの粒子を記録します。MPIは、陽子内の構成パートン（クォークとグルーオン）間の複数の散乱であり、イベント内の粒子活動を増加させる可能性があります。シミュレートされたイベントではMPIの数を設定できますが、実際のデータではMPIは粒子が形成される前に発生し、直接観測できません。測定された量から推測する必要があります。\n</p>\n<p>\nMPIと強く相関する2つの観測値は次のとおりです。\n<ul>\n<li><strong>多重度</strong>：検出器がイベントで見る粒子の数。</li>\n<li><strong>球状度</strong>：粒子運動量がどれだけ均一に分布しているか（0 = ジェット状、1 = 等方的/球状）。</li>\n</ul>\n歴史的に、分析では、多重度と球状度の単純な長方形カットを使用して、高MPIイベントと低MPIイベントを分離してきました。これは簡単ですが粗く、高/低の2値ラベルしか提供せず、実際のMPIカウントは提供しません。\n</p>\n\n<h3>プロジェクトの目標</h3>\n<ul>\n<li>MPIに関する情報を提供する検出器レベルの特徴を選択および前処理します。</li>\n<li>特徴をランク付けおよびデコレート（ROOT/TMVA）して、冗長な情報を削除します。</li>\n<li>高MPIと低MPIイベントを分離するために分類器をトレーニングおよび比較します。</li>\n<li>最適な動作点を見つけ、従来の球状度×多重度カットとML選択を比較します。</li>\n<li>イベントごとの実際のMPI数を予測するために回帰を実行します（この分析では新しい）。</li>\n</ul>\n\n<h3>データとトレーニング戦略</h3>\n<p>\nトレーニングとテストには、ALICE検出器の条件を模倣するために専用のモンテカルロプロダクションが使用されました。NMPI（MPIの数）作業では、分類器はLHC18f1サンプルをLHC16kに固定してトレーニングされ、LHC15g3c3でテストが実行されました。この分離は、独立したサンプルへのモデルの一般化を評価するのに役立ちます[ machine_learningfin1.pdf ]。\n</p>\n\n<h3>特徴選択と前処理</h3>\n<p>\n再構築後、候補となる観測値のセットが準備されました（例：多重度、球状度、平均pT、球状性、反動、リーディングpT）。ROOT/TMVAランキングを使用して、どの変数が最も識別力を持っているかを判断しました。共分散/デコレーションステップにより、より強力な変数と相関しているためにのみ有用である変数が削除され、モデルの安定性が向上し、過学習が減少した、直交する情報豊富なコンパクトな特徴セットが得られました。\n</p>\n\n<h3>トレーニングされたモデルとその根拠</h3>\n<p>\nブースト決定木（BDT）、多層パーセプトロン（MLP）、線形識別子など、複数の方法が比較されました。分離境界が非線形の場合、線形手法は失敗する可能性があります。ツリーベースおよびニューラル手法（BDT、MLP）はこの問題でより良いパフォーマンスを発揮しました。モデルはMC真実ラベル（分類の高/低MPIおよび回帰の数値MPI）を使用してトレーニングされ、独立したテストサンプルで評価されました[ machine_learningfin1.pdf ]。\n</p>\n\n<h3>評価と結果</h3>\n<p>\n分類器のパフォーマンスは、信号効率対バックグラウンド拒否曲線で要約されました。MLベースの選択は、単純な球状度×多重度カットと比較して分離力を向上させ、純度と効率のより良い制御を提供しました。特に、回帰モデルはイベントごとのMPI数の連続的な推定を生成しました。これは、この分析チェーンでは以前は利用できなかった機能であり、定量的なモデル-データ比較に役立ちます。\n</p>\n\n<h3>新規性と影響</h3>\n<p>\n重要な新規性は、検出器の観測値を使用したイベントごとのMPI回帰です。これにより、横断領域の活動に対する競合する説明（例：MPI +カラー再結合対QGP仮説）の直接的かつ定量的なテストが可能になり、MPI推定値を他の観測値と相関させるために使用できます。特徴ランキングとデコレーションのワークフローとTMVAトレーニング/評価プロセスも、測定データから潜在的（観測されていない）量を推測する必要がある他の状況に広く適用できます[ machine_learningfin1.pdf ]。\n</p>\n\n<div style='margin: 1rem 0; max-width: 900px;'>\n<div style='width: 100%; padding-top: 56%; position:relative; border: 1px solid #ddd; border-radius: 6px; overflow:hidden;'>\n<iframe\nsrc='/assets/machine_learningfin1.pdf#view=FitH'\ntitle='Embedded slides: Machine learning applied to event classification'\nstyle='position:absolute; top:0; left:0; width:100%; height:100%; border:0;'\nallowfullscreen>\n</iframe>\n</div>\n<p style='font-size:0.9rem; margin:0.5rem 0 0;'>\n<a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Open slides in a new tab</a>\n</p>\n</div>\n\n<h3>ファイルとリンク</h3>\n<ul>\n<li><a href='https://tesiunamdocumentos.dgb.unam.mx/ptd2019/septiembre/0796038/Index.html' target='_blank' rel='noopener noreferrer'>完全な学士論文</a></li>\n<li><a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>プレゼンテーションスライド（上に埋め込まれています）</a></li>\n</ul>\n\n</article>",
            "ru": "</article class='project-article'>\n<h2>Классификация и регрессия мультипартонных взаимодействий в pp столкновениях с помощью машинного обучения — бакалаврский проект</h2>\n\n<p>\nЭтот бакалаврский проект разработал методы машинного обучения (ML) для оценки количества мультипартонных взаимодействий (MPI), произошедших в отдельных событиях столкновений протон-протон (pp), зарегистрированных ALICE. Работа была мотивирована наблюдаемым избытком активности частиц в поперечной области событий pp, что вызвало дебаты: некоторые группы предложили крошечные капли кварк-глюонной плазмы, в то время как наша лаборатория выступала за объяснение, основанное на мультипартонных взаимодействиях в сочетании с цветовой рекомбинацией во время адронизации. Целью здесь было выйти за рамки качественных аргументов и построить оценщик MPI для каждого события, используя только наблюдаемые величины на уровне детектора.\n</p>\n\n<h3>Контекст и мотивация (дружелюбно для неспециалистов)</h3>\n<p>\nВ каждом столкновении детектор регистрирует множество частиц. MPI — это множественные рассеяния между составными партономи (кварками и глюонами) внутри протонов, которые могут увеличить активность частиц в событии. В смоделированных событиях можно задать количество MPI, но в реальных данных MPI происходят до формирования частиц и не могут быть непосредственно наблюдаемы — их необходимо выводить из величин, измеряемых детектором.\n</p>\n<p>\nДва наблюдаемых параметра, сильно коррелирующих с MPI:\n<ul>\n<li><strong>Мультипликативность</strong>: сколько частиц видит детектор в событии.</li>\n<li><strong>Сферичность</strong>: насколько равномерно распределены импульсы частиц (0 = струйный, 1 = изотропный/сферический).</li>\n</ul>\nИсторически анализы использовали простое прямоугольное отсечение по мультипликативности и сферичности для разделения событий с высоким и низким MPI; это просто, но грубо и дает только двоичную метку (высокий/низкий), а не фактическое количество MPI.\n</p>\n\n<h3>Цели проекта</h3>\n<ul>\n<li>Выбрать и предварительно обработать информативные о MPI признаки на уровне детектора.</li>\n<li>Ранжировать и декоррелировать признаки (ROOT/TMVA) для удаления избыточной информации.</li>\n<li>Обучить и сравнить классификаторы для разделения событий с высоким и низким MPI.</li>\n<li>Найти оптимальную рабочую точку и сравнить выбор ML с традиционным отсечением по сферичности× мультипликативности.</li>\n<li>Выполнить регрессию для прогнозирования фактического количества MPI на событие (новинка для этого анализа).</li>\n</ul>\n\n<h3>Данные и стратегия обучения</h3>\n<p>\nОбучение и тестирование использовали специализированные производства Монте-Карло для имитации условий детектора ALICE. Для работы NMPI (число MPI) классификаторы обучались с использованием выборки LHC18f1, привязанной к LHC16k, а тестирование проводилось на LHC15g3c3 — это разделение помогает оценить обобщение модели на независимые выборки [ machine_learningfin1.pdf ].\n</p>\n\n<h3>Выбор и предварительная обработка признаков</h3>\n<p>\nПосле реконструкции был подготовлен набор кандидатных наблюдаемых величин (примеры: мультипликативность, сферичность, средний pT, сферичность, отдача, ведущий pT). Для определения того, какие переменные обладают наибольшей дискриминационной способностью, использовался рейтинг ROOT/TMVA. Шаг ковариации/декорреляции удалил переменные, которые были полезны только потому, что они были скоррелированы с более сильными переменными; в результате получился компактный набор ортогональных информативных признаков, которые улучшили стабильность модели и уменьшили переобучение.\n</p>\n\n<h3>Обученные модели и обоснование</h3>\n<p>\nБыло сравнено несколько методов, включая бустинг деревьев решений (BDT), многослойные персептроны (MLP) и линейные дискриминанты. Линейные методы могут не справляться, когда граница разделения нелинейна; методы на основе деревьев и нейронные сети (BDT, MLP) показали лучшие результаты для этой задачи. Модели обучались на истинных метках MC (высокий/низкий MPI для классиикации и числовой MPI для регрессии) и оценивались на независимых тестовых выборках [ machine_learningfin1.pdf ].\n</p>\n\n<h3>Оценка и результаты</h3>\n<p>\nПроизводительность классификатора была обобщена с помощью кривых эффективности сигнала против отклонения фона. Выбор на основе ML улучшил способность к разделению по сравнению с простым отсечением по сферичности×мультипликативности, обеспечивая лучший контроль чистоты и эффективности. Особенно примечательно, что регрессионные модели дали непрерывные оценки количества MPI на событие —возможность, которая ранее не была доступна в этой цепочке анализа и полезна для количественных сравнений модель-данные.\n</p>\n\n<h3>Новизна и влияние</h3>\n<p>\nКлючевая новизна заключается в регрессии MPI на событие с использованием измеренных детектором наблюдаемых величин. Это позволяет проводить прямые и количественные тесты конкурирующих объяснений активности в поперечной области (например, MPI+цветовая рекомбинация против гипотезы QGP) и может использоваться для корреляции оценок MPI с другими наблюдаемыми величинами. Рабочий процесс ранжирования и декорреляции признаков вместе с процессом обучения/оценки TMVA также широко применимы в других ситуациях, когда скрытую (ненаблюдаемую) величину необходимо вывести из измеренных данных [ machine_learningfin1.pdf ].\n</p>\n\n<div style='margin: 1rem 0; max-width: 900px;'>\n<div style='width: 100%; padding-top: 56%; position:relative; border: 1px solid #ddd; border-radius: 6px; overflow:hidden;'>\n<iframe\nsrc='/assets/machine_learningfin1.pdf#view=FitH'\ntitle='Embedded slides: Machine learning applied to event classification'\nstyle='position:absolute; top:0; left:0; width:100%; height:100%; border:0;'\nallowfullscreen>\n</iframe>\n</div>\n<p style='font-size:0.9rem; margin:0.5rem 0 0;'>\n<a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Open slides in a new tab</a>\n</p>\n</div>\n\n<h3>Файлы и ссылки</h3>\n<ul>\n<li><a href='https://tesiunamdocumentos.dgb.unam.mx/ptd2019/septiembre/0796038/Index.html' target='_blank' rel='noopener noreferrer'>Полная бакалаврская диссертация</a></li>\n<li><a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Слайды презентации (встроены выше)</a></li>\n</ul>\n\n</article>",
            "fr": "</article class='project-article'>\n<h2>Classification et régression des interactions multipartites dans les collisions pp à l'aide de l'apprentissage automatique — Projet de licence</h2>\n\n<p>\nCe projet de licence a développé des méthodes d'apprentissage automatique (ML) pour estimer le nombre d'interactions multipartites (MPI) survenues dans des événements individuels de collisions proton-proton (pp) enregistrés par ALICE. Le travail a été motivé par un excès observé d'activité des particules dans la région transversale des événements pp, une caractéristique qui a suscité des débats : certains groupes ont proposé de petites gouttes de plasma quark-gluon, tandis que notre laboratoire défendait une explication basée sur les interactions multipartites combinées à la recombinaison de couleur lors de l'hadronisation. L'objectif ici était d'aller au-delà des arguments qualitatifs et de construire un estimateur MPI événement par événement en utilisant uniquement des observables au niveau du détecteur.\n</p>\n\n<h3>Contexte et motivation (convivial pour les non-experts)</h3>\n<p>\nLors de chaque collision, le détecteur enregistre de nombreuses particules. Les MPI sont des dispersions multiples entre les partons constitutifs (quarks et gluons) à l'intérieur des protons qui peuvent augmenter l'activité des particules dans un événement. Dans les événements simulés, le nombre de MPI peut être défini, mais dans les données réelles, les MPI se produisent avant la formation des particules et ne sont pas directement observables ; elles doivent être inférées à partir des quantités mesurées par le détecteur.\n</p>\n<p>\nDeux observables fortement corrélées aux MPI sont :\n<ul>\n<li><strong>Multiplicité</strong> : combien de particules le détecteur voit dans l'événement.</li>\n<li><strong>Sphéricité</strong> : à quel point les moments des particules sont uniformément distribués (0 = type jet, 1 = isotropique/sphérique).</li>\n</ul>\nHistoriquement, les analyses utilisaient une simple coupure rectangulaire sur la multiplicité et la sphéricité pour séparer les événements à haute MPI des événements à basse MPI ; c'est facile mais grossier et ne donne qu'une étiquette binaire (haut/bas), pas le décompte réel des MPI.\n</p>\n\n<h3>Objectifs du projet</h3>\n<ul>\n<li>Sélectionner et prétraiter des caractéristiques au niveau du détecteur informatives sur les MPI.</li>\n<li>Classer et décorréler les caractéristiques (ROOT/TMVA) pour éliminer les informations redondantes.</li>\n<li>Former et comparer des classificateurs pour séparer les événements à haute MPI des événements à basse MPI.</li>\n<li>Trouver un point de fonctionnement optimal et comparer la sélection ML avec la coupure traditionnelle de sphéricité×multiplicité.</li>\n<li>Effectuer une régression pour prédire le nombre réel de MPI par événement (nouveauté pour cette analyse).</li>\n</ul>\n\n<h3>Données et stratégie de formation</h3>\n<p>\nLa formation et le test ont utilisé des productions Monte Carlo dédiées pour imiter les conditions du détecteur ALICE. Pour le travail NMPI (nombre de MPI), les classificateurs ont été formés en utilisant l'échantillon LHC18f1 ancré à LHC16k, et les tests ont été effectués sur LHC15g3c3 — cette séparation aide à évaluer la généralisation du modèle sur des échantillons indépendants [ machine_learningfin1.pdf ].\n</p>\n\n<h3>Sélection et prétraitement des caractéristiques</h3>\n<p>\nAprès la reconstruction, un ensemble de quantités observables candidates a été préparé (exemples : multiplicité, sphéricité, pT moyen, sphéricité, recul, pT principal). Le classement ROOT/TMVA a été utilisé pour déterminer quelles variables avaient le plus de pouvoir discriminant. L'étape de covariance/décorrélation a supprimé les variables qui n'étaient utiles que parce qu'elles étaient corrélées à des variables plus fortes ; le résultat était un ensemble compact de caractéristiques informatives orthogonales qui ont amélioré la stabilité du modèle et réduit le surapprentissage.\n</p>\n\n<h3>Modèles formés et justification</h3>\n<p>\nPlusieurs méthodes ont été comparées, y compris les arbres de décision boostés (BDT), les perceptrons multicouches (MLP) et les discriminants linéaires. Les méthodes linéaires peuvent échouer lorsque la frontière de séparation est non linéaire ; les méthodes basées sur les arbres et les réseaux neuronaux (BDT, MLP) ont montré de meilleures performances pour cette tâche. Les modèles ont été formés sur les étiquettes vraies MC (haut/bas MPI pour la classification et MPI numérique pour la régression) et évalués sur des échantillons de test indépendants [ machine_learningfin1.pdf ].\n</p>\n\n<h3>Évaluation et résultats</h3>\n<p>\nLes performances du classificateur ont été résumées à l'aide de courbes d'efficacité du signal contre le rejet du fond. La sélection basée sur ML a amélioré la capacité de séparation par rapport à la simple coupure de sphéricité×multiplicité, offrant un meilleur contrôle de la pureté et de l'efficacité. Il est particulièrement remarquable que les modèles de régression aient donné des estimations continues du nombre de MPI par événement — une fonctionnalité qui n'était pas auparavant disponible dans cette chaîne d'analyse et utile pour les comparaisons quantitatives modèle-données.\n</p>\n\n<h3>Nouveauté et impact</h3>\n<p>\nLa nouveauté clé réside dans la régression MPI par événement en utilisant des observables mesurées par le détecteur. Cela permet des tests directs et quantitatifs des explications concurrentes de l'activité dans la région transversale (par exemple, MPI+recombinaison de couleur contre l'hypothèse QGP) et peut être utilisé pour corréler les estimations MPI avec d'autres observables. Le flux de travail de classement et de décorrélation des caractéristiques, ainsi que le processus de formation/évaluation TMVA, sont également largement applicables à d'autres situations où une quantité cachée (non observable) doit être inférée à partir de données mesurées [ machine_learningfin1.pdf ].\n</p>\n\n<div style='margin: 1rem 0; max-width: 900px;'>\n<div style='width: 100%; padding-top: 56%; position:relative; border: 1px solid #ddd; border-radius: 6px; overflow:hidden;'>\n<iframe\nsrc='/assets/machine_learningfin1.pdf#view=FitH'\ntitle='Embedded slides: Machine learning applied to event classification'\nstyle='position:absolute; top:0; left:0; width:100%; height:100%; border:0;'\nallowfullscreen>\n</iframe>\n</div>\n<p style='font-size:0.9rem; margin:0.5rem 0 0;'>\n<a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Open slides in a new tab</a>\n</p>\n</div>\n\n<h3>Fichiers et liens</h3>\n<ul>\n<li><a href='https://tesiunamdocumentos.dgb.unam.mx/ptd2019/septiembre/0796038/Index.html' target='_blank' rel='noopener noreferrer'>Thèse de licence complète</a></li>\n<li><a href='/assets/machine_learningfin1.pdf' target='_blank' rel='noopener noreferrer'>Diapositives de présentation (intégrées ci-dessus)</a></li>\n</ul>\n\n</article>"
        }
    },
    {
        "id": 9,
        "title": {
            "en": "Local LLM with Retrieval-Augmented Generation",
            "es": "LLM Local con Generación Aumentada por Recuperación",
            "fr": "LLM Local avec Génération Augmentée par Récupération",
            "ja": "検索強化生成を備えたローカルLLM",
            "ru": "Локальная LLM с генерацией с поддержкой поиска"
        },
        "date": "2024-11-15",
        "description": {
            "en": "Development of a local large language model system using retrieval-augmented generation, combining vector search with tool-based querying and citation-aware responses.",
            "es": "Desarrollo de un sistema local de modelos de lenguaje grande utilizando generación aumentada por recuperación, combinando búsqueda vectorial con consultas basadas en herramientas y respuestas conscientes de citas.",
            "fr": "Développement d'un système local de grands modèles de langage utilisant la génération augmentée par récupération, combinant la recherche vectorielle avec des requêtes basées sur des outils et des réponses conscientes des citations.",
            "ja": "検索強化生成を使用したローカル大規模言語モデルシステムの開発、ベクトル検索とツールベースのクエリおよび引用対応の応答を組み合わせています。",
            "ru": "Разработка локальной системы больших языковых моделей с использованием генерации с поддержкой поиска, объединяющей векторный поиск с запросами на основе инструментов и ответами с учетом цитирования."
        },
        "tags": [
            17,
            18,
            3
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 100
            }
        ],
        "topic": "Artificial Intelligence",
        "image": {
            "en": "/assets/RAG.jpg"
        },
        "skills": [
            {
                "id": 14,
                "relevance": 100
            },
            {
                "id": 15,
                "relevance": 80
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>Retrieval-Augmented Generation (RAG) with Local LLM Agents</h2>\n\n  <p>\n    This project was an early exploration of <strong>Retrieval-Augmented Generation (RAG)</strong>, \n    developed at a time when locally deployable large language models were still relatively limited \n    in size, speed, and instruction-following capabilities. The primary goal was to design a system \n    capable of producing <strong>fact-backed answers with explicit references</strong>, rather than \n    free-form generative responses.\n  </p>\n\n  <p>\n    The core idea was to use a <strong>local LLM agent</strong> as an intermediate reasoning component. \n    Instead of directly querying a vector database with the user input, the model was first tasked \n    with extracting <em>keywords and topics</em> from the question. These keywords were then used to \n    perform a vector-based search over a database of article paragraphs, allowing for a more targeted \n    and interpretable retrieval step.\n  </p>\n\n  <p>\n    Retrieved paragraphs were passed back to the language model, which generated an answer constrained \n    to the provided sources. Each statement in the output was accompanied by <strong>explicit references</strong> \n    to the original documents, enabling traceability and manual verification. This design choice was \n    motivated by concerns around hallucinations and the need for transparency in research-oriented \n    question answering systems.\n  </p>\n\n  <p>\n    From a modern perspective, this architecture is intentionally conservative and somewhat rigid. \n    If redesigned today, the system would likely rely on more capable embedding models, structured \n    retrievers, multi-stage reranking, and stronger reasoning models. However, at the time, achieving \n    reliable instruction-following, multilingual handling, and reference-aware generation using a \n    fully local setup was a significant technical milestone.\n  </p>\n\n  <p>\n    Beyond the technical implementation, the project served as an important learning experience in \n    agent decomposition, prompt engineering, and the practical limitations of early-generation LLMs. \n    Many of the design decisions anticipated ideas that later became standard in modern RAG pipelines.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Bilingual_RAG_Presentation_1 (1).pdf#view=FitH'\n        title='Embedded slides: Retrieval-Augmented Generation project'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Bilingual_RAG_Presentation_1 (1).pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Links</h3>\n  <ul>\n    <li>\n      <a href='https://github.com/irsotarriva/DH/tree/main' target='_blank' rel='noopener noreferrer'>\n        GitHub repository\n      </a>\n    </li>\n  </ul>\n</article>",
            "es": "<article class='project-article'>\n  <h2>Generación Aumentada por Recuperación (RAG) con Agentes LLM Locales</h2>\n\n  <p>\n    Este proyecto fue una exploración temprana de la <strong>Generación Aumentada por Recuperación (RAG)</strong>, \n    desarrollado en un momento en que los modelos de lenguaje grande desplegables localmente aún eran relativamente limitados \n    en tamaño, velocidad y capacidades de seguimiento de instrucciones. El objetivo principal era diseñar un sistema \n    capaz de producir <strong>respuestas respaldadas por hechos con referencias explícitas</strong>, en lugar de \n    respuestas generativas de forma libre.\n  </p>\n\n  <p>\n    La idea central era utilizar un <strong>agente LLM local</strong> como componente intermedio de razonamiento. \n    En lugar de consultar directamente una base de datos vectorial con la entrada del usuario, se le asignaba primero \n    al modelo la tarea de extraer <em>palabras clave y temas</em> de la pregunta. Estas palabras clave se utilizaban luego para \n    realizar una búsqueda basada en vectores en una base de datos de párrafos de artículos, lo que permitía un paso de recuperación \n    más dirigido e interpretable.\n  </p>\n\n  <p>\n    Los párrafos recuperados se devolvían al modelo de lenguaje, que generaba una respuesta limitada a las fuentes proporcionadas. \n    Cada afirmación en la salida iba acompañada de <strong>referencias explícitas</strong> a los documentos originales, lo que permitía \n    la trazabilidad y la verificación manual. Esta elección de diseño fue motivada por preocupaciones sobre las alucinaciones y la necesidad \n    de transparencia en los sistemas de preguntas y respuestas orientados a la investigación.\n  </p>\n\n  <p>\n    Desde una perspectiva moderna, esta arquitectura es intencionalmente conservadora y algo rígida. Si se rediseñara hoy, el sistema probablemente dependería \n    de modelos de incrustación más capaces, recuperadores estructurados, reordenamiento en múltiples etapas y modelos de razonamiento más fuertes. Sin embargo, en ese momento, lograr un seguimiento confiable de instrucciones, manejo multilingüe y generación consciente de referencias utilizando una configuración completamente local fue un hito técnico significativo.\n  </p>\n\n  <p>\n    Más allá de la implementación técnica, el proyecto sirvió como una experiencia de aprendizaje importante en la descomposición de agentes, la ingeniería de indicaciones y las limitaciones prácticas de los LLM de primera generación. Muchas de las decisiones de diseño anticiparon ideas que luego se convirtieron en estándar en las tuberías RAG modernas.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Bilingual_RAG_Presentation_1 (1).pdf#view=FitH'\n        title='Embedded slides: Retrieval-Augmented Generation project'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Bilingual_RAG_Presentation_1 (1).pdf' target='_blank' rel='noopener noreferrer'>\n        Abrir diapositivas en una nueva pestaña\n      </a>\n    </p>\n  </div>\n\n  <h3>Enlaces</h3>\n  <ul>\n    <li>\n      <a href='https://github.com/irsotarriva/DH/tree/main' target='_blank' rel='noopener noreferrer'>\n        Repositorio de GitHub\n      </a>\n    </li>\n  </ul>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>Génération Augmentée par Récupération (RAG) avec des Agents LLM Locaux</h2>\n\n  <p>\n    Ce projet était une exploration précoce de la <strong>Génération Augmentée par Récupération (RAG)</strong>, \n    développé à une époque où les grands modèles de langage déployables localement étaient encore relativement limités \n    en taille, vitesse et capacités de suivi des instructions. L'objectif principal était de concevoir un système \n    capable de produire des <strong>réponses étayées par des faits avec des références explicites</strong>, plutôt que \n    des réponses génératives en forme libre.\n  </p>\n\n  <p>\n    L'idée centrale était d'utiliser un <strong>agent LLM local</strong> comme composant de raisonnement intermédiaire. \n    Au lieu d'interroger directement une base de données vectorielle avec l'entrée utilisateur, le modèle se voyait d'abord \n    confier la tâche d'extraire des <em>mots-clés et des sujets</em> de la question. Ces mots-clés étaient ensuite utilisés pour \n    effectuer une recherche basée sur des vecteurs dans une base de données de paragraphes d'articles, permettant une étape de récupération \n    plus ciblée et interprétable.\n  </p>\n\n  <p>\n    Les paragraphes récupérés étaient renvoyés au modèle de langage, qui générait une réponse contrainte aux sources fournies. \n    Chaque affirmation dans la sortie était accompagnée de <strong>références explicites</strong> aux documents originaux, permettant ainsi \n    la traçabilité et la vérification manuelle. Ce choix de conception était motivé par des préoccupations concernant les hallucinations et le besoin de transparence dans les systèmes de questions-réponses orientés recherche.\n  </p>\n\n  <p>\n    D'un point de vue moderne, cette architecture est intentionnellement conservatrice et quelque peu rigide. Si elle était repensée aujourd'hui, le système s'appuierait probablement sur des modèles d'intégration plus performants, des récupérateurs structurés, un reranking en plusieurs étapes et des modèles de raisonnement plus solides. Cependant, à l'époque, parvenir à un suivi fiable des instructions, à la gestion multilingue et à la génération consciente des références en utilisant une configuration entièrement locale était une étape technique importante.\n  </p>\n\n  <p>\n    Au-delà de la mise en œuvre technique, le projet a servi d'expérience d'apprentissage importante dans la décomposition des agents, l'ingénierie des invites et les limitations pratiques des LLM de première génération. De nombreuses décisions de conception ont anticipé des idées qui sont ensuite devenues standard dans les pipelines RAG modernes.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Bilingual_RAG_Presentation_1 (1).pdf#view=FitH'\n        title='Embedded slides: Retrieval-Augmented Generation project'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Bilingual_RAG_Presentation_1 (1).pdf' target='_blank' rel='noopener noreferrer'>\n        Ouvrir les diapositives dans un nouvel onglet\n      </a>\n    </p>\n  </div>\n\n  <h3>Liens</h3>\n  <ul>\n    <li>\n      <a href='https://github.com/irsotarriva/DH/tree/main' target='_blank' rel='noopener noreferrer'>\n        Dépôt GitHub\n      </a>\n    </li>\n  </ul>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>検索強化生成（RAG）とローカルLLMエージェント</h2>\n\n  <p>\n    このプロジェクトは、検索強化生成（RAG）の初期の探求であり、ローカルで展開可能な大規模言語モデルがまだ比較的サイズ、速度、指示追従能力に制限されていた時期に開発されました。主な目標は、自由形式の生成応答ではなく、<strong>事実に基づいた明示的な参照を伴う回答を生成できるシステムを設計することでした。</n>\n  </p>\n\n  <p>\n    中核となるアイデアは、中間の推論コンポーネントとして<strong>ローカルLLMエージェント</strong>を使用することでした。ユーザー入力でベクトルデータベースに直接クエリを送信する代わりに、最初にモデルに質問から<em>キーワードとトピック</em>を抽出するタスクが与えられました。これらのキーワードは、その後、記事の段落のデータベースに対してベクトルベースの検索を実行するために使用され、よりターゲットを絞った解釈可能な検索ステップが可能になりました。\n  </p>\n\n  <p>\n    検索された段落は言語モデルに戻され、提供されたソースに制約された回答が生成されました。出力内の各ステートメントには、元のドキュメントへの<strong>明示的な参照</strong>が伴い、追跡可能性と手動検証が可能になりました。この設計上の選択は、幻覚に関する懸念と研究指向の質問応答システムにおける透明性の必要性に動機付けられました。\n  </p>\n\n  <p>\n    現代の視点から見ると、このアーキテクチャは意図的に保守的でやや堅苦しいものです。今日再設計する場合、システムはより能力の高い埋め込みモデル、構造化された検索エンジン、マルチステージの再ランキング、より強力な推論モデルに依存する可能性があります。しかし、その当時、完全にローカルなセットアップを使用して、信頼性の高い指示追従、多言語対応、参照対応の生成を達成することは、重要な技術的マイルストーンでした。\n  </p>\n\n  <p>\n    技術的な実装を超えて、このプロジェクトはエージェントの分解、プロンプトエンジニアリング、初期世代のLLMの実際的な制限に関する重要な学習経験として役立ちました。多くの設計上の決定は、後に現代のRAGパイプラインで標準となったアイデアを予見していました。\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Bilingual_RAG_Presentation_1 (1).pdf#view=FitH'\n        title='Embedded slides: Retrieval-Augmented Generation project'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Bilingual_RAG_Presentation_1 (1).pdf' target='_blank' rel='noopener noreferrer'>\n        新しいタブでスライドを開く\n      </a>\n    </p>\n  </div>\n\n  <h3>リンク</h3>\n  <ul>\n    <li>\n      <a href=https://github.com/irsotarriva/DH/tree/main target='_blank' rel='noopener noreferrer'>\n        GitHubリポジトリ\n      </a>\n    </li>\n  </ul>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>Генерация с поддержкой поиска (RAG) с локальными агентами LLM</h2>\n\n  <p>\n    Этот проект был ранним исследованием <strong>генерации с поддержкой поиска (RAG)</strong>, \n    разработанным в то время, когда локально развертываемые большие языковые модели все еще были относительно ограничены \n    по размеру, скорости и возможностям следования инструкциям. Основная цель заключалась в разработке системы, \n    способной предоставлять <strong>ответы, подкрепленные фактами с явными ссылками</strong>, а не свободные генеративные ответы.\n  </p>\n\n  <p>\n    Основная идея заключалась в использовании <strong>локального агента LLM</strong> в качестве промежуточного компонента рассуждения. \n    Вместо того чтобы напрямую запрашивать векторную базу данных с помощью пользовательского ввода, модель сначала должна была \n    извлечь <em>ключевые слова и темы</em> из вопроса. Эти ключевые слова затем использовались для выполнения векторного поиска \n    по базе данных абзацев статей, что позволяло более целенаправленный и интерпретируемый этап извлечения.\n  </p>\n\n  <p>\n    Извлеченные абзацы возвращались обратно в языковую модель, которая генерировала ответ, ограниченный предоставленными источниками. \n    Каждое утверждение в выводе сопровождалось <strong>явными ссылками</strong> на оригинальные документы, что обеспечивало отслеживаемость и возможность ручной проверки. Этот выбор дизайна был мотивирован опасениями по поводу галлюцинаций и необходимостью прозрачности в системах вопросов и ответов, ориентированных на исследования.\n  </p>\n\n  <p>\n    С современной точки зрения эта архитектура является намеренно консервативной и несколько жесткой. Если бы ее разрабатывали сегодня, система, вероятно, полагалась бы на более мощные модели встраивания, структурированные поисковые механизмы, многоэтапное переупорядочивание и более сильные модели рассуждения. Однако в то время достижение надежного следования инструкциям, многоязыковой поддержки и генерации с учетом ссылок с использованием полностью локальной настройки было значительным техническим достижением.\n  </p>\n\n  <p>\n    Помимо технической реализации, проект послужил важным опытом обучения в области декомпозиции агентов, проектирования подсказок и практических ограничений LLM первого поколения. Многие дизайнерские решения предвосхитили идеи, которые позже стали стандартом в современных RAG-конвейерах.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%; padding-top: 56%; position: relative; border: 1px solid #ddd; border-radius: 6px; overflow: hidden;'>\n      <iframe\n        src='assets/Bilingual_RAG_Presentation_1 (1).pdf#view=FitH'\n        title='Embedded slides: Retrieval-Augmented Generation project'\n        style='position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem; margin: 0.5rem 0 0;'>\n      <a href='assets/Bilingual_RAG_Presentation_1 (1).pdf' target='_blank' rel='noopener noreferrer'>\n        Открыть слайды в новой вкладке\n      </a>\n    </p>\n  </div>\n\n  <h3>Ссылки</h3>\n  <ul>\n    <li>\n      <a href='https://github.com/irsotarriva/DH/tree/main' target='_blank' rel='noopener noreferrer'>\n        Репозиторий GitHub\n      </a>\n    </li>\n  </ul>\n</article>"
        }
    },
    {
        "id": 10,
        "title": {
            "en": "Paper Recommendation System",
            "es": "Sistema de Recomendación de Artículos",
            "fr": "Système de Recommandation d'Articles",
            "ja": "論文推薦システム",
            "ru": "Система рекомендаций статей"
        },
        "date": "2025-12-22",
        "description": {
            "en": "Paper recommendation system based on vector embeddings and user data, featuring a graph-based interface to explore relationships between related scientific papers.",
            "es": "Sistema de recomendación de artículos basado en incrustaciones vectoriales y datos de usuarios, con una interfaz basada en gráficos para explorar las relaciones entre artículos científicos relacionados.",
            "fr": "Système de recommandation d'articles basé sur des embeddings vectoriels et des données utilisateur, avec une interface basée sur des graphes pour explorer les relations entre les articles scientifiques connexes.",
            "ja": "ベクトル埋め込みとユーザーデータに基づく論文推薦システムで、関連する科学論文間の関係を探索するためのグラフベースのインターフェースを備えています。",
            "ru": "Система рекомендаций статей на основе векторных встраиваний и пользовательских данных, с графическим интерфейсом для изучения отношений между связанными научными статьями."
        },
        "tags": [
            19,
            3
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 80
            },
            {
                "name": "nextjs",
                "proportion": 10
            },
            {
                "name": "HTML/CSS",
                "proportion": 10
            }
        ],
        "topic": "Artificial Intelligence",
        "image": {
            "en": "/assets/Journet.jpg"
        },
        "skills": [
            {
                "id": 15,
                "relevance": 80
            },
            {
                "id": 16,
                "relevance": 100
            },
            {
                "id": 17,
                "relevance": 70
            },
            {
                "id": 18,
                "relevance": 90
            },
            {
                "id": 19,
                "relevance": 100
            },
            {
                "id": 1,
                "relevance": 80
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n  <h2>JourNet — Paper Recommendation and Discovery System</h2>\n\n  <p>\n    JourNet is a paper recommendation and discovery system developed during the\n    Programming Boot Camp in Funabashi, Chiba, as part of the <strong>Tokyo Tech Academy for Leadership (TOTAL)</strong>\n    curriculum. The project was built by a team of four: I am <strong>Isai Sotarriva</strong>,\n    with teammates <strong>Andre Lecona Buttelli</strong> and <strong>Jianwei Wen</strong>,\n    and our teaching assistant <strong>Sameer Deshmukh</strong> who supervised the work.\n  </p>\n\n  <p>\n    The application is split into two clear parts: a <strong>frontend</strong> (Next.js)\n    and a <strong>backend</strong> (Python + FastAPI). The backend is the only component\n    that holds database credentials and is responsible for enforcing authorization,\n    validating frontend requests, and applying privacy rules — for example, editing out\n    a username when a user elects to stay anonymous in a comment.\n  </p>\n\n  <h3>My role</h3>\n  <p>\n    As the project architect I designed the app architecture and deployment, implemented\n    the recommendation system, and built the interactive graph UI that surfaces recommendations.\n    I also implemented the frontend script that renders recommendations as an exploratory graph.\n    Andre implemented user login and handled most of the remaining backend functionality.\n    Jianwei created the initial Next.js template and worked on the UI. Sameer acted as our TA/supervisor.\n  </p>\n\n  <h3>Backend, databases and data flow</h3>\n  <p>\n    The backend is written in Python using <em>FastAPI</em> to expose discrete actions for the frontend.\n    Two databases are used:\n  </p>\n  <ul>\n    <li><strong>Supabase</strong> — stores users, comments, ratings, article metadata and other app state.</li>\n    <li><strong>Qdrant</strong> — stores and indexes vector embeddings (we embed paper abstracts).</li>\n  </ul>\n\n  <p>\n    User interactions across the platform are tracked to build a dynamic user profile. A profile\n    is represented as a list of (article, weight) pairs where each article points to a vector in Qdrant.\n    Weights indicate how strongly an article should influence recommendations: interactions such as\n    commenting increase weight, while ratings can increase or decrease it. Weights may be positive or negative.\n  </p>\n\n  <h3>Recommendation algorithm (high-level)</h3>\n  <p>\n    The recommendation mechanism projects the embedding space along an axis derived from the user's\n    weighted article list. Concretely, the profile weights define a direction in the vector space;\n    candidate articles are scored by their projection along that direction, and the system returns\n    articles that lie furthest in the positive direction — i.e., those that best match the user's\n    expressed interests. Qdrant is used to search the vector space efficiently for these top candidates.\n  </p>\n\n  <h3>Graph UI and exploration</h3>\n  <p>\n    The graph is the central UX element. When a user selects a node (an article), the system finds\n    related articles and visualizes them as neighboring nodes. Before adding a new node the frontend\n    checks for existing matches: if a related article already exists in the graph a link is drawn\n    instead of creating a duplicate node. This produces a dense, navigable graph that highlights\n    relationships and lets users discover new relevant papers through exploration.\n  </p>\n\n  <p>\n    The graph UI is interactive and supports continual refinement of the user profile: actions like\n    commenting or rating immediately adjust article weights and therefore affect subsequent recommendations.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n      <iframe\n        src='/assets/Journet.pdf#view=FitH'\n        title='Embedded slides: Journet'\n        style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;background:#fafafa;display:flex;align-items:center;justify-content:center;'>\n      <img src='/assets/Journet.jpg' alt='JourNet app screenshot' style='position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:6px;'/><\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.jpg' target='_blank' rel='noopener noreferrer'>\n        Open app screenshot in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Implementation notes</h3>\n  <p>\n    - FastAPI endpoints are minimal and focused: authentication, profile updates, comment/rating actions,\n    and recommendation queries. The backend validates authorization before accessing Supabase or Qdrant.\n  </p>\n  <p>\n    - Qdrant stores embeddings of abstracts (generated with the chosen embedding model) and serves nearest-neighbor\n    and projection-based queries for the recommendation engine.\n  </p>\n  <p>\n    - Supabase stores relational app data and user-visible content; all edits that affect privacy (e.g. anonymizing\n    a comment) are handled server-side to prevent client bypass.\n  </p>\n\n  <h3>Links</h3>\n  <a href='https://jour-net-client-git-presentation-irsotarrivas-projects.vercel.app/' target='_blank' rel='noopener noreferrer'>Live demo — JourNet</a><br/>\n  <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>Project slides (PDF)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNetClient' target='_blank' rel='noopener noreferrer'>Front-end repository (GitHub)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNet' target='_blank' rel='noopener noreferrer'>Back-end repository (GitHub)</a>\n</article>",
            "es": "<article class='project-article'>\n  <h2>JourNet — Sistema de Recomendación y Descubrimiento de Artículos</h2>\n\n  <p>\n    JourNet es un sistema de recomendación y descubrimiento de artículos desarrollado durante el\n    Boot Camp de Programación en Funabashi, Chiba, como parte del currículo de la <strong>Tokyo Tech Academy for Leadership (TOTAL)</strong>.\n    El proyecto fue construido por un equipo de cuatro: yo soy <strong>Isai Sotarriva</strong>,\n    con los compañeros de equipo <strong>Andre Lecona Buttelli</strong> y <strong>Jianwei Wen</strong>,\n    y nuestro asistente de enseñanza <strong>Sameer Deshmukh</strong> que supervisó el trabajo.\n  </p>\n\n  <p>\n    La aplicación se divide en dos partes claras: un <strong>frontend</strong> (Next.js)\n    y un <strong>backend</strong> (Python + FastAPI). El backend es el único componente\n    que contiene las credenciales de la base de datos y es responsable de hacer cumplir la autorización,\n    validar las solicitudes del frontend y aplicar las reglas de privacidad, por ejemplo, editar\n    un nombre de usuario cuando un usuario elige permanecer anónimo en un comentario.\n  </p>\n\n  <h3>Mi rol</h3>\n  <p>\n    Como arquitecto del proyecto, diseñé la arquitectura y el despliegue de la aplicación, implementé\n    el sistema de recomendación y construí la interfaz gráfica interactiva que muestra las recomendaciones.\n    Andre implementó el inicio de sesión de usuario y manejó la mayor parte de la funcionalidad restante del backend.\n    Jianwei creó la plantilla inicial de Next.js y trabajó en la interfaz de usuario. Sameer actuó como nuestro TA/supervisor.\n  </p>\n\n  <h3>Backend, bases de datos y flujo de datos</h3>\n  <p>\n    El backend está escrito en Python usando <em>FastAPI</em> para exponer acciones discretas para el frontend.\n    Se utilizan dos bases de datos:\n  </p>\n  <ul>\n    <li><strong>Supabase</strong> — almacena usuarios, comentarios, calificaciones, metadatos de artículos y otro estado de la aplicación.</li>\n    <li><strong>Qdrant</strong> — almacena e indexa incrustaciones vectoriales (embebemos resúmenes de artículos).</li>\n  </ul>\n\n  <p>\n    Las interacciones de los usuarios en toda la plataforma se rastrean para construir un perfil de usuario dinámico. Un perfil\n    se representa como una lista de pares (artículo, peso) donde cada artículo apunta a un vector en Qdrant.\n    Los pesos indican qué tan fuertemente un artículo debe influir en las recomendaciones: las interacciones como\n    comentar aumentan el peso, mientras que las calificaciones pueden aumentarlo o disminuirlo. Los pesos pueden ser positivos o negativos.\n  </p>\n\n  <h3>Algoritmo de recomendación (alto nivel)</h3>\n  <p>\n    El mecanismo de recomendación proyecta el espacio de incrustaciones a lo largo de un eje derivado de la lista de artículos ponderados del usuario.\n    Concretamente, los pesos del perfil definen una dirección en el espacio vectorial;\n    los artículos candidatos se puntúan por su proyección a lo largo de esa dirección, y el sistema devuelve\n    artículos que se encuentran más lejos en la dirección positiva, es decir, aquellos que mejor coinciden con los intereses expresados por el usuario.\n    Qdrant se utiliza para buscar eficientemente en el espacio vectorial estos principales candidatos.\n  </p>\n\n  <h3>Interfaz gráfica y exploración</h3>\n  <p>\n    El gráfico es el elemento central de la experiencia de usuario. Cuando un usuario selecciona un nodo (un artículo), el sistema encuentra\n    artículos relacionados y los visualiza como nodos vecinos. Antes de agregar un nuevo nodo, el frontend\n    verifica si hay coincidencias existentes: si un artículo relacionado ya existe en el gráfico, se dibuja un enlace\n    en lugar de crear un nodo duplicado. Esto produce un gráfico denso y navegable que resalta\n    las relaciones y permite a los usuarios descubrir nuevos artículos relevantes a través de la exploración.\n  </p>\n\n  <p>\n    La interfaz gráfica es interactiva y admite el refinamiento continuo del perfil del usuario: acciones como\n    comentar o calificar ajustan inmediatamente los pesos de los artículos y, por lo tanto, afectan las recomendaciones posteriores.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n      <iframe\n        src='/assets/Journet.pdf#view=FitH'\n        title='Embedded slides: Journet'\n        style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;background:#fafafa;display:flex;align-items:center;justify-content:center;'>\n      <img src='/assets/Journet.jpg' alt='JourNet app screenshot' style='position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:6px;'/><\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.jpg' target='_blank' rel='noopener noreferrer'>\n        Open app screenshot in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Notas de implementación</h3>\n  <p>\n    - Los endpoints de FastAPI son mínimos y enfocados: autenticación, actualizaciones de perfil, acciones de comentarios/calificaciones,\n    y consultas de recomendación. El backend valida la autorización antes de acceder a Supabase o Qdrant.\n  </p>\n  <p>\n    - Qdrant almacena incrustaciones de resúmenes (generadas con el modelo de incrustación elegido) y sirve consultas de vecinos más cercanos\n    y basadas en proyecciones para el motor de recomendación.\n  </p>\n  <p>\n    - Supabase almacena datos relacionales de la aplicación y contenido visible para el usuario; todas las ediciones que afectan la privacidad (por ejemplo, anonimizar\n    un comentario) se manejan del lado del servidor para evitar eludir el cliente.\n  </p>\n\n  <h3>Enlaces</h3>\n  <a href='https://jour-net-client-git-presentation-irsotarrivas-projects.vercel.app/' target='_blank' rel='noopener noreferrer'>Live demo — JourNet</a><br/>\n  <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>Project slides (PDF)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNetClient' target='_blank' rel='noopener noreferrer'>Repositorio front-end — JourNetClient</a><br/>\n  <a href='https://github.com/irsotarriva/JourNet' target='_blank' rel='noopener noreferrer'>Repositorio back-end — JourNet</a>\n</article>",
            "fr": "<article class='project-article'>\n  <h2>JourNet — Système de Recommandation et de Découverte d'Articles</h2>\n\n  <p>\n    JourNet est un système de recommandation et de découverte d'articles développé lors du\n    Boot Camp de Programmation à Funabashi, Chiba, dans le cadre du programme de la <strong>Tokyo Tech Academy for Leadership (TOTAL)</strong>.\n    Le projet a été construit par une équipe de quatre personnes : je suis <strong>Isai Sotarriva</strong>,\n    avec les coéquipiers <strong>Andre Lecona Buttelli</strong> et <strong>Jianwei Wen</strong>,\n    et notre assistant pédagogique <strong>Sameer Deshmukh</strong> qui a supervisé le travail.\n  </p>\n\n  <p>\n    L'application est divisée en deux parties distinctes : un <strong>frontend</strong> (Next.js)\n    et un <strong>backend</strong> (Python + FastAPI). Le backend est le seul composant\n    qui détient les informations d'identification de la base de données et est responsable de l'application de l'autorisation,\n    de la validation des demandes du frontend et de l'application des règles de confidentialité, par exemple, en modifiant\n    un nom d'utilisateur lorsqu'un utilisateur choisit de rester anonyme dans un commentaire.\n  </p>\n\n  <h3>Mon rôle</h3>\n  <p>\n    En tant qu'architecte du projet, j'ai conçu l'architecture et le déploiement de l'application, mis en œuvre\n    le système de recommandation et construit l'interface graphique interactive qui affiche les recommandations.\n    Andre a mis en œuvre la connexion utilisateur et géré la majeure partie des fonctionnalités restantes du backend.\n    Jianwei a créé le modèle initial Next.js et travaillé sur l'interface utilisateur. Sameer a agi en tant que notre TA/superviseur.\n  </p>\n\n  <h3>Backend, bases de données et flux de données</h3>\n  <p>\n    Le backend est écrit en Python utilisant <em>FastAPI</em> pour exposer des actions discrètes pour le frontend.\n    Deux bases de données sont utilisées :\n  </p>\n  <ul>\n    <li><strong>Supabase</strong> — stocke les utilisateurs, les commentaires, les évaluations, les métadonnées des articles et d'autres états de l'application.</li>\n    <li><strong>Qdrant</strong> — stocke et indexe les embeddings vectoriels (nous intégrons les résumés des articles).</li>\n  </ul>\n\n  <p>\n    Les interactions des utilisateurs sur toute la plateforme sont suivies pour construire un profil utilisateur dynamique. Un profil\n    est représenté comme une liste de paires (article, poids) où chaque article pointe vers un vecteur dans Qdrant.\n    Les poids indiquent à quel point un article doit influencer les recommandations : les interactions telles que\n    commenter augmentent le poids, tandis que les évaluations peuvent l'augmenter ou le diminuer. Les poids peuvent être positifs ou négatifs.\n  </p>\n\n  <h3>Algorithme de recommandation (haut niveau)</h3>\n  <p>\n    Le mécanisme de recommandation projette l'espace d'embeddings le long d'un axe dérivé de la liste d'articles pondérés de l'utilisateur.\n    Concrètement, les poids du profil définissent une direction dans l'espace vectoriel;\n    les articles candidats sont notés par leur projection le long de cette direction, et le système renvoie\n    les articles qui se trouvent le plus loin dans la direction positive, c'est-à-dire ceux qui correspondent le mieux aux intérêts exprimés par l'utilisateur.\n    Qdrant est utilisé pour rechercher efficacement dans l'espace vectoriel ces meilleurs candidats.\n  </p>\n\n  <h3>Interface graphique et exploration</h3>\n  <p>\n    Le graphique est l'élément central de l'expérience utilisateur. Lorsqu'un utilisateur sélectionne un nœud (un article), le système trouve\n    des articles connexes et les visualise comme des nœuds voisins. Avant d'ajouter un nouveau nœud, le frontend\n    vérifie les correspondances existantes : si un article connexe existe déjà dans le graphique, un lien est tracé\n    au lieu de créer un nœud en double. Cela produit un graphique dense et navigable qui met en évidence\n    les relations et permet aux utilisateurs de découvrir de nouveaux articles pertinents grâce à l'exploration.\n  </p>\n\n  <p>\n    L'interface graphique est interactive et prend en charge le raffinement continu du profil utilisateur : des actions telles que\n    commenter ou évaluer ajustent immédiatement les poids des articles et affectent donc les recommandations ultérieures.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n      <iframe\n        src='/assets/Journet.pdf#view=FitH'\n        title='Embedded slides: Journet'\n        style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;background:#fafafa;display:flex;align-items:center;justify-content:center;'>\n      <img src='/assets/Journet.jpg' alt='JourNet app screenshot' style='position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:6px;'/><\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.jpg' target='_blank' rel='noopener noreferrer'>\n        Open app screenshot in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Notes d'implémentation</h3>\n  <p>\n    - Les endpoints FastAPI sont minimaux et ciblés : authentification, mises à jour de profil, actions de commentaires/évaluations,\n    et requêtes de recommandation. Le backend valide l'autorisation avant d'accéder à Supabase ou Qdrant.\n  </p>\n  <p>\n    - Qdrant stocke les embeddings des résumés (générés avec le modèle d'embedding choisi) et sert des requêtes de plus proches voisins\n    et basées sur des projections pour le moteur de recommandation.\n  </p>\n  <p>\n    - Supabase stocke les données relationnelles de l'application et le contenu visible par l'utilisateur ; toutes les modifications qui affectent la confidentialité (par exemple,\n    anonymiser un commentaire) sont gérées côté serveur pour éviter tout contournement côté client.\n  </p>\n\n  <h3>Liens</h3>\n  <a href='https://jour-net-client-git-presentation-irsotarrivas-projects.vercel.app/' target='_blank' rel='noopener noreferrer'>Live demo — JourNet</a><br/>\n  <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>Project slides (PDF)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNetClient' target='_blank' rel='noopener noreferrer'>Dépôt front-end — JourNetClient</a><br/>\n  <a href='https://github.com/irsotarriva/JourNet' target='_blank' rel='noopener noreferrer'>Dépôt back-end — JourNet</a>\n</article>",
            "ja": "<article class='project-article'>\n  <h2>JourNet — 論文推薦および発見システム</h2>\n\n  <p>\n    JourNetは、千葉県船橋市で開催されたプログラミングブートキャンプ中に開発された論文推薦および発見システムであり、\n    東京工業大学リーダーシップアカデミー（TOTAL）のカリキュラムの一部です。プロジェクトは4人のチームによって構築されました：私は<strong>Isai Sotarriva</strong>、\n    チームメイトの<strong>Andre Lecona Buttelli</strong>と<strong>Jianwei Wen</strong>、\n    そして私たちのティーチングアシスタントである<strong>Sameer Deshmukh</strong>が作業を監督しました。\n  </p>\n\n  <p>\n    アプリケーションは明確に2つの部分に分かれています：<strong>フロントエンド</strong>（Next.js）\n    と<strong>バックエンド</strong>（Python + FastAPI）。バックエンドはデータベースの資格情報を保持する唯一のコンポーネントであり、認可の強制、\n    フロントエンドからのリクエストの検証、およびプライバシールールの適用を担当しています。例えば、ユーザーがコメントで匿名を選択した場合にユーザー名を編集するなどです。\n  </p>\n\n  <h3>私の役割</h3>\n  <p>\n    プロジェクトアーキテクトとして、アプリケーションのアーキテクチャと展開を設計し、\n    推薦システムを実装し、推薦を表示するインタラクティブなグラフUIを構築しました。\n    Andreはユーザーログインを実装し、バックエンドの残りの機能の大部分を担当しました。\n    Jianweiは最初のNext.jsテンプレートを作成し、UIに取り組みました。Sameerは私たちのTA/スーパーバイザーとして活動しました。\n  </p>\n\n  <h3>バックエンド、データベース、およびデータフロー</h3>\n  <p>\n    バックエンドはPythonで書かれており、<em>FastAPI</em>を使用してフロントエンドのための離散的なアクションを公開しています。\n    2つのデータベースが使用されています：\n  </p>\n  <ul>\n    <li><strong>Supabase</strong> — ユーザー、コメント、評価、記事のメタデータ、およびその他のアプリケーション状態を保存します。</li>\n    <li><strong>Qdrant</strong> — ベクトル埋め込みを保存およびインデックス化します（記事の要約を埋め込みます）。</li>\n  </ul>\n\n  <p>\n    プラットフォーム全体でのユーザーの相互作用は追跡され、動的なユーザープロフィールを構築します。プロフィールは（記事、重み）ペアのリストとして表され、各記事はQdrant内のベクトルを指します。\n    重みは、記事が推薦にどれだけ影響を与えるべきかを示します：コメントなどの相互作用は重みを増加させ、評価はそれを増加または減少させることができます。重みは正または負である可能性があります。\n  </p>\n\n  <h3>推薦アルゴリズム（高レベル）</h3>\n  <p>\n    推薦メカニズムは、ユーザーの重み付けされた記事リストから導出された軸に沿って埋め込み空間を投影します。\n    具体的には、プロフィールの重みはベクトル空間内の方向を定義します；\n    候補記事はその方向に沿った投影によってスコアリングされ、システムは正の方向に最も遠い記事を返します。つまり、ユーザーの表明された関心に最も一致する記事です。\n    Qdrantは、これらのトップ候補を効率的に検索するために使用されます。\n  </p>\n\n  <h3>グラフUIと探索</h3>\n  <p>\n    グラフは中心的なUX要素です。ユーザーがノード（記事）を選択すると、システムは関連する記事を見つけ、それらを隣接ノードとして視覚化します。新しいノードを追加する前に、フロントエンドは既存の一致をチェックします：関連する記事が既にグラフに存在する場合、重複ノードを作成する代わりにリンクが描画されます。これにより、関係を強調し、探索を通じて新しい関連論文を発見できる密度の高いナビゲート可能なグラフが生成されます。\n  </p>\n\n  <p>\n    グラフUIはインタラクティブであり、ユーザープロフィールの継続的な洗練をサポートします：\n    コメントや評価などのアクションは、記事の重みを即座に調整し、そのため後続の推薦に影響を与えます。\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n      <iframe\n        src='/assets/Journet.pdf#view=FitH'\n        title='Embedded slides: Journet'\n        style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;background:#fafafa;display:flex;align-items:center;justify-content:center;'>\n      <img src='/assets/Journet.jpg' alt='JourNet app screenshot' style='position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:6px;'/><\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.jpg' target='_blank' rel='noopener noreferrer'>\n        Open app screenshot in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>実装ノート</h3>\n  <p>\n    - FastAPIエンドポイントは最小限で焦点を絞っています：認証、プロフィールの更新、コメント/評価アクション、\n    および推薦クエリ。バックエンドはSupabaseまたはQdrantにアクセスする前に認可を検証します。\n  </p>\n  <p>\n    - Qdrantは要約の埋め込みを保存します（選択した埋め込みモデルで生成）および推薦エンジンのための最近傍および投影ベースのクエリを提供します。\n  </p>\n  <p>\n    - Supabaseはアプリケーションのリレーショナルデータとユーザーが表示するコンテンツを保存します；プライバシーに影響を与えるすべての編集（例：\n    コメントの匿名化）はクライアントのバイパスを防ぐためにサーバー側で処理されます。\n  </p>\n\n  <h3>リンク</h3>\n  <a href='https://jour-net-client-git-presentation-irsotarrivas-projects.vercel.app/' target='_blank' rel='noopener noreferrer'>Live demo — JourNet</a><br/>\n  <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>Project slides (PDF)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNetClient' target='_blank' rel='noopener noreferrer'>フロントエンドリポジトリ — JourNetClient</a><br/>\n  <a href='https://github.com/irsotarriva/JourNet' target='_blank' rel='noopener noreferrer'>バックエンドリポジトリ — JourNet</a>\n</article>",
            "ru": "<article class='project-article'>\n  <h2>JourNet — Система Рекомендаций и Обнаружения Статей</h2>\n\n  <p>\n    JourNet — это система рекомендаций и обнаружения статей, разработанная во время\n    Программного Буткемпа в Фунабаси, Чиба, в рамках учебной программы <strong>Tokyo Tech Academy for Leadership (TOTAL)</strong>.\n    Проект был создан командой из четырех человек: я — <strong>Isai Sotarriva</strong>,\n    с товарищами по команде <strong>Andre Lecona Buttelli</strong> и <strong>Jianwei Wen</strong>,\n    а также нашим ассистентом преподавателя <strong>Sameer Deshmukh</strong>, который курировал работу.\n  </p>\n\n  <p>\n    Приложение разделено на две четкие части: <strong>фронтенд</strong> (Next.js)\n    и <strong>бэкенд</strong> (Python + FastAPI). Бэкенд — это единственный компонент,\n    который содержит учетные данные базы данных и отвечает за обеспечение авторизации,\n    проверку запросов с фронтенда и применение правил конфиденциальности, например, изменение\n    имени пользователя, когда пользователь выбирает оставаться анонимным в комментарии.\n  </p>\n\n  <h3>Моя роль</h3>\n  <p>\n    В качестве архитектора проекта я спроектировал архитектуру и развертывание приложения, реализовал\n    систему рекомендаций и построил интерактивный графический интерфейс для отображения рекомендаций.\n    Андре реализовал вход пользователя и обработал большую часть оставшейся функциональности бэкенда.\n    Цзянвэй создал начальный шаблон Next.js и работал над пользовательским интерфейсом. Самир выступал в роли нашего TA/супервайзера.\n  </p>\n\n  <h3>Бэкенд, базы данных и поток данных</h3>\n  <p>\n    Бэкенд написан на Python с использованием <em>FastAPI</em> для предоставления дискретных действий для фронтенда.\n    Используются две базы данных:\n  </p>\n  <ul>\n    <li><strong>Supabase</strong> — хранит пользователей, комментарии, оценки, метаданные статей и другое состояние приложения.</li>\n    <li><strong>Qdrant</strong> — хранит и индексирует векторные встраивания (мы встраиваем резюме статей).</li>\n  </ul>\n\n  <p>\n    Взаимодействия пользователей по всей платформе отслеживаются для построения динамического профиля пользователя. Профиль\n    представлен как список пар (статья, вес), где каждая статья указывает на вектор в Qdrant.\n    Веса указывают, насколько сильно статья должна влиять на рекомендации: взаимодействия, такие как\n    комментарии, увеличивают вес, в то время как оценки могут его увеличить или уменьшить. Веса могут быть положительными или отрицательными.\n  </p>\n\n  <h3>Алгоритм рекомендаций (высокий уровень)</h3>\n  <p>\n    Механизм рекомендаций проецирует пространство встраиваний вдоль оси, выведенной из списка взвешенных статей пользователя.\n    Конкретно, веса профиля определяют направление в векторном пространстве;\n    кандидатные статьи оцениваются по их проекции вдоль этого направления, и система возвращает\n    статьи, которые находятся дальше всего в положительном направлении, то есть те, которые лучше всего соответствуют интересам, выраженным пользователем.\n    Qdrant используется для эффективного поиска этих лучших кандидатов в векторном пространстве.\n  </p>\n\n  <h3>Графический интерфейс и исследование</h3>\n  <p>\n    Граф является центральным элементом пользовательского опыта. Когда пользователь выбирает узел (статью), система находит\n    связанные статьи и визуализирует их как соседние узлы. Перед добавлением нового узла фронтенд\n    проверяет существующие совпадения: если связанная статья уже существует в графе, рисуется ссылка\n    вместо создания дублирующего узла. Это создает плотный и навигируемый граф, который выделяет\n    отношения и позволяет пользователям открывать новые релевантные статьи через исследование.\n  </p>\n\n  <p>\n    Графический интерфейс интерактивен и поддерживает непрерывное уточнение профиля пользователя: действия, такие как\n    комментирование или оценка, немедленно корректируют веса статей и, следовательно, влияют на последующие рекомендации.\n  </p>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;'>\n      <iframe\n        src='/assets/Journet.pdf#view=FitH'\n        title='Embedded slides: Journet'\n        style='position:absolute;top: 0;left: 0;width: 100%;height: 100%;border: 0;'\n        allowfullscreen>\n      </iframe>\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>\n        Open slides in a new tab\n      </a>\n    </p>\n  </div>\n\n  <div style='margin: 1rem 0; max-width: 900px;'>\n    <div style='width: 100%;padding-top: 56%;position:relative;border: 1px solid #ddd;border-radius: 6px;overflow:hidden;background:#fafafa;display:flex;align-items:center;justify-content:center;'>\n      <img src='/assets/Journet.jpg' alt='JourNet app screenshot' style='position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:6px;'/><\n    </div>\n    <p style='font-size: 0.9rem;margin: 0.5rem 0 0;'>\n      <a href='/assets/Journet.jpg' target='_blank' rel='noopener noreferrer'>\n        Open app screenshot in a new tab\n      </a>\n    </p>\n  </div>\n\n  <h3>Примечания по реализации</h3>\n  <p>\n    - Конечные точки FastAPI минимальны и целенаправленны: аутентификация, обновления профиля, действия комментариев/оценок,\n    и запросы рекомендаций. Бэкенд проверяет авторизацию перед доступом к Supabase или Qdrant.\n  </p>\n  <p>\n    - Qdrant хранит встраивания резюме (сгенерированные с помощью выбранной модели встраивания) и обслуживает запросы ближайших соседей\n    и на основе проекций для движка рекомендаций.\n  </p>\n  <p>\n    - Supabase хранит реляционные данные приложения и контент, видимый пользователю; все изменения, влияющие на конфиденциальность (например,\n    анонимизация комментария), обрабатываются на стороне сервера, чтобы избежать обхода на стороне клиента.\n  </p>\n\n  <h3>Ссылки</h3>\n  <a href='https://jour-net-client-git-presentation-irsotarrivas-projects.vercel.app/' target='_blank' rel='noopener noreferrer'>Live demo — JourNet</a><br/>\n  <a href='/assets/Journet.pdf' target='_blank' rel='noopener noreferrer'>Project slides (PDF)</a><br/>\n  <a href='https://github.com/irsotarriva/JourNetClient' target='_blank' rel='noopener noreferrer'>Репозиторий фронтенда — JourNetClient</a><br/>\n  <a href='https://github.com/irsotarriva/JourNet' target='_blank' rel='noopener noreferrer'>Репозиторий бэкенда — JourNet</a>\n</article>"
        }
    },
    {
        "id": 11,
        "title": {
            "en": "Fast Elo Estimation for Chess",
            "es": "Estimación Rápida de Elo para Ajedrez",
            "fr": "Estimation Rapide de l'Elo pour les Échecs",
            "ja": "チェスの高速Elo推定",
            "ru": "Быстрая оценка Эло для шахмат"
        },
        "date": "2025-11-01",
        "description": {
            "en": "Implemented a loop of 2 transformer models to estimate the Elo of the player based on his previous movements and adjust the bot model so that the win rate remains exactly 50%. This allows to estimate the Elo of any player within a single game against the bot.",
            "es": "Implementé un bucle de 2 modelos transformadores para estimar el Elo del jugador basado en sus movimientos anteriores y ajustar el modelo del bot para que la tasa de victorias se mantenga exactamente en 50%. Esto permite estimar el Elo de cualquier jugador en un solo juego contra el bot.",
            "fr": "J'ai mis en place une boucle de 2 modèles transformateurs pour estimer l'Elo du joueur en fonction de ses mouvements précédents et ajuster le modèle du bot afin que le taux de victoire reste exactement à 50%. Cela permet d'estimer l'Elo de n'importe quel joueur en un seul jeu contre le bot.",
            "ja": "2つのトランスフォーマーモデルのループを実装して、プレイヤーの以前の動きに基づいてEloを推定し、勝率が正確に50％に保たれるようにボットモデルを調整しました。これにより、ボットとの単一のゲームで任意のプレイヤーのEloを推定できます。",
            "ru": "Реализован цикл из 2 трансформерных моделей для оценки Эло игрока на основе его предыдущих ходов и настройки модели бота так, чтобы коэффициент побед оставался ровно 50%. Это позволяет оценить Эло любого игрока в одной игре против бота."
        },
        "tags": [
            3,
            8
        ],
        "languages": [
            {
                "name": "Python",
                "proportion": 100
            }
        ],
        "topic": "Artificial Intelligence",
        "image": {
            "en": "/assets/fast-elo.png"
        },
        "skills": [
            {
                "id": 20,
                "relevance": 100
            },
            {
                "id": 21,
                "relevance": 90
            }
        ],
        "content": {
            "en": "<article class='project-article'>\n<h2>fast-elo — Real-time, human-like ELO-adaptive chess actor</h2>\n\n<p>\nfast-elo is an experimental weekend project I built a couple of months ago that explores a\ncritic–actor architecture for producing a chess engine that plays like a human at any\nrequested ELO and adapts in real time to match an opponent's level. The full working demo\nand runnable notebook are available — you can open and run the Colab notebook to inspect the\ncells and reproduce the experiments.\n</p>\n\n<h3>Concept</h3>\n<p>\nThe system contains two core components: an <strong>actor</strong> that outputs a probability\ndistribution over legal moves given the current position and a target ELO, and a\n<strong>critic</strong> that observes the whole game history and estimates the playing strength\n(ELO) of both players. A lightweight <strong>PID controller</strong> closes the loop: it\nmodifies the actor's target ELO on each move so that, in the long run, the critic's predicted\nELO for the actor tracks the human opponent's ELO.\n</p>\n\n<h3>Why this?</h3>\n<p>\nTwo practical goals motivated fast-elo:\n</p>\n<ol>\n<li>\nProvide a per-game estimate of a player's strength (ELO) instead of waiting many games for\nrating changes — helpful for new players who can be demoralized by slow rating convergence.\n</li>\n<li>\nProduce an actor that plays in a human-like manner at any ELO, enabling adaptive training\npartners, tutorials, or matchmaking simulations that behave plausibly for a given skill level.\n</li>\n</ol>\n\n<h3>Architecture</h3>\n<p>\nThe project uses three main building blocks:\n</p>\n<ul>\n<li>\n<strong>Chess Engine Actor</strong> — a transformer-based model (ViT-like) that accepts a\npiece-position encoding plus a target ELO and returns a probability distribution over a\nprecomputed vocabulary of legal moves. The actor is trained with supervised learning to\nimitate human moves conditioned on position and ELO.\n</li>\n<li>\n<strong>Critic</strong> — a transformer that ingests the full game history (sequence of\nposition encodings + UCI move indices) and predicts both players' ELOs. The critic is trained\non labeled game histories.\n</li>\n<li>\n<strong>PID Controller</strong> — compares target ELO vs critic prediction and adjusts the\nactor's target ELO for the following move so the critic's long-term estimate for the actor\nconverges to the opponent's ELO.\n</li>\n</ul>\n\n<h3>Key implementation details</h3>\n<p>\nThe notebook contains runnable implementations and notes for each important piece of the\npipeline:\n</p>\n<ul>\n<li>\n<strong>Position encoding</strong>: boards are reconstructed with python-chess and expressed\nas a sequence of piece tokens (max length 32). Each token combines a piece-type &amp;\ncolor vocabulary (12 tokens) with sinusoidal positional encodings; global state (castling\nrights, en-passant, move counters) is included via learned embeddings.\n</li>\n<li>\n<strong>Move vocabulary</strong>: a compact vocabulary of all possible legal moves (~under 2000)\nis precomputed (diagonals, straight lines, knight jumps, promotions, castling). The model\noutputs logits over this vocabulary and masks illegal moves per-position before softmax.\n</li>\n<li>\n<strong>Sequence encoding</strong>: game histories use Rotary Positional Encoding (RoPE) to\ncapture relative ordering of moves; RoPE is applied to move/position embeddings before the\ntransformer stack.\n</li>\n<li>\n<strong>Models</strong>: both actor and critic are implemented with transformer encoder layers.\nThe actor maps board tokens through transformer blocks to VOCAB_SIZE logits; the critic maps\nthe RoPE-encoded history to two continuous outputs (predicted ELOs).\n</li>\n<li>\n<strong>Training data</strong>: the Lichess dataset is used for supervised training. Games\nprovide position → move pairs with player ELO tags for the actor, and full histories with\nELO labels for the critic.\n</li>\n<li>\n<strong>PID tuning</strong>: controller gains (Kp, Ki, Kd) are tuned by grid search on a\nvalidation set; the tuning objective is to minimize mean absolute error between target ELO\nand critic-predicted ELO over move sequences.\n</li>\n</ul>\n\n<h3>Training &amp; inference</h3>\n<p>\nTraining is standard supervised learning:\n</p>\n<ul>\n<li>Actor: cross-entropy loss to predict the human move given position + player ELO.</li>\n<li>Critic: mean-squared-error loss to predict both players' ELOs from partial/full history.</li>\n</ul>\n<p>\nDuring inference the critic continuously estimates player ELOs. The PID adjusts the actor's\ntarget ELO so that the critic's estimate for the actor matches the opponent's estimated ELO\nover time, producing an adaptive, human-like opponent.\n</p>\n\n<h3>Demo &amp; how to run</h3>\n<p>\nThe Colab notebook contains the working code and small demos (model stubs, toy training loops,\nand a simple interactive loop to play with the adaptive actor). To run:\n</p>\n<ol>\n<li>Open the notebook in Colab.</li>\n<li>Install required packages (python-chess, PyTorch or TensorFlow depending on selected cell).</li>\n<li>Run cells top-to-bottom — there are commented cells that build the move vocabulary, encoders,\nsmall model instances and a minimal interactive demo.</li>\n</ol>\n\n<h3>Limitations &amp; next steps</h3>\n<p>\nfast-elo is a proof-of-concept weekend experiment. Current limitations include:\n</p>\n<ul>\n<li>Models in the notebook are intentionally small / toy-sized for speed — scaling will require larger datasets and compute.</li>\n<li>Per-game ELO prediction is noisy early in a short game; longer histories give more reliable estimates.</li>\n<li>The actor learns to imitate human moves at a given ELO but does not explicitly optimize for human-like errors (future work: behavior cloning + penalty terms for non-human heuristics).</li>\n</ul>\n<p>\nReasonable next steps: scale actor &amp; critic, incorporate reinforcement fine-tuning for more robust adaptive play, and evaluate human perception of \"human-likeness\" across ELO bands.\n</p>\n\n<h3>Links</h3>\n<a href='https://colab.research.google.com/drive/1mUeFFOFaGrdJroYQS3wMqFKE4IXxBh1w?usp=sharing' target='_blank' rel='noopener noreferrer'>\nOpen fast-elo notebook on Colab\n</a>\n</article>",
            "es": "<article class='project-article'>\n<h2>fast-elo — Actor de ajedrez adaptativo en tiempo real y similar a un humano</h2>\n\n<p>\nfast-elo es un proyecto experimental de fin de semana que construí hace un par de meses que explora una\narquitectura crítico-actor para producir un motor de ajedrez que juegue como un humano en cualquier\nELO solicitado y se adapte en tiempo real para igualar el nivel de un oponente. La demostración completa\ny el cuaderno ejecutable están disponibles: puedes abrir y ejecutar el cuaderno de Colab para inspeccionar las\nceldas y reproducir los experimentos.\n</p>\n\n<h3>Concepto</h3>\n<p>\nEl sistema contiene dos componentes principales: un <strong>actor</strong> que produce una distribución de probabilidad\nsobre movimientos legales dado la posición actual y un ELO objetivo, y un <strong>crítico</strong> que observa todo el historial del juego y estima la fuerza de juego\n(ELO) de ambos jugadores. Un <strong>controlador PID</strong> ligero cierra el ciclo: modifica el ELO objetivo del actor en cada movimiento para que, a largo plazo, el ELO predicho por el crítico para el actor siga el ELO del oponente humano.\n</p>\n\n<h3>¿Por qué esto?</h3>\n<p>\nDos objetivos prácticos motivaron fast-elo:\n</p>\n<ol>\n<li>\nProporcionar una estimación por juego de la fuerza de un jugador (ELO) en lugar de esperar muchos juegos para los cambios de calificación, lo cual es útil para jugadores nuevos que pueden desanimarse por la lenta convergencia de la calificación.\n</li>\n<li>\nProducir un actor que juegue de manera similar a un humano en cualquier ELO, permitiendo socios de entrenamiento adaptativos, tutoriales o simulaciones de emparejamiento que se comporten plausiblemente para un nivel de habilidad dado.\n</li>\n</ol>\n\n<h3>Arquitectura</h3>\n<p>\nEl proyecto utiliza tres bloques principales:\n</p>\n<ul>\n<li>\n<strong>Actor del motor de ajedrez</strong>: un modelo basado en transformadores (similar a ViT) que acepta una codificación de posición de piezas más un ELO objetivo y devuelve una distribución de probabilidad sobre un vocabulario precomputado de movimientos legales. El actor se entrena con aprendizaje supervisado para imitar movimientos humanos condicionados por posición y ELO.\n</li>\n<li>\n<strong>Crítico</strong>: un transformador que ingiere todo el historial del juego (secuencia de codificaciones de posición + índices de movimiento UCI) y predice los ELOs de ambos jugadores. El crítico se entrena en historiales de juegos etiquetados.\n</li>\n<li>\n<strong>Controlador PID</strong>: compara el ELO objetivo con la predicción del crítico y ajusta el ELO objetivo del actor para el siguiente movimiento para que la estimación a largo plazo del crítico para el actor\nconverja al ELO del oponente.\n</li>\n</ul>\n\n<h3>Detalles clave de implementación</h3>\n<p>\nEl cuaderno contiene implementaciones ejecutables y notas para cada pieza importante de la\ncadena de procesamiento:\n</p>\n<ul>\n<li>\n<strong>Codificación de posición</strong>: los tableros se reconstruyen con python-chess y se expresan como una secuencia de tokens de piezas (longitud máxima 32). Cada token combina un vocabulario de tipo de pieza y color (12 tokens) con codificaciones posicionales sinusoidales; el estado global (derechos de enroque, en passant, contadores de movimientos) se incluye mediante incrustaciones aprendidas.\n</li>\n<li>\n<strong>Vocabulario de movimientos</strong>: se precomputa un vocabulario compacto de todos los movimientos legales posibles (~menos de 2000) (diagonales, líneas rectas, saltos de caballos, promociones, enroques). El modelo produce logits sobre este vocabulario y enmascara los movimientos ilegales por posición antes del softmax.\n</li>\n<li>\n<strong>Codificación de secuencia</strong>: los historiales de juegos utilizan la codificación posicional rotatoria (RoPE) para capturar el orden relativo de los movimientos; RoPE se aplica a las incrustaciones de movimiento/posición antes del conjunto de transformadores.\n</li>\n<li>\n<strong>Modelos</strong>: tanto el actor como el crítico se implementan con capas de codificador de transformadores. El actor mapea los tokens del tablero a través de bloques de transformadores a logits de VOCAB_SIZE; el crítico mapea el historial codificado con RoPE a dos salidas continuas (ELOs predichos).\n</li>\n<li>\n<strong>Datos de entrenamiento</strong>: se utiliza el conjunto de datos de Lichess para el entrenamiento supervisado. Los juegos proporcionan pares posición → movimiento con etiquetas de ELO de jugador para el actor, y historiales completos con etiquetas de ELO para el crítico.\n</li>\n<li>\n<strong>Ajuste del PID</strong>: las ganancias del controlador (Kp, Ki, Kd) se ajustan mediante búsqueda en cuadrícula en un conjunto de validación; el objetivo de ajuste es minimizar el error absoluto medio entre el ELO objetivo y el ELO predicho por el crítico sobre secuencias de movimientos.\n</li>\n</ul>\n\n<h3>Entrenamiento e inferencia</h3>\n<p>\nEl entrenamiento es un aprendizaje supervisado estándar:\n</p>\n<ul>\n<li>Actor: pérdida de entropía cruzada para predecir el movimiento humano dado la posición + ELO del jugador.</li>\n<li>Crítico: pérdida de error cuadrático medio para predecir ambos ELOs a partir del historial parcial/completo.</li>\n</ul>\n<p>\nDurante la inferencia, el crítico estima continuamente los ELOs de los jugadores. El PID ajusta el ELO objetivo del actor para que la estimación del crítico para el actor coincida con el ELO estimado del oponente a lo largo del tiempo, produciendo un oponente adaptativo y similar a un humano.\n</p>\n\n<h3>Demo y cómo ejecutar</h3>\n<p>\nEl cuaderno de Colab contiene el código de trabajo y pequeñas demostraciones (bocetos de modelos, bucles de entrenamiento de juguete y un simple bucle interactivo para jugar con el actor adaptativo). Para ejecutar:\n</p>\n<ol>\n<li>Abre el cuaderno en Colab.</li>\n<li>Instala los paquetes requeridos (python-chess, PyTorch o TensorFlow dependiendo de la celda seleccionada).</li>\n<li>Ejecuta las celdas de arriba hacia abajo: hay celdas comentadas que construyen el vocabulario de movimientos, codificadores, pequeñas instancias de modelos y una demostración interactiva simple.</li>\n</ol>\n\n<h3>Limitaciones y próximos pasos</h3>\n<p>\nfast-elo es un experimento de fin de semana como prueba de concepto. Las limitaciones actuales incluyen:\n</p>\n<ul>\n<li>Los modelos en el cuaderno son intencionalmente pequeños / de juguete para mayor velocidad: escalar requerirá conjuntos de datos y computación más grandes.</li>\n<li>La predicción de ELO por juego es ruidosa al principio de un juego corto; los historiales más largos proporcionan estimaciones más confiables.</li>\n<li>El actor aprende a imitar movimientos humanos en un ELO dado, pero no optimiza explícitamente para errores similares a los humanos (trabajo futuro: clonación de comportamiento + términos de penalización por heurísticas no humanas).</li>\n</ul>\n<p>\nLos próximos pasos razonables: escalar el actor y el crítico, incorporar un ajuste fino de refuerzo para un juego adaptativo más robusto y evaluar la percepción humana de la \"similitud humana\" a través de bandas de ELO.\n</p>\n\n<h3>Links</h3>\n<a href='https://colab.research.google.com/drive/1mUeFFOFaGrdJroYQS3wMqFKE4IXxBh1w?usp=sharing' target='_blank' rel='noopener noreferrer'>\nAbrir cuaderno fast-elo en Colab\n</a>\n</article>",
            "fr": "<article class='project-article'>\n<h2>fast-elo — Acteur d'échecs adaptatif en temps réel et semblable à un humain</h2>\n\n<p>\nfast-elo est un projet expérimental de week-end que j'ai construit il y a quelques mois et qui explore une\narchitecture critique-acteur pour produire un moteur d'échecs qui joue comme un humain à n'importe quel\nELO demandé et s'adapte en temps réel pour correspondre au niveau d'un adversaire. La démo complète\net le notebook exécutable sont disponibles — vous pouvez ouvrir et exécuter le notebook Colab pour inspecter les\ncellules et reproduire les expériences.\n</p>\n\n<h3>Concept</h3>\n<p>\nLe système contient deux composants principaux : un <strong>acteur</strong> qui produit une distribution de probabilité\nsur les coups légaux étant donné la position actuelle et un ELO cible, et un <strong>critique</strong> qui observe l'historique complet du jeu et estime la force de jeu\n(ELO) des deux joueurs. Un <strong>contrôleur PID</strong> léger ferme la boucle : il\nmodifie l'ELO cible de l'acteur à chaque coup afin que, à long terme, l'ELO prédit par le critique pour l'acteur suive l'ELO de l'adversaire humain.\n</p>\n\n<h3>Pourquoi cela ?</h3>\n<p>\nDeux objectifs pratiques ont motivé fast-elo :\n</p>\n<ol>\n<li>\nFournir une estimation par partie de la force d'un joueur (ELO) au lieu d'attendre de nombreuses parties pour les changements de classement — utile pour les nouveaux joueurs qui peuvent être démoralisés par la lente convergence du classement.\n</li>\n<li>\nProduire un acteur qui joue de manière semblable à un humain à n'importe quel ELO, permettant des partenaires d'entraînement adaptatifs, des tutoriels ou des simulations de matchmaking qui se comportent de manière plausible pour un niveau de compétence donné.\n</li>\n</ol>\n\n<h3>Architecture</h3>\n<p>\nLe projet utilise trois blocs principaux :\n</p>\n<ul>\n<li>\n<strong>Acteur du moteur d'échecs</strong> — un modèle basé sur des transformateurs (de type ViT) qui accepte une\ncodification de la position des pièces plus un ELO cible et renvoie une distribution de probabilité sur un\nvocabulaire pré-calculé de coups légaux. L'acteur est entraîné avec un apprentissage supervisé pour\nimiter les coups humains conditionnés par la position et l'ELO.\n</li>\n<li>\n<strong>Critique</strong> — un transformateur qui ingère l'historique complet du jeu (séquence de\ncodifications de position + indices de coups UCI) et prédit les ELOs des deux joueurs. Le critique est entraîné\nsur des historiques de jeux étiquetés.\n</li>\n<li>\n<strong>Contrôleur PID</strong> — compare l'ELO cible à la prédiction du critique et ajuste l'ELO cible de l'acteur pour le coup suivant afin que l'estimation à long terme du critique pour l'acteur\nconverge vers l'ELO de l'adversaire.\n</li>\n</ul>\n\n<h3>Détails clés de l'implémentation</h3>\n<p>\nLe notebook contient des implémentations exécutables et des notes pour chaque pièce importante de la\nchaîne de traitement :\n</p>\n<ul>\n<li>\n<strong>Codification de la position</strong> : les plateaux sont reconstruits avec python-chess et exprimés comme une séquence de tokens de pièces (longueur max 32). Chaque token combine un vocabulaire de type de pièce et de couleur (12 tokens) avec des codifications positionnelles sinusoïdales ; l'état global (droits de roque, en passant, compteurs de coups) est inclus via des embeddings appris.\n</li>\n<li>\n<strong>Vocabulaire des coups</strong> : un vocabulaire compact de tous les coups légaux possibles (~moins de 2000) est pré-calculé (diagonales, lignes droites, sauts de cavalier, promotions, roques). Le modèle produit des logits sur ce vocabulaire et masque les coups illégaux par position avant le softmax.\n</li>\n<li>\n<strong>Codification de la séquence</strong> : les historiques de jeux utilisent la codification positionnelle rotative (RoPE) pour capturer l'ordre relatif des coups ; RoPE est appliqué aux embeddings de mouvement/position avant la pile de transformateurs.\n</li>\n<li>\n<strong>Modèles</strong> : l'acteur et le critique sont tous deux implémentés avec des couches d'encodeur de transformateurs. L'acteur mappe les tokens du plateau à travers des blocs de transformateurs vers des logits VOCAB_SIZE ; le critique mappe l'historique codé avec RoPE vers deux sorties continues (ELOs prédits).\n</li>\n<li>\n<strong>Données d'entraînement</strong> : le jeu de données Lichess est utilisé pour l'entraînement supervisé. Les parties fournissent des paires position → coup avec des étiquettes ELO de joueur pour l'acteur, et des historiques complets avec des étiquettes ELO pour le critique.\n</li>\n<li>\n<strong>Ajustement du PID</strong> : les gains du contrôleur (Kp, Ki, Kd) sont ajustés par recherche en grille sur un ensemble de validation ; l'objectif d'ajustement est de minimiser l'erreur absolue moyenne entre l'ELO cible et l'ELO prédit par le critique sur des séquences de coups.\n</li>\n</ul>\n\n<h3>Entraînement et inférence</h3>\n<p>\nL'entraînement est un apprentissage supervisé standard :\n</p>\n<ul>\n<li>Acteur : perte d'entropie croisée pour prédire le coup humain donné la position + l'ELO du joueur.</li>\n<li>Critique : perte d'erreur quadratique moyenne pour prédire les ELOs des deux joueurs à partir de l'historique partiel/complet.</li>\n</ul>\n<p>\nLors de l'inférence, le critique estime continuellement les ELOs des joueurs. Le PID ajuste l'ELO cible de l'acteur pour que l'estimation du critique pour l'acteur corresponde à l'ELO estimé de l'adversaire au fil du temps, produisant un adversaire adaptatif et semblable à un humain.\n</p>\n\n<h3>Démo et comment exécuter</h3>\n<p>\nLe notebook Colab contient le code de travail et de petites démos (ébauches de modèles, boucles d'entraînement jouet et une simple boucle interactive pour jouer avec l'acteur adaptatif). Pour exécuter :\n</p>\n<ol>\n<li>Ouvrez le notebook dans Colab.</li>\n<li>Installez les packages requis (python-chess, PyTorch ou TensorFlow selon la cellule sélectionnée).</li>\n<li>Exécutez les cellules de haut en bas — il y a des cellules commentées qui construisent le vocabulaire des coups, les encodeurs, de petites instances de modèles et une simple démo interactive.</li>\n</ol>\n\n<h3>Limitations et prochaines étapes</h3>\n<p>\nfast-elo est une preuve de concept. Les limitations actuelles incluent :\n</p>\n<ul>\n<li>Les modèles dans le notebook sont intentionnellement petits / de type jouet pour la vitesse — la mise à l'échelle nécessitera des ensembles de données et une puissance de calcul plus importants.</li>\n<li>La prédiction d'ELO par partie est bruyante au début d'une partie courte ; les historiques plus longs fournissent des estimations plus fiables.</li>\n<li>L'acteur apprend à imiter les coups humains à un ELO donné, mais n'optimise pas explicitement pour des erreurs semblables à celles des humains (travail futur : clonage de comportement + termes de pénalité pour les heuristiques non humaines).</li>\n</ul>\n<p>\nLes prochains pas raisonnables : mettre à l'échelle l'acteur et le critique, incorporer un ajustement fin par renforcement pour un jeu adaptatif plus robuste, et évaluer la perception humaine de la \"ressemblance humaine\" à travers les bandes ELO.\n</p>\n\n<h3>Links</h3>\n<a href='https://colab.research.google.com/drive/1mUeFFOFaGrdJroYQS3wMqFKE4IXxBh1w?usp=sharing' target='_blank' rel='noopener noreferrer'>\nOuvrir le notebook fast-elo sur Colab\n</a>\n</article>",
            "ja": "<article class='project-article'>\n<h2>fast-elo — リアルタイムで人間のように適応するチェスアクター</h2>\n\n<p>\nfast-eloは、数ヶ月前に構築した実験的な週末プロジェクトであり、人間のようにプレイするチェスエンジンを生成するためのクリティック-アクターアーキテクチャを探求しています。要求されたELOでリアルタイムに適応します。完全なデモと実行可能なノートブックが利用可能です。Colabノートブックを開いて実行し、セルを検査して実験を再現できます。\n</p>\n\n<h3>コンセプト</h3>\n<p>\nシステムには2つの主要なコンポーネントがあります。現在の位置と目標ELOに基づいて合法的な動きに対する確率分布を出力する<strong>アクター</strong>と、ゲームの全履歴を観察し、両方のプレイヤーのプレイ強度（ELO）を推定する<strong>クリティック</strong>です。軽量な<strong>PIDコントローラー</strong>がループを閉じます。各動きでアクターの目標ELOを変更し、長期的にはクリティックのアクターに対する予測ELOが人間の対戦相手のELOに追従するようにします。\n</p>\n\n<h3>なぜこれなのか？</h3>\n<p>\nfast-eloには2つの実用的な目標があります。\n</p>\n<ol>\n<li>\n多くのゲームを待って評価の変化を待つ代わりに、プレイヤーの強さ（ELO）のゲームごとの推定値を提供します。これは、評価の収束が遅いために落胆する可能性のある新しいプレイヤーに役立ちます。\n</li>\n<li>\n任意のELOで人間のようにプレイするアクターを生成し、適応型トレーニングパートナー、チュートリアル、または与えられたスキルレベルに対してもっともらしく振る舞うマッチメイキングシミュレーションを可能にします。\n</li>\n</ol>\n\n<h3>アーキテクチャ</h3>\n<p>\nプロジェクトは3つの主要なビルディングブロックを使用しています。\n</p>\n<ul>\n<li>\n<strong>チェスエンジンアクター</strong> — トランスフォーマーベースのモデル（ViTのようなもの）で、ピース位置エンコーディングと目標ELOを受け取り、合法的な動きの事前計算された語彙にわたる確率分布を返します。アクターは、位置とELOに条件付けられた人間の動きを模倣するために、教師あり学習で訓練されます。\n</li>\n<li>\n<strong>クリティック</strong> — 完全なゲーム履歴（位置エンコーディング+UCIムーブインデックスのシーケンス）を取り込み、両方のプレイヤーのELOを予測するトランスフォーマー。クリティックは、ラベル付きのゲーム履歴で訓練されます。\n</li>\n<li>\n<strong>PIDコントローラー</strong> — 目標ELOとクリティックの予測を比較し、アクターの次の動きの目標ELOを調整して、クリティックのアクターに対する長期的な推定が対戦相手のELOに収束するようにします。\n</li>\n</ul>\n\n<h3>実装の重要な詳細</h3>\n<p>\nノートブックには、パイプラインの各重要な部分の実行可能な実装とメモが含まれています。\n</p>\n<ul>\n<li>\n<strong>位置エンコーディング</strong>：ボードはpython-chessで再構築され、ピーストークンのシーケンスとして表現されます（最大長32）。各トークンは、ピースタイプと色の語彙（12トークン）を正弦波位置エンコーディングと組み合わせています。キャスリング権、アンパッサン、ムーブカウンターなどのグローバル状態は、学習された埋め込みを介して含まれています。\n</li>\n<li>\n<strong>ムーブ語彙</strong>：すべての可能な合法的な動きのコンパクトな語彙（約2000未満）が事前計算されます（対角線、直線、ナイトジャンプ、プロモーション、キャスリング）。モデルはこの語彙にわたるロジットを出力し、ソフトマックスの前に位置ごとに違法な動きをマスクします。\n</li>\n<li>\n<strong>シーケンスエンコーディング</strong>：ゲーム履歴は、動きの相対的な順序をキャプチャするために回転位置エンコーディング（RoPE）を使用します。RoPEは、トランスフォーマースタックの前にムーブ/ポジション埋め込みに適用されます。\n</li>\n<li>\n<strong>モデル</strong>：アクターとクリティックの両方は、トランスフォーマーエンコーダーレイヤーで実装されています。アクターはボードトークンをトランスフォーマーブロックを介してVOCAB_SIZEロジットにマッピングします。クリティックはRoPEエンコードされた履歴を2つの連続出力（予測ELO）にマッピングします。\n</li>\n<li>\n<strong>トレーニングデータ</strong>：教師あり学習にはLichessデータセットが使用されます。ゲームは、アクターのプレイヤーELOラベル付きの位置→ムーブペアを提供し、クリティックにはELOラベル付きの完全な履歴を提供します。\n</li>\n<li>\n<strong>PIDチューニング</strong>：コントローラーのゲイン（Kp、Ki、Kd）は、検証セットでのグリッドサーチによって調整されます。チューニングの目標は、ムーブシーケンスにわたる目標ELOとクリティックによって予測されたELOとの間の平均絶対誤差を最小化することです。\n</li>\n</ul>\n\n<h3>トレーニングと推論</h3>\n<p>\nトレーニングは標準的な教師あり学習です。\n</p>\n<ul>\n<li>アクター：プレイヤーの位置+ELOを与えられた人間の動きを予測するためのクロスエントロピー損失。</li>\n<li>クリティック：部分的/完全な履歴から両方のプレイヤーのELOを予測するための平均二乗誤差損失。</li>\n</ul>\n<p>\n推論中、クリティックはプレイヤーのELOを継続的に推定します。PIDは、時間の経過とともにクリティックのアクターに対する推定が対戦相手の推定ELOに一致するようにアクターの目標ELOを調整し、人間のように適応する対戦相手を生成します。\n</p>\n\n<h3>デモと実行方法</h3>\n<p>\nColabノートブックには、動作するコードと小さなデモ（モデルのスケッチ、トイゲームループ、適応アクターと遊ぶためのシンプルなインタラクティブループ）が含まれています。実行するには：\n</p>\n<ol>\n<li>Colabでノートブックを開きます。</li>\n<li>必要なパッケージをインストールします（python-chess、PyTorchまたはTensorFlow、選択したセルに応じて）。</li>\n<li>上から下へセルを実行します。ムーブ語彙、エンコーダー、小さなモデルインスタンス、シンプルなインタラクティブデモを構築するコメント付きセルがあります。</li>\n</ol>\n\n<h3>制限事項と今後のステップ</h3>\n<p>\nfast-eloは概念実証としての週末の実験です。現在の制限事項には以下が含まれます。\n</p>\n<ul>\n<li>ノートブック内のモデルは速度のために意図的に小さく/おもちゃサイズです。スケーリングにはより大きなデータセットと計算が必要です。</li>\n<li>短いゲームの初めでは、ゲームごとのELO予測はノイズが多いです。より長い履歴はより信頼性の高い推定を提供します。</li>\n<li>アクターは特定のELOで人間の動きを模倣することを学習しますが、人間に似たエラーを明示的に最適化しません（将来の作業：行動のクローン化+非人間的なヒューリスティックに対するペナルティ項）。</li>\n</ul>\n<p>\n合理的な次のステップ：アクターとクリティックのスケーリング、より堅牢な適応型ゲームのための強化学習による微調整の組み込み、ELOバンドを通じた「人間らしさ」の人間の知覚の評価。\n</p>\n\n<h3>Links</h3>\n<a href='https://colab.research.google.com/drive/1mUeFFOFaGrdJroYQS3wMqFKE4IXxBh1w?usp=sharing' target='_blank' rel='noopener noreferrer'>\nColabでfast-eloノートブックを開く\n</a>\n</article>",
            "ru": "<article class='project-article'>\n<h2>fast-elo — Адаптивный шахматный актёр в реальном времени, похожий на человека</h2>\n\n<p>\nfast-elo — это экспериментальный проект выходного дня, который я создал несколько месяцев назад. Он исследует архитектуру критик-актёр для создания шахматного движка, который играет как человек на любом запрошенном ELO и адаптируется в реальном времени, чтобы соответствовать уровню соперника. Доступна полная демонстрация и исполняемый блокнот — вы можете открыть и запустить блокнот Colab, чтобы изучить ячейки и воспроизвести эксперименты.\n</p>\n\n<h3>Концепция</h3>\n<p>\nСистема содержит два основных компонента: <strong>актёр</strong>, который генерирует распределение вероятностей по легальным ходам, учитывая текущую позицию и целевой ELO, и <strong>критик</strong>, который наблюдает за всей историей игры и оценивает силу игры (ELO) обоих игроков. Лёгкий <strong>PID-контроллер</strong> замыкает цикл: он изменяет целевой ELO актёра при каждом ходе, чтобы в долгосрочной перспективе предсказанный критиком ELO для актёра следовал за ELO человеческого соперника.\n</p>\n\n<h3>Зачем это нужно?</h3>\n<p>\nДва практических цели мотивировали fast-elo:\n</p>\n<ol>\n<li>\nПредоставить оценку силы игрока (ELO) за игру вместо ожидания множества игр для изменений рейтинга — это полезно для новых игроков, которые могут быть разочарованы медленной сходимостью рейтинга.\n</li>\n<li>\nСоздать актёра, который играет похоже на человека на любом ELO, позволяя адаптивным тренировочным партнёрам, учебным пособиям или симуляциям подбора матчей вести себя правдоподобно для заданного уровня навыков.\n</li>\n</ol>\n\n<h3>Архитектура</h3>\n<p>\nПроект использует три основных строительных блока:\n</p>\n<ul>\n<li>\n<strong>Актёр шахматного движка</strong> — модель на основе трансформеров (похожая на ViT), которая принимает кодирование позиции фигур плюс целевой ELO и возвращает распределение вероятностей по заранее вычисленному словарю легальных ходов. Актёр обучается с помощью контролируемого обучения для имитации человеческих ходов, обусловленных позицией и ELO.\n</li>\n<li>\n<strong>Критик</strong> — трансформер, который поглощает всю историю игры (последовательность кодировок позиций + индексы ходов UCI) и предсказывает ELO обоих игроков. Критик обучается на размеченных историях игр.\n</li>\n<li>\n<strong>PID-контроллер</strong> — сравнивает целевой ELO с предсказанием критика и корректирует целевой ELO актёра для следующего хода, чтобы долгосрочная оценка критика для актёра сходилась к ELO соперника.\n</li>\n</ul>\n\n<h3>Ключевые детали реализации</h3>\n<p>\nБлокнот содержит исполняемые реализации и заметки для каждой важной части конвейера обработки:\n</p>\n<ul>\n<li>\n<strong>Кодирование позиции</strong> — доски восстанавливаются с помощью python-chess и выражаются как последовательность токенов фигур (максимальная длина 32). Каждый токен сочетает в себе словарь типа фигуры и цвета (12 токенов) с синусоидальным позиционным кодированием; глобальное состояние (права на рокировку, взятие на проходе, счётчики ходов) включается через обучаемые встраивания.\n</li>\n<li>\n<strong>Словарь ходов</strong> — компактный словарь всех возможных легальных ходов (~менее 2000) предварительно вычисляется (диагонали, прямые линии, прыжки коня, превращения, рокировки). Модель генерирует логиты по этому словарю и маскирует нелегальные ходы по позиции перед софтмаксом.\n</li>\n<li>\n<strong>Кодирование последовательности</strong> — истории игр используют ротационное позиционное кодирование (RoPE) для захвата относительного порядка ходов; RoPE применяется к встраиваниям ходов/позиций перед стеком трансформеров.\n</li>\n<li>\n<strong>Модели</strong> — и актёр, и критик реализованы с помощью слоёв энкодера трансформеров. Актёр отображает токены доски через блоки трансформеров в логиты VOCAB_SIZE; критик отображает закодированную с помощью RoPE историю в два непрерывных выхода (предсказанные ELO).\n</li>\n<li>\n<strong>Данные для обучения</strong> — для контролируемого обучения используется набор данных Lichess. Игры предоставляют пары позиция → ход с метками ELO игрока для актёра и полные истории с метками ELO для критика.\n</li>\n<li>\n<strong>Настройка PID</strong> — коэффициенты контроллера (Kp, Ki, Kd) настраиваются с помощью перебора по сетке на валидационном наборе; цель настройки — минимизировать среднюю абсолютную ошибку между целевым ELO и предсказанным критиком ELO по последовательностям ходов.\n</li>\n</ul>\n\n<h3>Обучение и вывод</h3>\n<p>\nОбучение — это стандартное контролируемое обучение:\n</p>\n<ul>\n<li>Актёр: кросс-энтропийная потеря для предсказания человеческого хода, учитывая позицию + ELO игрока.</li>\n<li>Критик: потеря среднеквадратичной ошибки для предсказания ELO обоих игроков из частичной/полной истории.</li>\n</ul>\n<p>\nВо время вывода критик непрерывно оценивает ELO игроков. PID корректирует целевой ELO актёра, чтобы оценка критика для актёра соответствовала оценке ELO соперника с течением времени, создавая адаптивного и похожего на человека соперника.\n</p>\n\n<h3>Демо и как запустить</h3>\n<p>\nБлокнот Colab содержит рабочий код и небольшие демонстрации (наброски моделей, игрушечные игровые циклы и простой интерактивный цикл для игры с адаптивным актёром). Чтобы запустить:\n</p>\n<ol>\n<li>Откройте блокнот в Colab.</li>\n<li>Установите необходимые пакеты (python-chess, PyTorch или TensorFlow в зависимости от выбранной ячейки).</li>\n<li>Выполните ячейки сверху вниз: есть комментированные ячейки, которые строят словарь ходов, энкодеры, небольшие экземпляры моделей и простое интерактивное демо.</li>\n</ol>\n\n<h3>Ограничения и следующие шаги</h3>\n<p>\nfast-elo — это эксперимент выходного дня для доказательства концепции. Текущие ограничения включают:\n</p>\n<ul>\n<li>Модели в блокноте намеренно маленькие/игрушечные для скорости — масштабирование потребует больших наборов данных и вычислительных ресурсов.</li>\n<li>Прогноз ELO за игру шумный в начале короткой игры; более длинные истории дают более надежные оценки.</li>\n<li>Актёр учится имитировать человеческие ходы на заданном ELO, но не оптимизирует явно для ошибок, похожих на человеческие (будущая работа: клонирование поведения + штрафные термы для нечеловеческих эвристик).</li>\n</ul>\n<p>\nРазумные следующие шаги: масштабирование актёра и критика, включение донастройки с подкреплением для более надежной адаптивной игры и оценка человеческого восприятия «человечности» через диапазоны ELO.\n</p>\n\n<h3>Links</h3>\n<a href='https://colab.research.google.com/drive/1mUeFFOFaGrdJroYQS3wMqFKE4IXxBh1w?usp=sharing' target='_blank' rel='noopener noreferrer'>\nОткрыть блокнот fast-elo на Colab\n</a>\n</article>"
        }
    }
]